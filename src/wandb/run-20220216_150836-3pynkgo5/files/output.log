LSTM(
  (conv1): Conv1d(1, 30, kernel_size=(10,), stride=(1,))
  (conv2): Conv1d(30, 30, kernel_size=(8,), stride=(1,))
  (conv3): Conv1d(30, 40, kernel_size=(6,), stride=(1,))
  (conv4): Conv1d(40, 50, kernel_size=(5,), stride=(1,))
  (conv5): Conv1d(50, 50, kernel_size=(5,), stride=(1,))
  (linear1): Linear(in_features=23500, out_features=1024, bias=True)
  (linear2): Linear(in_features=1024, out_features=1, bias=True)
  (relu): ReLU()
  (leaky): LeakyReLU(negative_slope=0.01)
  (dropout): Dropout(p=0.2, inplace=False)
)
Window Length:  499
5.802908
trigger times: 0
Loss after 131100 batches: 0.1167
1.839865
trigger times: 0
Loss after 262200 batches: 0.0863
1350420.5
trigger times: 1
Loss after 393300 batches: 398920278.5855
138454.6
trigger times: 2
Loss after 524400 batches: 9461883.0865
4827.86
trigger times: 3
Loss after 655500 batches: 249250.1417
4360.6616
trigger times: 4
Loss after 786600 batches: 109384.3567
4580.1333
trigger times: 5
Loss after 917700 batches: 54139.3157
6071.6084
trigger times: 6
Loss after 1048800 batches: 27755.9931
3724.8782
trigger times: 7
Loss after 1179900 batches: 14511.6390
1727.6389
trigger times: 8
Loss after 1311000 batches: 8196.7679
Time to train on one home:  2326.2614443302155