LSTM(
  (conv1): Conv1d(1, 30, kernel_size=(10,), stride=(1,))
  (conv2): Conv1d(30, 30, kernel_size=(8,), stride=(1,))
  (conv3): Conv1d(30, 40, kernel_size=(6,), stride=(1,))
  (conv4): Conv1d(40, 50, kernel_size=(5,), stride=(1,))
  (conv5): Conv1d(50, 50, kernel_size=(5,), stride=(1,))
  (linear1): Linear(in_features=23500, out_features=1024, bias=True)
  (linear2): Linear(in_features=1024, out_features=1, bias=True)
  (relu): ReLU()
  (leaky): LeakyReLU(negative_slope=0.01)
  (dropout): Dropout(p=0.2, inplace=False)
)
Window Length:  499
Adjusting learning rate of group 0 to 3.3181e-04.
Adjusting learning rate of group 0 to 3.3181e-04.
trigger times: 0
Loss after 393300 batches: 0.7668
Adjusting learning rate of group 0 to 3.3181e-04.
trigger times: 0
Loss after 786600 batches: 0.5372
Adjusting learning rate of group 0 to 3.3181e-04.
trigger times: 0
Loss after 1179900 batches: 0.3551
Adjusting learning rate of group 0 to 3.3181e-04.
trigger times: 1
Loss after 1573200 batches: 0.2406
Adjusting learning rate of group 0 to 3.1522e-04.
trigger times: 0
Loss after 1966500 batches: 0.1823
Adjusting learning rate of group 0 to 3.1522e-04.
trigger times: 0
Loss after 2359800 batches: 0.1481
Adjusting learning rate of group 0 to 3.1522e-04.
trigger times: 0
Loss after 2753100 batches: 0.1277
Adjusting learning rate of group 0 to 3.1522e-04.
trigger times: 1
Loss after 3146400 batches: 0.1152
Adjusting learning rate of group 0 to 3.1522e-04.
trigger times: 0
Loss after 3539700 batches: 0.1053
Adjusting learning rate of group 0 to 2.9946e-04.
trigger times: 0
Loss after 3933000 batches: 0.0973
Adjusting learning rate of group 0 to 2.9946e-04.
trigger times: 1
Loss after 4326300 batches: 0.0903
Adjusting learning rate of group 0 to 2.9946e-04.
trigger times: 0
Loss after 4719600 batches: 0.0865
Adjusting learning rate of group 0 to 2.9946e-04.
trigger times: 1
Loss after 5112900 batches: 0.0803
Adjusting learning rate of group 0 to 2.9946e-04.
trigger times: 2
Loss after 5506200 batches: 0.0769
Adjusting learning rate of group 0 to 2.8448e-04.
trigger times: 0
Loss after 5899500 batches: 0.0737
Adjusting learning rate of group 0 to 2.8448e-04.
trigger times: 0
Loss after 6292800 batches: 0.0695
Adjusting learning rate of group 0 to 2.8448e-04.
trigger times: 0
Loss after 6686100 batches: 0.0682
Adjusting learning rate of group 0 to 2.8448e-04.
trigger times: 1
Loss after 7079400 batches: 0.0646
Adjusting learning rate of group 0 to 2.8448e-04.
trigger times: 2
Loss after 7472700 batches: 0.0636
Adjusting learning rate of group 0 to 2.7026e-04.
trigger times: 3
Loss after 7866000 batches: 0.0609
Adjusting learning rate of group 0 to 2.7026e-04.
trigger times: 0
Loss after 8259300 batches: 0.0586
Adjusting learning rate of group 0 to 2.7026e-04.
trigger times: 0
Loss after 8652600 batches: 0.0566
Adjusting learning rate of group 0 to 2.7026e-04.
trigger times: 1
Loss after 9045900 batches: 0.0557
Adjusting learning rate of group 0 to 2.7026e-04.
trigger times: 0
Loss after 9439200 batches: 0.0541
Adjusting learning rate of group 0 to 2.5675e-04.
trigger times: 0
Loss after 9832500 batches: 0.0528
Adjusting learning rate of group 0 to 2.5675e-04.
trigger times: 0
Loss after 10225800 batches: 0.0508
Adjusting learning rate of group 0 to 2.5675e-04.
trigger times: 1
Loss after 10619100 batches: 0.0502
Adjusting learning rate of group 0 to 2.5675e-04.
trigger times: 2
Loss after 11012400 batches: 0.0488
Adjusting learning rate of group 0 to 2.5675e-04.
trigger times: 0
Loss after 11405700 batches: 0.0475
Adjusting learning rate of group 0 to 2.4391e-04.
trigger times: 1
Loss after 11799000 batches: 0.0473
Adjusting learning rate of group 0 to 2.4391e-04.
trigger times: 0
Loss after 12192300 batches: 0.0459
Adjusting learning rate of group 0 to 2.4391e-04.
trigger times: 1
Loss after 12585600 batches: 0.0440
Adjusting learning rate of group 0 to 2.4391e-04.
trigger times: 0
Loss after 12978900 batches: 0.0442
Adjusting learning rate of group 0 to 2.4391e-04.
trigger times: 0
Loss after 13372200 batches: 0.0427
Adjusting learning rate of group 0 to 2.3171e-04.
trigger times: 0
Loss after 13765500 batches: 0.0427
Adjusting learning rate of group 0 to 2.3171e-04.
trigger times: 1
Loss after 14158800 batches: 0.0416
Adjusting learning rate of group 0 to 2.3171e-04.
trigger times: 2
Loss after 14552100 batches: 0.0408
Adjusting learning rate of group 0 to 2.3171e-04.
trigger times: 3
Loss after 14945400 batches: 0.0406
Adjusting learning rate of group 0 to 2.3171e-04.
trigger times: 4
Loss after 15338700 batches: 0.0394
Adjusting learning rate of group 0 to 2.2013e-04.
trigger times: 0
Loss after 15732000 batches: 0.0393
Adjusting learning rate of group 0 to 2.2013e-04.
trigger times: 1
Loss after 16125300 batches: 0.0384
Adjusting learning rate of group 0 to 2.2013e-04.
trigger times: 2
Loss after 16518600 batches: 0.0376
Adjusting learning rate of group 0 to 2.2013e-04.
trigger times: 3
Loss after 16911900 batches: 0.0377
Adjusting learning rate of group 0 to 2.2013e-04.
trigger times: 4
Loss after 17305200 batches: 0.0373
Adjusting learning rate of group 0 to 2.0912e-04.
trigger times: 5
Loss after 17698500 batches: 0.0363
Adjusting learning rate of group 0 to 2.0912e-04.
trigger times: 6
Loss after 18091800 batches: 0.0359
Adjusting learning rate of group 0 to 2.0912e-04.
trigger times: 7
Loss after 18485100 batches: 0.0357
Adjusting learning rate of group 0 to 2.0912e-04.
trigger times: 8
Loss after 18878400 batches: 0.0350
Adjusting learning rate of group 0 to 2.0912e-04.
trigger times: 9
Loss after 19271700 batches: 0.0345
Adjusting learning rate of group 0 to 1.9867e-04.
trigger times: 10
Loss after 19665000 batches: 0.0345
Adjusting learning rate of group 0 to 1.9867e-04.
trigger times: 11
Loss after 20058300 batches: 0.0341
Adjusting learning rate of group 0 to 1.9867e-04.
trigger times: 12
Loss after 20451600 batches: 0.0332
Adjusting learning rate of group 0 to 1.9867e-04.
trigger times: 13
Loss after 20844900 batches: 0.0334
Adjusting learning rate of group 0 to 1.9867e-04.
trigger times: 0
Loss after 21238200 batches: 0.0330
Adjusting learning rate of group 0 to 1.8873e-04.
trigger times: 1
Loss after 21631500 batches: 0.0328
Adjusting learning rate of group 0 to 1.8873e-04.
trigger times: 2
Loss after 22024800 batches: 0.0324
Adjusting learning rate of group 0 to 1.8873e-04.
trigger times: 3
Loss after 22418100 batches: 0.0318
Adjusting learning rate of group 0 to 1.8873e-04.
trigger times: 4
Loss after 22811400 batches: 0.0318
Adjusting learning rate of group 0 to 1.8873e-04.
trigger times: 5
Loss after 23204700 batches: 0.0313
Adjusting learning rate of group 0 to 1.7930e-04.
trigger times: 6
Loss after 23598000 batches: 0.0313
Adjusting learning rate of group 0 to 1.7930e-04.
trigger times: 7
Loss after 23991300 batches: 0.0309
Adjusting learning rate of group 0 to 1.7930e-04.
trigger times: 8
Loss after 24384600 batches: 0.0304
Adjusting learning rate of group 0 to 1.7930e-04.
trigger times: 9
Loss after 24777900 batches: 0.0305
Adjusting learning rate of group 0 to 1.7930e-04.
trigger times: 10
Loss after 25171200 batches: 0.0298
Adjusting learning rate of group 0 to 1.7033e-04.
trigger times: 11
Loss after 25564500 batches: 0.0298
Adjusting learning rate of group 0 to 1.7033e-04.
trigger times: 12
Loss after 25957800 batches: 0.0297
Adjusting learning rate of group 0 to 1.7033e-04.
trigger times: 13
Loss after 26351100 batches: 0.0288
Adjusting learning rate of group 0 to 1.7033e-04.
trigger times: 14
Loss after 26744400 batches: 0.0294
Adjusting learning rate of group 0 to 1.7033e-04.
trigger times: 15
Loss after 27137700 batches: 0.0289
Adjusting learning rate of group 0 to 1.6181e-04.
trigger times: 16
Loss after 27531000 batches: 0.0289
Adjusting learning rate of group 0 to 1.6181e-04.
trigger times: 17
Loss after 27924300 batches: 0.0280
Adjusting learning rate of group 0 to 1.6181e-04.
trigger times: 18
Loss after 28317600 batches: 0.0283
Adjusting learning rate of group 0 to 1.6181e-04.
trigger times: 19
Loss after 28710900 batches: 0.0282
Adjusting learning rate of group 0 to 1.6181e-04.
trigger times: 20
Early stopping!
Start to test process.
Loss after 29104200 batches: 0.0278
Time to train on one home:  9329.834589958191