LSTM(
  (conv1): Conv1d(1, 30, kernel_size=(10,), stride=(1,))
  (conv2): Conv1d(30, 30, kernel_size=(8,), stride=(1,))
  (conv3): Conv1d(30, 40, kernel_size=(6,), stride=(1,))
  (conv4): Conv1d(40, 50, kernel_size=(5,), stride=(1,))
  (conv5): Conv1d(50, 50, kernel_size=(5,), stride=(1,))
  (linear1): Linear(in_features=23500, out_features=1024, bias=True)
  (linear2): Linear(in_features=1024, out_features=1, bias=True)
  (relu): ReLU()
  (leaky): LeakyReLU(negative_slope=0.01)
  (dropout): Dropout(p=0.2, inplace=False)
)
Window Length:  499
Adjusting learning rate of group 0 to 3.3181e-04.
Adjusting learning rate of group 0 to 3.3181e-04.
trigger times: 0
Loss after 1620840 batches: 0.5355
Adjusting learning rate of group 0 to 3.3181e-04.
trigger times: 1
Loss after 3241680 batches: 0.3445
Adjusting learning rate of group 0 to 3.3181e-04.
trigger times: 2
Loss after 4862520 batches: 0.2296
Adjusting learning rate of group 0 to 3.3181e-04.
trigger times: 3
Loss after 6483360 batches: 0.1695
Adjusting learning rate of group 0 to 3.1522e-04.
trigger times: 4
Loss after 8104200 batches: 0.1404
Adjusting learning rate of group 0 to 3.1522e-04.
trigger times: 5
Loss after 9725040 batches: 0.1196
Adjusting learning rate of group 0 to 3.1522e-04.
trigger times: 6
Loss after 11345880 batches: 0.1074
Adjusting learning rate of group 0 to 3.1522e-04.
trigger times: 7
Loss after 12966720 batches: 0.0975
Adjusting learning rate of group 0 to 3.1522e-04.
trigger times: 8
Loss after 14587560 batches: 0.0900
Adjusting learning rate of group 0 to 2.9946e-04.
trigger times: 9
Loss after 16208400 batches: 0.0832
Adjusting learning rate of group 0 to 2.9946e-04.
trigger times: 0
Loss after 17829240 batches: 0.0777
Adjusting learning rate of group 0 to 2.9946e-04.
trigger times: 1
Loss after 19450080 batches: 0.0722
Adjusting learning rate of group 0 to 2.9946e-04.
trigger times: 2
Loss after 21070920 batches: 0.0696
Adjusting learning rate of group 0 to 2.9946e-04.
trigger times: 3
Loss after 22691760 batches: 0.0659
Adjusting learning rate of group 0 to 2.8448e-04.
trigger times: 4
Loss after 24312600 batches: 0.0634
Adjusting learning rate of group 0 to 2.8448e-04.
trigger times: 5
Loss after 25933440 batches: 0.0596
Adjusting learning rate of group 0 to 2.8448e-04.
trigger times: 6
Loss after 27554280 batches: 0.0576
Adjusting learning rate of group 0 to 2.8448e-04.
trigger times: 7
Loss after 29175120 batches: 0.0564
Adjusting learning rate of group 0 to 2.8448e-04.
trigger times: 8
Loss after 30795960 batches: 0.0542
Adjusting learning rate of group 0 to 2.7026e-04.
trigger times: 9
Loss after 32416800 batches: 0.0529
Adjusting learning rate of group 0 to 2.7026e-04.
trigger times: 10
Loss after 34037640 batches: 0.0513
Adjusting learning rate of group 0 to 2.7026e-04.
trigger times: 11
Loss after 35658480 batches: 0.0500
Adjusting learning rate of group 0 to 2.7026e-04.
trigger times: 12
Loss after 37279320 batches: 0.0490
Adjusting learning rate of group 0 to 2.7026e-04.
trigger times: 13
Loss after 38900160 batches: 0.0478
Adjusting learning rate of group 0 to 2.5675e-04.
trigger times: 14
Loss after 40521000 batches: 0.0469
Adjusting learning rate of group 0 to 2.5675e-04.
trigger times: 15
Loss after 42141840 batches: 0.0456
Adjusting learning rate of group 0 to 2.5675e-04.
trigger times: 16
Loss after 43762680 batches: 0.0447
Adjusting learning rate of group 0 to 2.5675e-04.
trigger times: 17
Loss after 45383520 batches: 0.0438
Adjusting learning rate of group 0 to 2.5675e-04.
trigger times: 18
Loss after 47004360 batches: 0.0434
Adjusting learning rate of group 0 to 2.4391e-04.
trigger times: 19
Loss after 48625200 batches: 0.0426
Adjusting learning rate of group 0 to 2.4391e-04.
trigger times: 20
Early stopping!
Start to test process.
Loss after 50246040 batches: 0.0418
Time to train on one home:  16472.44886136055