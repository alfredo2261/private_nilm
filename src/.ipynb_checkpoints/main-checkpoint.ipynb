{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "937e8860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from data_loaders import make_train_data, make_test_val_data, make_model\n",
    "from train import train, test\n",
    "import torch\n",
    "import time\n",
    "import gc\n",
    "import config_file\n",
    "from clean_data import load_all_houses_with_device\n",
    "import random\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fee6b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnilm\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "wandb.login()\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(torch.__version__)  # should be 1.7.1\n",
    "\n",
    "\n",
    "config_ = config_file.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e609b5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.20.3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bef2e037",
   "metadata": {},
   "outputs": [],
   "source": [
    "homes = load_all_houses_with_device(config_file.path, 'drye1')\n",
    "\n",
    "\n",
    "drye1_homes = homes['dataid'].loc[homes['dataid'] != 1706].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d774e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"hidden_size_1\": trial.suggest_int(\"hidden_size_1\", 8, 128),\n",
    "        \"hidden_size_2\": trial.suggest_int(\"hidden_size_2\", 32, 512),\n",
    "        \"fc1\": trial.suggest_int(\"fc1\", 32, 512),\n",
    "        \"fc2\": trial.suggest_int(\"fc2\", 1, 32),\n",
    "        \"weight_decay\": trial.suggest_uniform(\"weight_decay\", 0, 0.1),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-6, 1e-3),\n",
    "        \"window_size\": trial.suggest_int(\"window_size\", 1, 250)\n",
    "    }\n",
    "\n",
    "    model, result = model_pipeline(\n",
    "        config_,\n",
    "        'may_june_july',\n",
    "        'may_june_july',\n",
    "        'drye1',\n",
    "        params['window_size'],\n",
    "        [drye1_homes[0]],\n",
    "        [1706],\n",
    "    params)\n",
    "        \n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3da120d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-19 18:38:59,537]\u001b[0m A new study created in memory with name: no-name-05ba8ff3-f7ae-46d1-8332-de9e050fa094\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">fearless-sound-487</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nilm/Drye1_single_houses\" target=\"_blank\">https://wandb.ai/nilm/Drye1_single_houses</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/nilm/Drye1_single_houses/runs/18io9ayo\" target=\"_blank\">https://wandb.ai/nilm/Drye1_single_houses/runs/18io9ayo</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\wandb\\run-20211119_183859-18io9ayo</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (conv1): Conv1d(1, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "  (lstm1): LSTM(16, 44, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (lstm2): LSTM(88, 341, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (linear1): Linear(in_features=682, out_features=183, bias=True)\n",
      "  (linear2): Linear(in_features=183, out_features=12, bias=True)\n",
      "  (linear3): Linear(in_features=12, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 00068 batches: 0.8754\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 00136 batches: 0.8826\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 00204 batches: 0.8823\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 00272 batches: 0.8813\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 00340 batches: 0.8810\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 00408 batches: 0.8736\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 00476 batches: 0.8830\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 00544 batches: 0.8744\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 00612 batches: 0.8815\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 00680 batches: 0.8761\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 00748 batches: 0.8731\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 00816 batches: 0.8745\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 00884 batches: 0.8759\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 00952 batches: 0.8740\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 01020 batches: 0.8710\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 01088 batches: 0.8697\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 01156 batches: 0.8739\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 01224 batches: 0.8735\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 01292 batches: 0.8672\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 01360 batches: 0.8676\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 01428 batches: 0.8717\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 01496 batches: 0.8725\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 01564 batches: 0.8732\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 01632 batches: 0.8698\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 01700 batches: 0.8688\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 01768 batches: 0.8688\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 01836 batches: 0.8723\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 01904 batches: 0.8669\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 01972 batches: 0.8591\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 02040 batches: 0.8696\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 02108 batches: 0.8680\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 02176 batches: 0.8526\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 02244 batches: 0.8656\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 02312 batches: 0.8639\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 02380 batches: 0.8542\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 02448 batches: 0.8636\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 02516 batches: 0.8554\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 02584 batches: 0.8604\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 02652 batches: 0.8550\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 02720 batches: 0.8606\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 02788 batches: 0.8593\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 02856 batches: 0.8596\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 02924 batches: 0.8637\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 02992 batches: 0.8549\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 03060 batches: 0.8618\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 03128 batches: 0.8500\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 03196 batches: 0.8504\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 03264 batches: 0.8566\n",
      "Adjusting learning rate of group 0 to 2.7988e-06.\n",
      "Loss after 03332 batches: 0.8479\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 03400 batches: 0.8568\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 03468 batches: 0.8602\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 03536 batches: 0.8493\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 03604 batches: 0.8623\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 03672 batches: 0.8485\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 03740 batches: 0.8477\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 03808 batches: 0.8479\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 03876 batches: 0.8487\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 03944 batches: 0.8540\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 04012 batches: 0.8475\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 04080 batches: 0.8450\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 04148 batches: 0.8518\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 04216 batches: 0.8463\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 04284 batches: 0.8470\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 04352 batches: 0.8475\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 04420 batches: 0.8419\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 04488 batches: 0.8422\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 04556 batches: 0.8510\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 04624 batches: 0.8463\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 04692 batches: 0.8411\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 04760 batches: 0.8397\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 04828 batches: 0.8449\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 04896 batches: 0.8374\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 04964 batches: 0.8401\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 05032 batches: 0.8398\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 05100 batches: 0.8387\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 05168 batches: 0.8408\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 05236 batches: 0.8447\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 05304 batches: 0.8464\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 05372 batches: 0.8354\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 05440 batches: 0.8445\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 05508 batches: 0.8413\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 05576 batches: 0.8363\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 05644 batches: 0.8453\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 05712 batches: 0.8404\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 05780 batches: 0.8419\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 05848 batches: 0.8387\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 05916 batches: 0.8356\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 05984 batches: 0.8279\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 06052 batches: 0.8308\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 06120 batches: 0.8324\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 06188 batches: 0.8396\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 06256 batches: 0.8241\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 06324 batches: 0.8298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 06392 batches: 0.8314\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 06460 batches: 0.8219\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 06528 batches: 0.8316\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 06596 batches: 0.8353\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 06664 batches: 0.8312\n",
      "Adjusting learning rate of group 0 to 2.5189e-06.\n",
      "Loss after 06732 batches: 0.8303\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 06800 batches: 0.8278\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 06868 batches: 0.8317\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 06936 batches: 0.8302\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 07004 batches: 0.8337\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 07072 batches: 0.8276\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 07140 batches: 0.8345\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 07208 batches: 0.8232\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 07276 batches: 0.8335\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 07344 batches: 0.8259\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 07412 batches: 0.8257\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 07480 batches: 0.8252\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 07548 batches: 0.8274\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 07616 batches: 0.8257\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 07684 batches: 0.8148\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 07752 batches: 0.8317\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 07820 batches: 0.8229\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 07888 batches: 0.8199\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 07956 batches: 0.8187\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 08024 batches: 0.8246\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 08092 batches: 0.8210\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 08160 batches: 0.8185\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 08228 batches: 0.8177\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 08296 batches: 0.8211\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 08364 batches: 0.8129\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 08432 batches: 0.8250\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 08500 batches: 0.8161\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 08568 batches: 0.8168\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 08636 batches: 0.8266\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 08704 batches: 0.8241\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 08772 batches: 0.8179\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 08840 batches: 0.8168\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 08908 batches: 0.8184\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 08976 batches: 0.8135\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 09044 batches: 0.8184\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 09112 batches: 0.8173\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 09180 batches: 0.8208\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 09248 batches: 0.8172\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 09316 batches: 0.8154\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 09384 batches: 0.8199\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 09452 batches: 0.8115\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 09520 batches: 0.8223\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 09588 batches: 0.8138\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 09656 batches: 0.8059\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 09724 batches: 0.8114\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 09792 batches: 0.8013\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 09860 batches: 0.8114\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 09928 batches: 0.8159\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 09996 batches: 0.8048\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 10064 batches: 0.8059\n",
      "Adjusting learning rate of group 0 to 2.2670e-06.\n",
      "Loss after 10132 batches: 0.8142\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 10200 batches: 0.8029\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 10268 batches: 0.8069\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 10336 batches: 0.8025\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 10404 batches: 0.7995\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 10472 batches: 0.8133\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 10540 batches: 0.8045\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 10608 batches: 0.8024\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 10676 batches: 0.8054\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 10744 batches: 0.8023\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 10812 batches: 0.8018\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 10880 batches: 0.8054\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 10948 batches: 0.8119\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 11016 batches: 0.8064\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 11084 batches: 0.7984\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 11152 batches: 0.8001\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 11220 batches: 0.8020\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 11288 batches: 0.7989\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 11356 batches: 0.8027\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 11424 batches: 0.7981\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 11492 batches: 0.7996\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 11560 batches: 0.8028\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 11628 batches: 0.8016\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 11696 batches: 0.8022\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 11764 batches: 0.7928\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 11832 batches: 0.7995\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 11900 batches: 0.7998\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 11968 batches: 0.8006\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 12036 batches: 0.7994\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 12104 batches: 0.8031\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 12172 batches: 0.7971\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 12240 batches: 0.7962\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 12308 batches: 0.7974\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 12376 batches: 0.7928\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 12444 batches: 0.7965\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 12512 batches: 0.7942\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 12580 batches: 0.7954\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 12648 batches: 0.7959\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 12716 batches: 0.7994\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 12784 batches: 0.7967\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 12852 batches: 0.7911\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 12920 batches: 0.7969\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 12988 batches: 0.7951\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 13056 batches: 0.7941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 13124 batches: 0.7950\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 13192 batches: 0.7952\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 13260 batches: 0.7884\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 13328 batches: 0.7939\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 13396 batches: 0.7891\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 13464 batches: 0.7935\n",
      "Adjusting learning rate of group 0 to 2.0403e-06.\n",
      "Loss after 13532 batches: 0.7888\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 13600 batches: 0.7928\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 13668 batches: 0.7871\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 13736 batches: 0.7873\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 13804 batches: 0.7828\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 13872 batches: 0.7925\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 13940 batches: 0.7836\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 14008 batches: 0.7892\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 14076 batches: 0.7750\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 14144 batches: 0.7848\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 14212 batches: 0.7926\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 14280 batches: 0.7831\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 14348 batches: 0.7862\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 14416 batches: 0.7891\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 14484 batches: 0.7890\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 14552 batches: 0.7811\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 14620 batches: 0.7827\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 14688 batches: 0.7898\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 14756 batches: 0.7841\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 14824 batches: 0.7872\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 14892 batches: 0.7802\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 14960 batches: 0.7905\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 15028 batches: 0.7779\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 15096 batches: 0.7855\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 15164 batches: 0.7880\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 15232 batches: 0.7857\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 15300 batches: 0.7834\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 15368 batches: 0.7819\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 15436 batches: 0.7795\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 15504 batches: 0.7760\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 15572 batches: 0.7834\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 15640 batches: 0.7862\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 15708 batches: 0.7758\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 15776 batches: 0.7787\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 15844 batches: 0.7787\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 15912 batches: 0.7822\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 15980 batches: 0.7779\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 16048 batches: 0.7803\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 16116 batches: 0.7817\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 16184 batches: 0.7765\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 16252 batches: 0.7740\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 16320 batches: 0.7768\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 16388 batches: 0.7717\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 16456 batches: 0.7734\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 16524 batches: 0.7814\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 16592 batches: 0.7728\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 16660 batches: 0.7835\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 16728 batches: 0.7761\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 16796 batches: 0.7690\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 16864 batches: 0.7741\n",
      "Adjusting learning rate of group 0 to 1.8363e-06.\n",
      "Loss after 16932 batches: 0.7779\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 17000 batches: 0.7779\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 17068 batches: 0.7784\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 17136 batches: 0.7753\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 17204 batches: 0.7734\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 17272 batches: 0.7720\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 17340 batches: 0.7687\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 17408 batches: 0.7755\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 17476 batches: 0.7704\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 17544 batches: 0.7694\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 17612 batches: 0.7655\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 17680 batches: 0.7727\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 17748 batches: 0.7701\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 17816 batches: 0.7722\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 17884 batches: 0.7692\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 17952 batches: 0.7662\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 18020 batches: 0.7617\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 18088 batches: 0.7667\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 18156 batches: 0.7660\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 18224 batches: 0.7582\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 18292 batches: 0.7601\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 18360 batches: 0.7634\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 18428 batches: 0.7685\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 18496 batches: 0.7705\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 18564 batches: 0.7664\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 18632 batches: 0.7715\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 18700 batches: 0.7720\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 18768 batches: 0.7643\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 18836 batches: 0.7709\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 18904 batches: 0.7642\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 18972 batches: 0.7680\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 19040 batches: 0.7675\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 19108 batches: 0.7647\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 19176 batches: 0.7578\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 19244 batches: 0.7644\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 19312 batches: 0.7639\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 19380 batches: 0.7651\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 19448 batches: 0.7707\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 19516 batches: 0.7662\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 19584 batches: 0.7597\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 19652 batches: 0.7658\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 19720 batches: 0.7647\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 19788 batches: 0.7629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 19856 batches: 0.7596\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 19924 batches: 0.7632\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 19992 batches: 0.7564\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 20060 batches: 0.7618\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 20128 batches: 0.7566\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 20196 batches: 0.7604\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 20264 batches: 0.7597\n",
      "Adjusting learning rate of group 0 to 1.6527e-06.\n",
      "Loss after 20332 batches: 0.7580\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 20400 batches: 0.7538\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 20468 batches: 0.7637\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 20536 batches: 0.7529\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 20604 batches: 0.7596\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 20672 batches: 0.7576\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 20740 batches: 0.7599\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 20808 batches: 0.7501\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 20876 batches: 0.7539\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 20944 batches: 0.7541\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 21012 batches: 0.7599\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 21080 batches: 0.7519\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 21148 batches: 0.7479\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 21216 batches: 0.7608\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 21284 batches: 0.7598\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 21352 batches: 0.7546\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 21420 batches: 0.7567\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 21488 batches: 0.7537\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 21556 batches: 0.7516\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 21624 batches: 0.7596\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 21692 batches: 0.7487\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 21760 batches: 0.7509\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 21828 batches: 0.7590\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 21896 batches: 0.7516\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 21964 batches: 0.7560\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 22032 batches: 0.7467\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 22100 batches: 0.7549\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 22168 batches: 0.7518\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 22236 batches: 0.7529\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 22304 batches: 0.7613\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 22372 batches: 0.7526\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 22440 batches: 0.7488\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 22508 batches: 0.7521\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 22576 batches: 0.7493\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 22644 batches: 0.7501\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 22712 batches: 0.7465\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 22780 batches: 0.7496\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 22848 batches: 0.7513\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 22916 batches: 0.7478\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 22984 batches: 0.7485\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 23052 batches: 0.7546\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 23120 batches: 0.7473\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 23188 batches: 0.7442\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 23256 batches: 0.7498\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 23324 batches: 0.7424\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 23392 batches: 0.7486\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 23460 batches: 0.7461\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 23528 batches: 0.7429\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 23596 batches: 0.7515\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 23664 batches: 0.7505\n",
      "Adjusting learning rate of group 0 to 1.4874e-06.\n",
      "Loss after 23732 batches: 0.7454\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 23800 batches: 0.7473\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 23868 batches: 0.7420\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 23936 batches: 0.7492\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 24004 batches: 0.7481\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 24072 batches: 0.7430\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 24140 batches: 0.7461\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 24208 batches: 0.7443\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 24276 batches: 0.7486\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 24344 batches: 0.7451\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 24412 batches: 0.7430\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 24480 batches: 0.7398\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 24548 batches: 0.7449\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 24616 batches: 0.7386\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 24684 batches: 0.7354\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 24752 batches: 0.7396\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 24820 batches: 0.7410\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 24888 batches: 0.7419\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 24956 batches: 0.7376\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 25024 batches: 0.7455\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 25092 batches: 0.7375\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 25160 batches: 0.7467\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 25228 batches: 0.7425\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 25296 batches: 0.7357\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 25364 batches: 0.7394\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 25432 batches: 0.7483\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 25500 batches: 0.7344\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 25568 batches: 0.7440\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 25636 batches: 0.7467\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 25704 batches: 0.7419\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 25772 batches: 0.7419\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 25840 batches: 0.7411\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 25908 batches: 0.7326\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 25976 batches: 0.7405\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 26044 batches: 0.7393\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 26112 batches: 0.7354\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 26180 batches: 0.7323\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 26248 batches: 0.7318\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 26316 batches: 0.7345\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 26384 batches: 0.7389\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 26452 batches: 0.7392\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 26520 batches: 0.7341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 26588 batches: 0.7367\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 26656 batches: 0.7374\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 26724 batches: 0.7335\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 26792 batches: 0.7413\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 26860 batches: 0.7349\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 26928 batches: 0.7320\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 26996 batches: 0.7338\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 27064 batches: 0.7317\n",
      "Adjusting learning rate of group 0 to 1.3387e-06.\n",
      "Loss after 27132 batches: 0.7307\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 27200 batches: 0.7367\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 27268 batches: 0.7358\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 27336 batches: 0.7337\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 27404 batches: 0.7265\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 27472 batches: 0.7318\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 27540 batches: 0.7362\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 27608 batches: 0.7290\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 27676 batches: 0.7412\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 27744 batches: 0.7320\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 27812 batches: 0.7340\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 27880 batches: 0.7340\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 27948 batches: 0.7240\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 28016 batches: 0.7394\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 28084 batches: 0.7332\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 28152 batches: 0.7349\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 28220 batches: 0.7343\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 28288 batches: 0.7425\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 28356 batches: 0.7292\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 28424 batches: 0.7271\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 28492 batches: 0.7297\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 28560 batches: 0.7314\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 28628 batches: 0.7333\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 28696 batches: 0.7317\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 28764 batches: 0.7319\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 28832 batches: 0.7330\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 28900 batches: 0.7249\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 28968 batches: 0.7316\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 29036 batches: 0.7305\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 29104 batches: 0.7290\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 29172 batches: 0.7297\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 29240 batches: 0.7338\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 29308 batches: 0.7293\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 29376 batches: 0.7297\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 29444 batches: 0.7295\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 29512 batches: 0.7263\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 29580 batches: 0.7272\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 29648 batches: 0.7212\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 29716 batches: 0.7296\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 29784 batches: 0.7307\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 29852 batches: 0.7311\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 29920 batches: 0.7240\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 29988 batches: 0.7288\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 30056 batches: 0.7297\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 30124 batches: 0.7213\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 30192 batches: 0.7310\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 30260 batches: 0.7247\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 30328 batches: 0.7300\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 30396 batches: 0.7237\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 30464 batches: 0.7211\n",
      "Adjusting learning rate of group 0 to 1.2048e-06.\n",
      "Loss after 30532 batches: 0.7218\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 30600 batches: 0.7362\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 30668 batches: 0.7185\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 30736 batches: 0.7275\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 30804 batches: 0.7234\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 30872 batches: 0.7262\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 30940 batches: 0.7294\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 31008 batches: 0.7273\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 31076 batches: 0.7250\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 31144 batches: 0.7235\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 31212 batches: 0.7197\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 31280 batches: 0.7208\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 31348 batches: 0.7197\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 31416 batches: 0.7145\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 31484 batches: 0.7205\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 31552 batches: 0.7224\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 31620 batches: 0.7237\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 31688 batches: 0.7215\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 31756 batches: 0.7176\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 31824 batches: 0.7223\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 31892 batches: 0.7249\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 31960 batches: 0.7274\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 32028 batches: 0.7216\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 32096 batches: 0.7150\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 32164 batches: 0.7215\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 32232 batches: 0.7224\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 32300 batches: 0.7222\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 32368 batches: 0.7160\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 32436 batches: 0.7184\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 32504 batches: 0.7205\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 32572 batches: 0.7209\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 32640 batches: 0.7233\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 32708 batches: 0.7154\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 32776 batches: 0.7233\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 32844 batches: 0.7176\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 32912 batches: 0.7180\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 32980 batches: 0.7188\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 33048 batches: 0.7165\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 33116 batches: 0.7201\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 33184 batches: 0.7149\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 33252 batches: 0.7166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 33320 batches: 0.7176\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 33388 batches: 0.7159\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 33456 batches: 0.7179\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 33524 batches: 0.7170\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 33592 batches: 0.7156\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 33660 batches: 0.7200\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 33728 batches: 0.7171\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 33796 batches: 0.7096\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 33864 batches: 0.7193\n",
      "Adjusting learning rate of group 0 to 1.0843e-06.\n",
      "Loss after 33932 batches: 0.7179\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 34000 batches: 0.7133\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 34068 batches: 0.7187\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 34136 batches: 0.7126\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 34204 batches: 0.7126\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 34272 batches: 0.7145\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 34340 batches: 0.7104\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 34408 batches: 0.7162\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 34476 batches: 0.7096\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 34544 batches: 0.7192\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 34612 batches: 0.7139\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 34680 batches: 0.7143\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 34748 batches: 0.7152\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 34816 batches: 0.7166\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 34884 batches: 0.7170\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 34952 batches: 0.7157\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 35020 batches: 0.7145\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 35088 batches: 0.7207\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 35156 batches: 0.7139\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 35224 batches: 0.7130\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 35292 batches: 0.7075\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 35360 batches: 0.7164\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 35428 batches: 0.7096\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 35496 batches: 0.7098\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 35564 batches: 0.7098\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 35632 batches: 0.7085\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 35700 batches: 0.7177\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 35768 batches: 0.7108\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 35836 batches: 0.7171\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 35904 batches: 0.7067\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 35972 batches: 0.7057\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 36040 batches: 0.7091\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 36108 batches: 0.7026\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 36176 batches: 0.7091\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 36244 batches: 0.7141\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 36312 batches: 0.7127\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 36380 batches: 0.7113\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 36448 batches: 0.7027\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 36516 batches: 0.7105\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 36584 batches: 0.7072\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 36652 batches: 0.7016\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 36720 batches: 0.7103\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 36788 batches: 0.7104\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 36856 batches: 0.7085\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 36924 batches: 0.7124\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 36992 batches: 0.7051\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 37060 batches: 0.7148\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 37128 batches: 0.7070\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 37196 batches: 0.7141\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 37264 batches: 0.7060\n",
      "Adjusting learning rate of group 0 to 9.7588e-07.\n",
      "Loss after 37332 batches: 0.7068\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 37400 batches: 0.7108\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 37468 batches: 0.7108\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 37536 batches: 0.7077\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 37604 batches: 0.7108\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 37672 batches: 0.7031\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 37740 batches: 0.7095\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 37808 batches: 0.7036\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 37876 batches: 0.7016\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 37944 batches: 0.7066\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 38012 batches: 0.6990\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 38080 batches: 0.7051\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 38148 batches: 0.7008\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 38216 batches: 0.7003\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 38284 batches: 0.7050\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 38352 batches: 0.7081\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 38420 batches: 0.7001\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 38488 batches: 0.6998\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 38556 batches: 0.6965\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 38624 batches: 0.7039\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 38692 batches: 0.7059\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 38760 batches: 0.7035\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 38828 batches: 0.7019\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 38896 batches: 0.7070\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 38964 batches: 0.7039\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 39032 batches: 0.7086\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 39100 batches: 0.7071\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 39168 batches: 0.6957\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 39236 batches: 0.7023\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 39304 batches: 0.6970\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 39372 batches: 0.7021\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 39440 batches: 0.7093\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 39508 batches: 0.6997\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 39576 batches: 0.6987\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 39644 batches: 0.7068\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 39712 batches: 0.7001\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 39780 batches: 0.7066\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 39848 batches: 0.6997\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 39916 batches: 0.7045\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 39984 batches: 0.7031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 40052 batches: 0.7026\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 40120 batches: 0.6990\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 40188 batches: 0.7084\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 40256 batches: 0.6974\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 40324 batches: 0.7005\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 40392 batches: 0.6984\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 40460 batches: 0.7004\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 40528 batches: 0.7050\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 40596 batches: 0.7023\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 40664 batches: 0.7009\n",
      "Adjusting learning rate of group 0 to 8.7829e-07.\n",
      "Loss after 40732 batches: 0.6983\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 40800 batches: 0.6953\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 40868 batches: 0.7004\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 40936 batches: 0.6948\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 41004 batches: 0.7011\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 41072 batches: 0.6992\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 41140 batches: 0.6996\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 41208 batches: 0.6966\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 41276 batches: 0.6995\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 41344 batches: 0.6966\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 41412 batches: 0.6911\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 41480 batches: 0.6937\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 41548 batches: 0.6931\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 41616 batches: 0.7001\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 41684 batches: 0.6983\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 41752 batches: 0.7035\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 41820 batches: 0.6986\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 41888 batches: 0.6981\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 41956 batches: 0.6965\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 42024 batches: 0.7025\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 42092 batches: 0.6965\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 42160 batches: 0.6930\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 42228 batches: 0.6937\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 42296 batches: 0.6950\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 42364 batches: 0.6984\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 42432 batches: 0.6958\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 42500 batches: 0.6971\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 42568 batches: 0.6994\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 42636 batches: 0.7016\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 42704 batches: 0.6985\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 42772 batches: 0.6928\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 42840 batches: 0.7019\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 42908 batches: 0.6984\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 42976 batches: 0.6934\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 43044 batches: 0.6954\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 43112 batches: 0.6933\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 43180 batches: 0.7000\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 43248 batches: 0.6966\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 43316 batches: 0.6960\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 43384 batches: 0.6900\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 43452 batches: 0.6935\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 43520 batches: 0.6984\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 43588 batches: 0.6944\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 43656 batches: 0.6906\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 43724 batches: 0.6976\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 43792 batches: 0.6891\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 43860 batches: 0.6885\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 43928 batches: 0.6962\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 43996 batches: 0.6931\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 44064 batches: 0.6944\n",
      "Adjusting learning rate of group 0 to 7.9046e-07.\n",
      "Loss after 44132 batches: 0.6868\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 44200 batches: 0.6912\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 44268 batches: 0.6974\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 44336 batches: 0.6872\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 44404 batches: 0.6911\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 44472 batches: 0.6976\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 44540 batches: 0.6934\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 44608 batches: 0.6931\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 44676 batches: 0.6920\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 44744 batches: 0.6889\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 44812 batches: 0.6950\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 44880 batches: 0.6945\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 44948 batches: 0.6927\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 45016 batches: 0.6927\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 45084 batches: 0.6939\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 45152 batches: 0.6997\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 45220 batches: 0.6919\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 45288 batches: 0.6908\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 45356 batches: 0.6958\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 45424 batches: 0.6940\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 45492 batches: 0.6905\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 45560 batches: 0.6910\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 45628 batches: 0.6956\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 45696 batches: 0.6936\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 45764 batches: 0.6972\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 45832 batches: 0.6873\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 45900 batches: 0.6899\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 45968 batches: 0.6918\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 46036 batches: 0.6948\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 46104 batches: 0.6933\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 46172 batches: 0.6904\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 46240 batches: 0.6894\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 46308 batches: 0.6878\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 46376 batches: 0.6890\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 46444 batches: 0.6852\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 46512 batches: 0.6884\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 46580 batches: 0.6916\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 46648 batches: 0.6859\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 46716 batches: 0.6910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 46784 batches: 0.6896\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 46852 batches: 0.6913\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 46920 batches: 0.6911\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 46988 batches: 0.6875\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 47056 batches: 0.6928\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 47124 batches: 0.6911\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 47192 batches: 0.6847\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 47260 batches: 0.6893\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 47328 batches: 0.6885\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 47396 batches: 0.6872\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 47464 batches: 0.6955\n",
      "Adjusting learning rate of group 0 to 7.1141e-07.\n",
      "Loss after 47532 batches: 0.6840\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 47600 batches: 0.6952\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 47668 batches: 0.6910\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 47736 batches: 0.6854\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 47804 batches: 0.6913\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 47872 batches: 0.6876\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 47940 batches: 0.6841\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 48008 batches: 0.6810\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 48076 batches: 0.6814\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 48144 batches: 0.6858\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 48212 batches: 0.6899\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 48280 batches: 0.6842\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 48348 batches: 0.6872\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 48416 batches: 0.6892\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 48484 batches: 0.6824\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 48552 batches: 0.6858\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 48620 batches: 0.6819\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 48688 batches: 0.6840\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 48756 batches: 0.6906\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 48824 batches: 0.6839\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 48892 batches: 0.6906\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 48960 batches: 0.6869\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 49028 batches: 0.6918\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 49096 batches: 0.6849\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 49164 batches: 0.6822\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 49232 batches: 0.6869\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 49300 batches: 0.6845\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 49368 batches: 0.6864\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 49436 batches: 0.6865\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 49504 batches: 0.6844\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 49572 batches: 0.6845\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 49640 batches: 0.6866\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 49708 batches: 0.6878\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 49776 batches: 0.6873\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 49844 batches: 0.6787\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 49912 batches: 0.6785\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 49980 batches: 0.6880\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 50048 batches: 0.6978\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 50116 batches: 0.6864\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 50184 batches: 0.6806\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 50252 batches: 0.6796\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 50320 batches: 0.6813\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 50388 batches: 0.6824\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 50456 batches: 0.6820\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 50524 batches: 0.6827\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 50592 batches: 0.6887\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 50660 batches: 0.6883\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 50728 batches: 0.6827\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 50796 batches: 0.6826\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 50864 batches: 0.6809\n",
      "Adjusting learning rate of group 0 to 6.4027e-07.\n",
      "Loss after 50932 batches: 0.6844\n",
      "Adjusting learning rate of group 0 to 5.7625e-07.\n",
      "Loss after 51000 batches: 0.6830\n",
      "Time to train on one home:  463.6048095226288\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 30276<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\wandb\\run-20211119_183859-18io9ayo\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\wandb\\run-20211119_183859-18io9ayo\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_F1_Score</td><td>4.31885</td></tr><tr><td>Test_MAE</td><td>139.7107</td></tr><tr><td>Test_MSE</td><td>0.72439</td></tr><tr><td>Test_NDE</td><td>2.63913</td></tr><tr><td>Test_NEP</td><td>2.73657</td></tr><tr><td>Test_R2_Value</td><td>-3.6736</td></tr><tr><td>Training_F1</td><td>9.60344</td></tr><tr><td>Training_MAE</td><td>133.64201</td></tr><tr><td>Training_MSE</td><td>0.68296</td></tr><tr><td>Training_NDE</td><td>2.37991</td></tr><tr><td>Training_NEP</td><td>2.02892</td></tr><tr><td>Training_R2</td><td>-2.8391</td></tr><tr><td>Validation_F1</td><td>2.42775</td></tr><tr><td>Validation_MAE</td><td>102.21282</td></tr><tr><td>Validation_MSE</td><td>0.42111</td></tr><tr><td>Validation_NDE</td><td>2.87922</td></tr><tr><td>Validation_NEP</td><td>3.22516</td></tr><tr><td>Validation_R2</td><td>-2.9004</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_F1_Score</td><td>▁</td></tr><tr><td>Test_MAE</td><td>▁</td></tr><tr><td>Test_MSE</td><td>▁</td></tr><tr><td>Test_NDE</td><td>▁</td></tr><tr><td>Test_NEP</td><td>▁</td></tr><tr><td>Test_R2_Value</td><td>▁</td></tr><tr><td>Training_F1</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇█▇█▇▇████</td></tr><tr><td>Training_MAE</td><td>███▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁</td></tr><tr><td>Training_MSE</td><td>██▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Training_NDE</td><td>██▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Training_NEP</td><td>███▇▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁</td></tr><tr><td>Training_R2</td><td>▁▁▁▂▃▂▃▂▃▄▄▄▄▅▅▆▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇█▇███████</td></tr><tr><td>Validation_F1</td><td>▁▁▁▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████</td></tr><tr><td>Validation_MAE</td><td>██▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation_MSE</td><td>██▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Validation_NDE</td><td>██▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation_NEP</td><td>██▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation_R2</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██████</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">fearless-sound-487</strong>: <a href=\"https://wandb.ai/nilm/Drye1_single_houses/runs/18io9ayo\" target=\"_blank\">https://wandb.ai/nilm/Drye1_single_houses/runs/18io9ayo</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-19 18:48:11,555]\u001b[0m Trial 0 finished with value: 0.7243872880935669 and parameters: {'hidden_size_1': 44, 'hidden_size_2': 341, 'fc1': 183, 'fc2': 12, 'weight_decay': 0.015297422609112233, 'learning_rate': 2.7987903204164326e-06, 'window_size': 186}. Best is trial 0 with value: 0.7243872880935669.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">comfy-pond-488</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nilm/Drye1_single_houses\" target=\"_blank\">https://wandb.ai/nilm/Drye1_single_houses</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/nilm/Drye1_single_houses/runs/25bwjamm\" target=\"_blank\">https://wandb.ai/nilm/Drye1_single_houses/runs/25bwjamm</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\wandb\\run-20211119_184811-25bwjamm</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (conv1): Conv1d(1, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "  (lstm1): LSTM(16, 111, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (lstm2): LSTM(222, 149, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (linear1): Linear(in_features=298, out_features=422, bias=True)\n",
      "  (linear2): Linear(in_features=422, out_features=22, bias=True)\n",
      "  (linear3): Linear(in_features=22, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 00084 batches: 0.2727\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 00168 batches: 0.2678\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 00252 batches: 0.2703\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 00336 batches: 0.2747\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 00420 batches: 0.2670\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 00504 batches: 0.2649\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 00588 batches: 0.2692\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 00672 batches: 0.2666\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 00756 batches: 0.2661\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 00840 batches: 0.2631\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 00924 batches: 0.2644\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 01008 batches: 0.2615\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 01092 batches: 0.2637\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 01176 batches: 0.2606\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 01260 batches: 0.2620\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 01344 batches: 0.2631\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 01428 batches: 0.2582\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 01512 batches: 0.2589\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 01596 batches: 0.2587\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 01680 batches: 0.2585\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 01764 batches: 0.2567\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 01848 batches: 0.2536\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 01932 batches: 0.2578\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 02016 batches: 0.2605\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 02100 batches: 0.2567\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 02184 batches: 0.2535\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 02268 batches: 0.2532\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 02352 batches: 0.2509\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 02436 batches: 0.2513\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 02520 batches: 0.2514\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 02604 batches: 0.2499\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 02688 batches: 0.2446\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 02772 batches: 0.2474\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 02856 batches: 0.2446\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 02940 batches: 0.2483\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 03024 batches: 0.2504\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 03108 batches: 0.2454\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 03192 batches: 0.2455\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 03276 batches: 0.2488\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 03360 batches: 0.2459\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 03444 batches: 0.2529\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 03528 batches: 0.2463\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 03612 batches: 0.2454\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 03696 batches: 0.2427\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 03780 batches: 0.2429\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 03864 batches: 0.2409\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 03948 batches: 0.2465\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 04032 batches: 0.2422\n",
      "Adjusting learning rate of group 0 to 1.6077e-05.\n",
      "Loss after 04116 batches: 0.2478\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 04200 batches: 0.2456\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 04284 batches: 0.2467\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 04368 batches: 0.2461\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 04452 batches: 0.2437\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 04536 batches: 0.2435\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 04620 batches: 0.2394\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 04704 batches: 0.2445\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 04788 batches: 0.2407\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 04872 batches: 0.2413\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 04956 batches: 0.2366\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 05040 batches: 0.2442\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 05124 batches: 0.2399\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 05208 batches: 0.2371\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 05292 batches: 0.2416\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 05376 batches: 0.2456\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 05460 batches: 0.2340\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 05544 batches: 0.2383\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 05628 batches: 0.2398\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 05712 batches: 0.2374\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 05796 batches: 0.2400\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 05880 batches: 0.2369\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 05964 batches: 0.2394\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 06048 batches: 0.2352\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 06132 batches: 0.2357\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 06216 batches: 0.2361\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 06300 batches: 0.2371\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 06384 batches: 0.2356\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 06468 batches: 0.2351\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 06552 batches: 0.2347\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 06636 batches: 0.2314\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 06720 batches: 0.2334\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 06804 batches: 0.2348\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 06888 batches: 0.2343\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 06972 batches: 0.2372\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 07056 batches: 0.2329\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 07140 batches: 0.2371\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 07224 batches: 0.2329\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 07308 batches: 0.2312\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 07392 batches: 0.2354\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 07476 batches: 0.2377\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 07560 batches: 0.2355\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 07644 batches: 0.2377\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 07728 batches: 0.2314\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 07812 batches: 0.2308\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 07896 batches: 0.2285\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 07980 batches: 0.2268\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 08064 batches: 0.2339\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 08148 batches: 0.2260\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 08232 batches: 0.2292\n",
      "Adjusting learning rate of group 0 to 1.4470e-05.\n",
      "Loss after 08316 batches: 0.2270\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 08400 batches: 0.2278\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 08484 batches: 0.2285\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 08568 batches: 0.2308\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 08652 batches: 0.2327\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 08736 batches: 0.2266\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 08820 batches: 0.2283\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 08904 batches: 0.2303\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 08988 batches: 0.2327\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 09072 batches: 0.2233\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 09156 batches: 0.2256\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 09240 batches: 0.2277\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 09324 batches: 0.2249\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 09408 batches: 0.2292\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 09492 batches: 0.2294\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 09576 batches: 0.2276\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 09660 batches: 0.2238\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 09744 batches: 0.2258\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 09828 batches: 0.2269\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 09912 batches: 0.2258\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 09996 batches: 0.2230\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 10080 batches: 0.2207\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 10164 batches: 0.2257\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 10248 batches: 0.2228\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 10332 batches: 0.2259\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 10416 batches: 0.2264\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 10500 batches: 0.2225\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 10584 batches: 0.2228\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 10668 batches: 0.2263\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 10752 batches: 0.2242\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 10836 batches: 0.2262\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 10920 batches: 0.2186\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 11004 batches: 0.2205\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 11088 batches: 0.2249\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 11172 batches: 0.2206\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 11256 batches: 0.2214\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 11340 batches: 0.2237\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 11424 batches: 0.2184\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 11508 batches: 0.2243\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 11592 batches: 0.2198\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 11676 batches: 0.2178\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 11760 batches: 0.2133\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 11844 batches: 0.2233\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 11928 batches: 0.2182\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 12012 batches: 0.2185\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 12096 batches: 0.2147\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 12180 batches: 0.2217\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 12264 batches: 0.2209\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 12348 batches: 0.2245\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 12432 batches: 0.2179\n",
      "Adjusting learning rate of group 0 to 1.3023e-05.\n",
      "Loss after 12516 batches: 0.2190\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 12600 batches: 0.2152\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 12684 batches: 0.2160\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 12768 batches: 0.2175\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 12852 batches: 0.2168\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 12936 batches: 0.2147\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 13020 batches: 0.2183\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 13104 batches: 0.2115\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 13188 batches: 0.2167\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 13272 batches: 0.2209\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 13356 batches: 0.2123\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 13440 batches: 0.2158\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 13524 batches: 0.2119\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 13608 batches: 0.2177\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 13692 batches: 0.2152\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 13776 batches: 0.2138\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 13860 batches: 0.2192\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 13944 batches: 0.2186\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 14028 batches: 0.2151\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 14112 batches: 0.2103\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 14196 batches: 0.2163\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 14280 batches: 0.2125\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 14364 batches: 0.2155\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 14448 batches: 0.2158\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 14532 batches: 0.2198\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 14616 batches: 0.2122\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 14700 batches: 0.2111\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 14784 batches: 0.2129\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 14868 batches: 0.2122\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 14952 batches: 0.2115\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 15036 batches: 0.2113\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 15120 batches: 0.2130\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 15204 batches: 0.2150\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 15288 batches: 0.2118\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 15372 batches: 0.2138\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 15456 batches: 0.2111\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 15540 batches: 0.2153\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 15624 batches: 0.2130\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 15708 batches: 0.2112\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 15792 batches: 0.2111\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 15876 batches: 0.2096\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 15960 batches: 0.2053\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 16044 batches: 0.2128\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 16128 batches: 0.2108\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 16212 batches: 0.2079\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 16296 batches: 0.2105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 16380 batches: 0.2145\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 16464 batches: 0.2127\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 16548 batches: 0.2116\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 16632 batches: 0.2074\n",
      "Adjusting learning rate of group 0 to 1.1720e-05.\n",
      "Loss after 16716 batches: 0.2070\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 16800 batches: 0.2082\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 16884 batches: 0.2131\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 16968 batches: 0.2044\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 17052 batches: 0.2078\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 17136 batches: 0.2082\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 17220 batches: 0.2108\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 17304 batches: 0.2053\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 17388 batches: 0.2069\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 17472 batches: 0.2044\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 17556 batches: 0.2079\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 17640 batches: 0.2073\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 17724 batches: 0.2061\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 17808 batches: 0.2092\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 17892 batches: 0.2049\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 17976 batches: 0.2071\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 18060 batches: 0.2059\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 18144 batches: 0.2040\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 18228 batches: 0.2057\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 18312 batches: 0.2091\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 18396 batches: 0.2057\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 18480 batches: 0.2050\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 18564 batches: 0.2084\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 18648 batches: 0.2056\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 18732 batches: 0.2078\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 18816 batches: 0.2067\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 18900 batches: 0.2070\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 18984 batches: 0.2065\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 19068 batches: 0.2044\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 19152 batches: 0.2066\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 19236 batches: 0.2056\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 19320 batches: 0.2017\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 19404 batches: 0.2057\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 19488 batches: 0.2061\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 19572 batches: 0.2044\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 19656 batches: 0.2023\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 19740 batches: 0.2023\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 19824 batches: 0.2045\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 19908 batches: 0.2046\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 19992 batches: 0.2033\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 20076 batches: 0.2027\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 20160 batches: 0.2037\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 20244 batches: 0.2011\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 20328 batches: 0.2037\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 20412 batches: 0.2020\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 20496 batches: 0.2026\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 20580 batches: 0.2037\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 20664 batches: 0.2008\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 20748 batches: 0.2034\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 20832 batches: 0.2015\n",
      "Adjusting learning rate of group 0 to 1.0548e-05.\n",
      "Loss after 20916 batches: 0.2020\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 21000 batches: 0.1996\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 21084 batches: 0.2019\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 21168 batches: 0.2051\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 21252 batches: 0.1997\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 21336 batches: 0.2016\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 21420 batches: 0.2006\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 21504 batches: 0.2021\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 21588 batches: 0.1978\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 21672 batches: 0.2034\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 21756 batches: 0.2056\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 21840 batches: 0.2033\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 21924 batches: 0.1992\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 22008 batches: 0.1998\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 22092 batches: 0.1995\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 22176 batches: 0.1997\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 22260 batches: 0.2030\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 22344 batches: 0.1967\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 22428 batches: 0.2008\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 22512 batches: 0.2015\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 22596 batches: 0.1982\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 22680 batches: 0.2026\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 22764 batches: 0.2023\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 22848 batches: 0.1980\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 22932 batches: 0.1998\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 23016 batches: 0.1987\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 23100 batches: 0.1999\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 23184 batches: 0.1936\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 23268 batches: 0.1960\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 23352 batches: 0.1964\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 23436 batches: 0.1989\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 23520 batches: 0.1991\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 23604 batches: 0.1993\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 23688 batches: 0.1979\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 23772 batches: 0.1987\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 23856 batches: 0.1964\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 23940 batches: 0.1958\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 24024 batches: 0.1977\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 24108 batches: 0.1978\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 24192 batches: 0.1961\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 24276 batches: 0.1962\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 24360 batches: 0.1935\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 24444 batches: 0.1953\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 24528 batches: 0.2002\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 24612 batches: 0.1962\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 24696 batches: 0.1932\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 24780 batches: 0.1930\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 24864 batches: 0.1955\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 24948 batches: 0.1951\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 25032 batches: 0.1972\n",
      "Adjusting learning rate of group 0 to 9.4935e-06.\n",
      "Loss after 25116 batches: 0.1967\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 25200 batches: 0.1960\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 25284 batches: 0.1958\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 25368 batches: 0.1971\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 25452 batches: 0.1953\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 25536 batches: 0.1939\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 25620 batches: 0.1952\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 25704 batches: 0.1955\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 25788 batches: 0.1924\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 25872 batches: 0.1976\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 25956 batches: 0.1938\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 26040 batches: 0.1941\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 26124 batches: 0.1962\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 26208 batches: 0.1944\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 26292 batches: 0.1992\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 26376 batches: 0.1926\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 26460 batches: 0.1947\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 26544 batches: 0.1945\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 26628 batches: 0.1910\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 26712 batches: 0.1888\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 26796 batches: 0.1962\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 26880 batches: 0.1959\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 26964 batches: 0.1934\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 27048 batches: 0.1913\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 27132 batches: 0.1930\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 27216 batches: 0.1930\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 27300 batches: 0.1942\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 27384 batches: 0.1926\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 27468 batches: 0.1923\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 27552 batches: 0.1933\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 27636 batches: 0.1978\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 27720 batches: 0.1908\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 27804 batches: 0.1949\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 27888 batches: 0.1950\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 27972 batches: 0.1902\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 28056 batches: 0.1924\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 28140 batches: 0.1937\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 28224 batches: 0.1876\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 28308 batches: 0.1898\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 28392 batches: 0.1891\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 28476 batches: 0.1925\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 28560 batches: 0.1902\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 28644 batches: 0.1926\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 28728 batches: 0.1911\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 28812 batches: 0.1904\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 28896 batches: 0.1930\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 28980 batches: 0.1912\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 29064 batches: 0.1911\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 29148 batches: 0.1898\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 29232 batches: 0.1900\n",
      "Adjusting learning rate of group 0 to 8.5442e-06.\n",
      "Loss after 29316 batches: 0.1907\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 29400 batches: 0.1900\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 29484 batches: 0.1893\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 29568 batches: 0.1904\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 29652 batches: 0.1894\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 29736 batches: 0.1922\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 29820 batches: 0.1921\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 29904 batches: 0.1898\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 29988 batches: 0.1893\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 30072 batches: 0.1881\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 30156 batches: 0.1908\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 30240 batches: 0.1895\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 30324 batches: 0.1857\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 30408 batches: 0.1897\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 30492 batches: 0.1894\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 30576 batches: 0.1876\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 30660 batches: 0.1931\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 30744 batches: 0.1902\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 30828 batches: 0.1903\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 30912 batches: 0.1863\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 30996 batches: 0.1908\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 31080 batches: 0.1880\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 31164 batches: 0.1918\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 31248 batches: 0.1869\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 31332 batches: 0.1902\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 31416 batches: 0.1907\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 31500 batches: 0.1896\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 31584 batches: 0.1877\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 31668 batches: 0.1882\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 31752 batches: 0.1918\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 31836 batches: 0.1920\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 31920 batches: 0.1897\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 32004 batches: 0.1883\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 32088 batches: 0.1891\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 32172 batches: 0.1850\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 32256 batches: 0.1850\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 32340 batches: 0.1907\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 32424 batches: 0.1891\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 32508 batches: 0.1859\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 32592 batches: 0.1905\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 32676 batches: 0.1882\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 32760 batches: 0.1896\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 32844 batches: 0.1870\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 32928 batches: 0.1847\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 33012 batches: 0.1887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 33096 batches: 0.1859\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 33180 batches: 0.1822\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 33264 batches: 0.1868\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 33348 batches: 0.1878\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 33432 batches: 0.1864\n",
      "Adjusting learning rate of group 0 to 7.6898e-06.\n",
      "Loss after 33516 batches: 0.1873\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 33600 batches: 0.1846\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 33684 batches: 0.1900\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 33768 batches: 0.1840\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 33852 batches: 0.1844\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 33936 batches: 0.1863\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 34020 batches: 0.1869\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 34104 batches: 0.1852\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 34188 batches: 0.1854\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 34272 batches: 0.1856\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 34356 batches: 0.1861\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 34440 batches: 0.1852\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 34524 batches: 0.1832\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 34608 batches: 0.1869\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 34692 batches: 0.1853\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 34776 batches: 0.1842\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 34860 batches: 0.1846\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 34944 batches: 0.1836\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 35028 batches: 0.1868\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 35112 batches: 0.1849\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 35196 batches: 0.1857\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 35280 batches: 0.1855\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 35364 batches: 0.1844\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 35448 batches: 0.1828\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 35532 batches: 0.1863\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 35616 batches: 0.1836\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 35700 batches: 0.1855\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 35784 batches: 0.1839\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 35868 batches: 0.1851\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 35952 batches: 0.1878\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 36036 batches: 0.1834\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 36120 batches: 0.1841\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 36204 batches: 0.1830\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 36288 batches: 0.1802\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 36372 batches: 0.1831\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 36456 batches: 0.1850\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 36540 batches: 0.1859\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 36624 batches: 0.1851\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 36708 batches: 0.1878\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 36792 batches: 0.1831\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 36876 batches: 0.1851\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 36960 batches: 0.1833\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 37044 batches: 0.1824\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 37128 batches: 0.1841\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 37212 batches: 0.1833\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 37296 batches: 0.1854\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 37380 batches: 0.1852\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 37464 batches: 0.1860\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 37548 batches: 0.1847\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 37632 batches: 0.1861\n",
      "Adjusting learning rate of group 0 to 6.9208e-06.\n",
      "Loss after 37716 batches: 0.1798\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 37800 batches: 0.1838\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 37884 batches: 0.1857\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 37968 batches: 0.1838\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 38052 batches: 0.1828\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 38136 batches: 0.1846\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 38220 batches: 0.1801\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 38304 batches: 0.1828\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 38388 batches: 0.1829\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 38472 batches: 0.1832\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 38556 batches: 0.1862\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 38640 batches: 0.1797\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 38724 batches: 0.1808\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 38808 batches: 0.1817\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 38892 batches: 0.1833\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 38976 batches: 0.1843\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 39060 batches: 0.1795\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 39144 batches: 0.1782\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 39228 batches: 0.1814\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 39312 batches: 0.1837\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 39396 batches: 0.1820\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 39480 batches: 0.1822\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 39564 batches: 0.1828\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 39648 batches: 0.1838\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 39732 batches: 0.1825\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 39816 batches: 0.1839\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 39900 batches: 0.1837\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 39984 batches: 0.1818\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 40068 batches: 0.1793\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 40152 batches: 0.1796\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 40236 batches: 0.1826\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 40320 batches: 0.1814\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 40404 batches: 0.1816\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 40488 batches: 0.1809\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 40572 batches: 0.1803\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 40656 batches: 0.1804\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 40740 batches: 0.1795\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 40824 batches: 0.1828\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 40908 batches: 0.1787\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 40992 batches: 0.1827\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 41076 batches: 0.1816\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 41160 batches: 0.1781\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 41244 batches: 0.1841\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 41328 batches: 0.1791\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 41412 batches: 0.1793\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 41496 batches: 0.1791\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 41580 batches: 0.1841\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 41664 batches: 0.1798\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 41748 batches: 0.1789\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 41832 batches: 0.1788\n",
      "Adjusting learning rate of group 0 to 6.2287e-06.\n",
      "Loss after 41916 batches: 0.1807\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 42000 batches: 0.1787\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 42084 batches: 0.1820\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 42168 batches: 0.1793\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 42252 batches: 0.1774\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 42336 batches: 0.1806\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 42420 batches: 0.1797\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 42504 batches: 0.1767\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 42588 batches: 0.1802\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 42672 batches: 0.1813\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 42756 batches: 0.1790\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 42840 batches: 0.1777\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 42924 batches: 0.1825\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 43008 batches: 0.1775\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 43092 batches: 0.1789\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 43176 batches: 0.1816\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 43260 batches: 0.1802\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 43344 batches: 0.1781\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 43428 batches: 0.1804\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 43512 batches: 0.1783\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 43596 batches: 0.1792\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 43680 batches: 0.1832\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 43764 batches: 0.1774\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 43848 batches: 0.1786\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 43932 batches: 0.1820\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 44016 batches: 0.1817\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 44100 batches: 0.1777\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 44184 batches: 0.1813\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 44268 batches: 0.1787\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 44352 batches: 0.1796\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 44436 batches: 0.1807\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 44520 batches: 0.1781\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 44604 batches: 0.1795\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 44688 batches: 0.1783\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 44772 batches: 0.1786\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 44856 batches: 0.1792\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 44940 batches: 0.1748\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 45024 batches: 0.1797\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 45108 batches: 0.1801\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 45192 batches: 0.1790\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 45276 batches: 0.1804\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 45360 batches: 0.1789\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 45444 batches: 0.1773\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 45528 batches: 0.1792\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 45612 batches: 0.1778\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 45696 batches: 0.1803\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 45780 batches: 0.1757\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 45864 batches: 0.1783\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 45948 batches: 0.1789\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 46032 batches: 0.1768\n",
      "Adjusting learning rate of group 0 to 5.6058e-06.\n",
      "Loss after 46116 batches: 0.1772\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 46200 batches: 0.1781\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 46284 batches: 0.1779\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 46368 batches: 0.1772\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 46452 batches: 0.1770\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 46536 batches: 0.1746\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 46620 batches: 0.1756\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 46704 batches: 0.1755\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 46788 batches: 0.1752\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 46872 batches: 0.1777\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 46956 batches: 0.1761\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 47040 batches: 0.1792\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 47124 batches: 0.1755\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 47208 batches: 0.1746\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 47292 batches: 0.1776\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 47376 batches: 0.1769\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 47460 batches: 0.1755\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 47544 batches: 0.1763\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 47628 batches: 0.1756\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 47712 batches: 0.1778\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 47796 batches: 0.1745\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 47880 batches: 0.1767\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 47964 batches: 0.1783\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 48048 batches: 0.1774\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 48132 batches: 0.1759\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 48216 batches: 0.1752\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 48300 batches: 0.1768\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 48384 batches: 0.1795\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 48468 batches: 0.1773\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 48552 batches: 0.1770\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 48636 batches: 0.1784\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 48720 batches: 0.1758\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 48804 batches: 0.1756\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 48888 batches: 0.1783\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 48972 batches: 0.1776\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 49056 batches: 0.1726\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 49140 batches: 0.1749\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 49224 batches: 0.1787\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 49308 batches: 0.1778\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 49392 batches: 0.1778\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 49476 batches: 0.1786\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 49560 batches: 0.1761\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 49644 batches: 0.1759\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 49728 batches: 0.1756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 49812 batches: 0.1766\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 49896 batches: 0.1742\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 49980 batches: 0.1760\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 50064 batches: 0.1755\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 50148 batches: 0.1741\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 50232 batches: 0.1741\n",
      "Adjusting learning rate of group 0 to 5.0453e-06.\n",
      "Loss after 50316 batches: 0.1749\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 50400 batches: 0.1766\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 50484 batches: 0.1769\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 50568 batches: 0.1741\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 50652 batches: 0.1757\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 50736 batches: 0.1758\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 50820 batches: 0.1767\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 50904 batches: 0.1757\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 50988 batches: 0.1766\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 51072 batches: 0.1726\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 51156 batches: 0.1746\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 51240 batches: 0.1746\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 51324 batches: 0.1732\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 51408 batches: 0.1743\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 51492 batches: 0.1771\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 51576 batches: 0.1733\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 51660 batches: 0.1753\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 51744 batches: 0.1712\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 51828 batches: 0.1713\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 51912 batches: 0.1748\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 51996 batches: 0.1721\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 52080 batches: 0.1777\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 52164 batches: 0.1764\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 52248 batches: 0.1759\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 52332 batches: 0.1759\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 52416 batches: 0.1737\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 52500 batches: 0.1716\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 52584 batches: 0.1747\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 52668 batches: 0.1732\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 52752 batches: 0.1730\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 52836 batches: 0.1763\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 52920 batches: 0.1763\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 53004 batches: 0.1711\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 53088 batches: 0.1722\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 53172 batches: 0.1737\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 53256 batches: 0.1706\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 53340 batches: 0.1745\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 53424 batches: 0.1742\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 53508 batches: 0.1741\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 53592 batches: 0.1749\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 53676 batches: 0.1744\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 53760 batches: 0.1738\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 53844 batches: 0.1739\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 53928 batches: 0.1729\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 54012 batches: 0.1733\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 54096 batches: 0.1740\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 54180 batches: 0.1749\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 54264 batches: 0.1722\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 54348 batches: 0.1750\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 54432 batches: 0.1731\n",
      "Adjusting learning rate of group 0 to 4.5407e-06.\n",
      "Loss after 54516 batches: 0.1740\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 54600 batches: 0.1739\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 54684 batches: 0.1737\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 54768 batches: 0.1728\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 54852 batches: 0.1719\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 54936 batches: 0.1737\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 55020 batches: 0.1747\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 55104 batches: 0.1710\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 55188 batches: 0.1724\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 55272 batches: 0.1723\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 55356 batches: 0.1686\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 55440 batches: 0.1752\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 55524 batches: 0.1719\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 55608 batches: 0.1710\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 55692 batches: 0.1732\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 55776 batches: 0.1708\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 55860 batches: 0.1707\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 55944 batches: 0.1728\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 56028 batches: 0.1724\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 56112 batches: 0.1711\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 56196 batches: 0.1695\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 56280 batches: 0.1703\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 56364 batches: 0.1703\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 56448 batches: 0.1685\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 56532 batches: 0.1711\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 56616 batches: 0.1719\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 56700 batches: 0.1731\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 56784 batches: 0.1746\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 56868 batches: 0.1748\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 56952 batches: 0.1728\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 57036 batches: 0.1729\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 57120 batches: 0.1723\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 57204 batches: 0.1728\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 57288 batches: 0.1720\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 57372 batches: 0.1732\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 57456 batches: 0.1686\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 57540 batches: 0.1714\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 57624 batches: 0.1740\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 57708 batches: 0.1708\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 57792 batches: 0.1709\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 57876 batches: 0.1724\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 57960 batches: 0.1703\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 58044 batches: 0.1736\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 58128 batches: 0.1697\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 58212 batches: 0.1725\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 58296 batches: 0.1718\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 58380 batches: 0.1699\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 58464 batches: 0.1683\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 58548 batches: 0.1720\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 58632 batches: 0.1714\n",
      "Adjusting learning rate of group 0 to 4.0867e-06.\n",
      "Loss after 58716 batches: 0.1707\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 58800 batches: 0.1727\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 58884 batches: 0.1694\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 58968 batches: 0.1738\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 59052 batches: 0.1721\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 59136 batches: 0.1696\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 59220 batches: 0.1708\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 59304 batches: 0.1732\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 59388 batches: 0.1731\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 59472 batches: 0.1701\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 59556 batches: 0.1707\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 59640 batches: 0.1716\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 59724 batches: 0.1716\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 59808 batches: 0.1739\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 59892 batches: 0.1692\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 59976 batches: 0.1719\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 60060 batches: 0.1691\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 60144 batches: 0.1706\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 60228 batches: 0.1707\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 60312 batches: 0.1728\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 60396 batches: 0.1713\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 60480 batches: 0.1686\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 60564 batches: 0.1705\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 60648 batches: 0.1757\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 60732 batches: 0.1718\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 60816 batches: 0.1688\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 60900 batches: 0.1689\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 60984 batches: 0.1706\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 61068 batches: 0.1739\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 61152 batches: 0.1694\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 61236 batches: 0.1703\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 61320 batches: 0.1714\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 61404 batches: 0.1694\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 61488 batches: 0.1713\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 61572 batches: 0.1695\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 61656 batches: 0.1692\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 61740 batches: 0.1690\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 61824 batches: 0.1690\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 61908 batches: 0.1689\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 61992 batches: 0.1727\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 62076 batches: 0.1714\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 62160 batches: 0.1667\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 62244 batches: 0.1684\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 62328 batches: 0.1683\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 62412 batches: 0.1679\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 62496 batches: 0.1735\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 62580 batches: 0.1707\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 62664 batches: 0.1661\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 62748 batches: 0.1722\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 62832 batches: 0.1691\n",
      "Adjusting learning rate of group 0 to 3.6780e-06.\n",
      "Loss after 62916 batches: 0.1688\n",
      "Adjusting learning rate of group 0 to 3.3102e-06.\n",
      "Loss after 63000 batches: 0.1692\n",
      "Time to train on one home:  171.1542203426361\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 35820<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\wandb\\run-20211119_184811-25bwjamm\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\wandb\\run-20211119_184811-25bwjamm\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_F1_Score</td><td>0.45673</td></tr><tr><td>Test_MAE</td><td>34.08388</td></tr><tr><td>Test_MSE</td><td>0.17984</td></tr><tr><td>Test_NDE</td><td>0.43492</td></tr><tr><td>Test_NEP</td><td>0.96972</td></tr><tr><td>Test_R2_Value</td><td>-0.2066</td></tr><tr><td>Training_F1</td><td>0.44911</td></tr><tr><td>Training_MAE</td><td>46.72343</td></tr><tr><td>Training_MSE</td><td>0.16921</td></tr><tr><td>Training_NDE</td><td>0.89737</td></tr><tr><td>Training_NEP</td><td>0.98231</td></tr><tr><td>Training_R2</td><td>-0.50322</td></tr><tr><td>Validation_F1</td><td>0.4162</td></tr><tr><td>Validation_MAE</td><td>55.17802</td></tr><tr><td>Validation_MSE</td><td>0.18065</td></tr><tr><td>Validation_NDE</td><td>0.78484</td></tr><tr><td>Validation_NEP</td><td>0.92407</td></tr><tr><td>Validation_R2</td><td>-0.66518</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_F1_Score</td><td>▁</td></tr><tr><td>Test_MAE</td><td>▁</td></tr><tr><td>Test_MSE</td><td>▁</td></tr><tr><td>Test_NDE</td><td>▁</td></tr><tr><td>Test_NEP</td><td>▁</td></tr><tr><td>Test_R2_Value</td><td>▁</td></tr><tr><td>Training_F1</td><td>▁▃▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>Training_MAE</td><td>▇█▇█▇▇▆▅▆▅▅▄▄▄▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▂</td></tr><tr><td>Training_MSE</td><td>██▇▇▆▆▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Training_NDE</td><td>██▇▇▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Training_NEP</td><td>▇█▇█▇▇▆▅▆▅▅▄▄▄▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▂</td></tr><tr><td>Training_R2</td><td>▁▂▁▂▃▃▃▄▄▅▄▅▅▅▆▆▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇███████</td></tr><tr><td>Validation_F1</td><td>▁▄▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>Validation_MAE</td><td>█▇▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>Validation_MSE</td><td>█▅▄▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation_NDE</td><td>█▆▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation_NEP</td><td>█▇▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>Validation_R2</td><td>▁▃▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">comfy-pond-488</strong>: <a href=\"https://wandb.ai/nilm/Drye1_single_houses/runs/25bwjamm\" target=\"_blank\">https://wandb.ai/nilm/Drye1_single_houses/runs/25bwjamm</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-19 18:52:31,266]\u001b[0m Trial 1 finished with value: 0.17984193563461304 and parameters: {'hidden_size_1': 111, 'hidden_size_2': 149, 'fc1': 422, 'fc2': 22, 'weight_decay': 0.04131961019566136, 'learning_rate': 1.6077380597629966e-05, 'window_size': 85}. Best is trial 1 with value: 0.17984193563461304.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">floral-universe-489</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nilm/Drye1_single_houses\" target=\"_blank\">https://wandb.ai/nilm/Drye1_single_houses</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/nilm/Drye1_single_houses/runs/35q4vcr5\" target=\"_blank\">https://wandb.ai/nilm/Drye1_single_houses/runs/35q4vcr5</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\wandb\\run-20211119_185231-35q4vcr5</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (conv1): Conv1d(1, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "  (lstm1): LSTM(16, 68, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (lstm2): LSTM(136, 409, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (linear1): Linear(in_features=818, out_features=417, bias=True)\n",
      "  (linear2): Linear(in_features=417, out_features=15, bias=True)\n",
      "  (linear3): Linear(in_features=15, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 00084 batches: 0.5047\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 00168 batches: 0.4992\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 00252 batches: 0.5049\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 00336 batches: 0.4932\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 00420 batches: 0.5025\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 00504 batches: 0.5127\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 00588 batches: 0.4991\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 00672 batches: 0.5028\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 00756 batches: 0.4996\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 00840 batches: 0.4940\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 00924 batches: 0.4978\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 01008 batches: 0.5010\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 01092 batches: 0.4976\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 01176 batches: 0.4939\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 01260 batches: 0.4941\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 01344 batches: 0.5012\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 01428 batches: 0.4975\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 01512 batches: 0.4963\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 01596 batches: 0.4836\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 01680 batches: 0.4840\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 01764 batches: 0.5003\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 01848 batches: 0.4969\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 01932 batches: 0.4902\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 02016 batches: 0.4963\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 02100 batches: 0.4982\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 02184 batches: 0.4977\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 02268 batches: 0.4936\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 02352 batches: 0.4944\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 02436 batches: 0.4879\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 02520 batches: 0.4940\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 02604 batches: 0.4923\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 02688 batches: 0.4912\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 02772 batches: 0.4954\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 02856 batches: 0.4897\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 02940 batches: 0.4923\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 03024 batches: 0.5015\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 03108 batches: 0.4901\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 03192 batches: 0.4895\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 03276 batches: 0.4857\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 03360 batches: 0.4898\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 03444 batches: 0.4914\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 03528 batches: 0.4888\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 03612 batches: 0.4926\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 03696 batches: 0.4851\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 03780 batches: 0.4883\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 03864 batches: 0.4928\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 03948 batches: 0.4821\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 04032 batches: 0.4901\n",
      "Adjusting learning rate of group 0 to 1.0419e-06.\n",
      "Loss after 04116 batches: 0.4929\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 04200 batches: 0.4845\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 04284 batches: 0.4910\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 04368 batches: 0.4866\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 04452 batches: 0.4863\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 04536 batches: 0.4822\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 04620 batches: 0.4871\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 04704 batches: 0.4931\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 04788 batches: 0.4807\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 04872 batches: 0.4873\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 04956 batches: 0.4855\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 05040 batches: 0.4890\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 05124 batches: 0.4767\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 05208 batches: 0.4747\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 05292 batches: 0.4872\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 05376 batches: 0.4893\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 05460 batches: 0.4819\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 05544 batches: 0.4857\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 05628 batches: 0.4894\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 05712 batches: 0.4786\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 05796 batches: 0.4898\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 05880 batches: 0.4790\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 05964 batches: 0.4863\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 06048 batches: 0.4784\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 06132 batches: 0.4881\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 06216 batches: 0.4794\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 06300 batches: 0.4795\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 06384 batches: 0.4809\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 06468 batches: 0.4778\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 06552 batches: 0.4799\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 06636 batches: 0.4890\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 06720 batches: 0.4830\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 06804 batches: 0.4828\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 06888 batches: 0.4824\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 06972 batches: 0.4809\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 07056 batches: 0.4804\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 07140 batches: 0.4828\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 07224 batches: 0.4797\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 07308 batches: 0.4833\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 07392 batches: 0.4831\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 07476 batches: 0.4720\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 07560 batches: 0.4725\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 07644 batches: 0.4845\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 07728 batches: 0.4650\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 07812 batches: 0.4801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 07896 batches: 0.4768\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 07980 batches: 0.4749\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 08064 batches: 0.4726\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 08148 batches: 0.4763\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 08232 batches: 0.4781\n",
      "Adjusting learning rate of group 0 to 9.3768e-07.\n",
      "Loss after 08316 batches: 0.4787\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 08400 batches: 0.4741\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 08484 batches: 0.4741\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 08568 batches: 0.4762\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 08652 batches: 0.4780\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 08736 batches: 0.4788\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 08820 batches: 0.4746\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 08904 batches: 0.4768\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 08988 batches: 0.4689\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 09072 batches: 0.4793\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 09156 batches: 0.4756\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 09240 batches: 0.4740\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 09324 batches: 0.4719\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 09408 batches: 0.4710\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 09492 batches: 0.4748\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 09576 batches: 0.4805\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 09660 batches: 0.4756\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 09744 batches: 0.4720\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 09828 batches: 0.4762\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 09912 batches: 0.4724\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 09996 batches: 0.4791\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 10080 batches: 0.4711\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 10164 batches: 0.4784\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 10248 batches: 0.4736\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 10332 batches: 0.4718\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 10416 batches: 0.4657\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 10500 batches: 0.4699\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 10584 batches: 0.4622\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 10668 batches: 0.4720\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 10752 batches: 0.4679\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 10836 batches: 0.4727\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 10920 batches: 0.4648\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 11004 batches: 0.4721\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 11088 batches: 0.4689\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 11172 batches: 0.4639\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 11256 batches: 0.4702\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 11340 batches: 0.4586\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 11424 batches: 0.4642\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 11508 batches: 0.4712\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 11592 batches: 0.4645\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 11676 batches: 0.4646\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 11760 batches: 0.4694\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 11844 batches: 0.4715\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 11928 batches: 0.4679\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 12012 batches: 0.4759\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 12096 batches: 0.4695\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 12180 batches: 0.4606\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 12264 batches: 0.4626\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 12348 batches: 0.4721\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 12432 batches: 0.4708\n",
      "Adjusting learning rate of group 0 to 8.4391e-07.\n",
      "Loss after 12516 batches: 0.4633\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 12600 batches: 0.4621\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 12684 batches: 0.4717\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 12768 batches: 0.4659\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 12852 batches: 0.4701\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 12936 batches: 0.4645\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 13020 batches: 0.4599\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 13104 batches: 0.4650\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 13188 batches: 0.4643\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 13272 batches: 0.4729\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 13356 batches: 0.4660\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 13440 batches: 0.4677\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 13524 batches: 0.4611\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 13608 batches: 0.4609\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 13692 batches: 0.4696\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 13776 batches: 0.4610\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 13860 batches: 0.4658\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 13944 batches: 0.4657\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 14028 batches: 0.4628\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 14112 batches: 0.4640\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 14196 batches: 0.4668\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 14280 batches: 0.4676\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 14364 batches: 0.4644\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 14448 batches: 0.4624\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 14532 batches: 0.4677\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 14616 batches: 0.4627\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 14700 batches: 0.4606\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 14784 batches: 0.4585\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 14868 batches: 0.4580\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 14952 batches: 0.4599\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 15036 batches: 0.4583\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 15120 batches: 0.4610\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 15204 batches: 0.4631\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 15288 batches: 0.4679\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 15372 batches: 0.4525\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 15456 batches: 0.4540\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 15540 batches: 0.4626\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 15624 batches: 0.4626\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 15708 batches: 0.4618\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 15792 batches: 0.4565\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 15876 batches: 0.4553\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 15960 batches: 0.4493\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 16044 batches: 0.4575\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 16128 batches: 0.4476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 16212 batches: 0.4631\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 16296 batches: 0.4586\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 16380 batches: 0.4573\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 16464 batches: 0.4551\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 16548 batches: 0.4588\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 16632 batches: 0.4463\n",
      "Adjusting learning rate of group 0 to 7.5952e-07.\n",
      "Loss after 16716 batches: 0.4555\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 16800 batches: 0.4542\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 16884 batches: 0.4600\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 16968 batches: 0.4569\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 17052 batches: 0.4547\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 17136 batches: 0.4509\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 17220 batches: 0.4548\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 17304 batches: 0.4496\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 17388 batches: 0.4488\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 17472 batches: 0.4555\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 17556 batches: 0.4497\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 17640 batches: 0.4539\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 17724 batches: 0.4480\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 17808 batches: 0.4590\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 17892 batches: 0.4526\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 17976 batches: 0.4540\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 18060 batches: 0.4529\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 18144 batches: 0.4531\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 18228 batches: 0.4554\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 18312 batches: 0.4507\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 18396 batches: 0.4576\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 18480 batches: 0.4608\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 18564 batches: 0.4524\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 18648 batches: 0.4532\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 18732 batches: 0.4523\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 18816 batches: 0.4510\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 18900 batches: 0.4572\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 18984 batches: 0.4541\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 19068 batches: 0.4475\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 19152 batches: 0.4494\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 19236 batches: 0.4515\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 19320 batches: 0.4430\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 19404 batches: 0.4533\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 19488 batches: 0.4490\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 19572 batches: 0.4535\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 19656 batches: 0.4369\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 19740 batches: 0.4533\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 19824 batches: 0.4558\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 19908 batches: 0.4511\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 19992 batches: 0.4500\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 20076 batches: 0.4468\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 20160 batches: 0.4534\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 20244 batches: 0.4461\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 20328 batches: 0.4524\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 20412 batches: 0.4574\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 20496 batches: 0.4479\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 20580 batches: 0.4506\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 20664 batches: 0.4478\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 20748 batches: 0.4512\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 20832 batches: 0.4523\n",
      "Adjusting learning rate of group 0 to 6.8357e-07.\n",
      "Loss after 20916 batches: 0.4504\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 21000 batches: 0.4505\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 21084 batches: 0.4503\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 21168 batches: 0.4467\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 21252 batches: 0.4512\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 21336 batches: 0.4490\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 21420 batches: 0.4502\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 21504 batches: 0.4465\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 21588 batches: 0.4485\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 21672 batches: 0.4515\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 21756 batches: 0.4536\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 21840 batches: 0.4452\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 21924 batches: 0.4432\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 22008 batches: 0.4495\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 22092 batches: 0.4555\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 22176 batches: 0.4488\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 22260 batches: 0.4524\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 22344 batches: 0.4489\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 22428 batches: 0.4444\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 22512 batches: 0.4499\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 22596 batches: 0.4539\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 22680 batches: 0.4518\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 22764 batches: 0.4474\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 22848 batches: 0.4415\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 22932 batches: 0.4377\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 23016 batches: 0.4428\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 23100 batches: 0.4436\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 23184 batches: 0.4477\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 23268 batches: 0.4460\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 23352 batches: 0.4431\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 23436 batches: 0.4414\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 23520 batches: 0.4438\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 23604 batches: 0.4482\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 23688 batches: 0.4351\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 23772 batches: 0.4544\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 23856 batches: 0.4421\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 23940 batches: 0.4353\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 24024 batches: 0.4428\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 24108 batches: 0.4449\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 24192 batches: 0.4535\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 24276 batches: 0.4347\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 24360 batches: 0.4421\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 24444 batches: 0.4485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 24528 batches: 0.4374\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 24612 batches: 0.4443\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 24696 batches: 0.4328\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 24780 batches: 0.4363\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 24864 batches: 0.4400\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 24948 batches: 0.4430\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 25032 batches: 0.4375\n",
      "Adjusting learning rate of group 0 to 6.1521e-07.\n",
      "Loss after 25116 batches: 0.4429\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 25200 batches: 0.4456\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 25284 batches: 0.4384\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 25368 batches: 0.4401\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 25452 batches: 0.4416\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 25536 batches: 0.4404\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 25620 batches: 0.4474\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 25704 batches: 0.4438\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 25788 batches: 0.4373\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 25872 batches: 0.4344\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 25956 batches: 0.4359\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 26040 batches: 0.4404\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 26124 batches: 0.4370\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 26208 batches: 0.4417\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 26292 batches: 0.4379\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 26376 batches: 0.4349\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 26460 batches: 0.4432\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 26544 batches: 0.4385\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 26628 batches: 0.4420\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 26712 batches: 0.4376\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 26796 batches: 0.4439\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 26880 batches: 0.4374\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 26964 batches: 0.4432\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 27048 batches: 0.4352\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 27132 batches: 0.4388\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 27216 batches: 0.4270\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 27300 batches: 0.4429\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 27384 batches: 0.4355\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 27468 batches: 0.4343\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 27552 batches: 0.4321\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 27636 batches: 0.4411\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 27720 batches: 0.4367\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 27804 batches: 0.4398\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 27888 batches: 0.4370\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 27972 batches: 0.4350\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 28056 batches: 0.4428\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 28140 batches: 0.4344\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 28224 batches: 0.4297\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 28308 batches: 0.4388\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 28392 batches: 0.4326\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 28476 batches: 0.4371\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 28560 batches: 0.4345\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 28644 batches: 0.4343\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 28728 batches: 0.4393\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 28812 batches: 0.4333\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 28896 batches: 0.4361\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 28980 batches: 0.4368\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 29064 batches: 0.4351\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 29148 batches: 0.4346\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 29232 batches: 0.4326\n",
      "Adjusting learning rate of group 0 to 5.5369e-07.\n",
      "Loss after 29316 batches: 0.4412\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 29400 batches: 0.4326\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 29484 batches: 0.4306\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 29568 batches: 0.4364\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 29652 batches: 0.4359\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 29736 batches: 0.4290\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 29820 batches: 0.4332\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 29904 batches: 0.4339\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 29988 batches: 0.4419\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 30072 batches: 0.4319\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 30156 batches: 0.4372\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 30240 batches: 0.4297\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 30324 batches: 0.4360\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 30408 batches: 0.4456\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 30492 batches: 0.4360\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 30576 batches: 0.4345\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 30660 batches: 0.4343\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 30744 batches: 0.4253\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 30828 batches: 0.4284\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 30912 batches: 0.4289\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 30996 batches: 0.4323\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 31080 batches: 0.4298\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 31164 batches: 0.4284\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 31248 batches: 0.4237\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 31332 batches: 0.4393\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 31416 batches: 0.4310\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 31500 batches: 0.4347\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 31584 batches: 0.4376\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 31668 batches: 0.4379\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 31752 batches: 0.4397\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 31836 batches: 0.4339\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 31920 batches: 0.4369\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 32004 batches: 0.4316\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 32088 batches: 0.4350\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 32172 batches: 0.4400\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 32256 batches: 0.4287\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 32340 batches: 0.4313\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 32424 batches: 0.4297\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 32508 batches: 0.4352\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 32592 batches: 0.4309\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 32676 batches: 0.4365\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 32760 batches: 0.4282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 32844 batches: 0.4314\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 32928 batches: 0.4299\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 33012 batches: 0.4288\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 33096 batches: 0.4280\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 33180 batches: 0.4331\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 33264 batches: 0.4282\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 33348 batches: 0.4335\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 33432 batches: 0.4287\n",
      "Adjusting learning rate of group 0 to 4.9832e-07.\n",
      "Loss after 33516 batches: 0.4265\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 33600 batches: 0.4358\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 33684 batches: 0.4251\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 33768 batches: 0.4306\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 33852 batches: 0.4224\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 33936 batches: 0.4291\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 34020 batches: 0.4341\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 34104 batches: 0.4340\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 34188 batches: 0.4244\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 34272 batches: 0.4241\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 34356 batches: 0.4220\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 34440 batches: 0.4378\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 34524 batches: 0.4301\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 34608 batches: 0.4317\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 34692 batches: 0.4262\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 34776 batches: 0.4272\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 34860 batches: 0.4366\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 34944 batches: 0.4256\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 35028 batches: 0.4306\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 35112 batches: 0.4246\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 35196 batches: 0.4153\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 35280 batches: 0.4294\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 35364 batches: 0.4192\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 35448 batches: 0.4249\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 35532 batches: 0.4289\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 35616 batches: 0.4162\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 35700 batches: 0.4233\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 35784 batches: 0.4296\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 35868 batches: 0.4353\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 35952 batches: 0.4211\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 36036 batches: 0.4244\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 36120 batches: 0.4257\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 36204 batches: 0.4195\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 36288 batches: 0.4279\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 36372 batches: 0.4296\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 36456 batches: 0.4259\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 36540 batches: 0.4345\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 36624 batches: 0.4251\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 36708 batches: 0.4302\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 36792 batches: 0.4243\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 36876 batches: 0.4229\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 36960 batches: 0.4209\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 37044 batches: 0.4396\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 37128 batches: 0.4310\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 37212 batches: 0.4238\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 37296 batches: 0.4267\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 37380 batches: 0.4236\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 37464 batches: 0.4204\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 37548 batches: 0.4246\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 37632 batches: 0.4254\n",
      "Adjusting learning rate of group 0 to 4.4849e-07.\n",
      "Loss after 37716 batches: 0.4247\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 37800 batches: 0.4200\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 37884 batches: 0.4228\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 37968 batches: 0.4240\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 38052 batches: 0.4209\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 38136 batches: 0.4227\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 38220 batches: 0.4236\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 38304 batches: 0.4216\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 38388 batches: 0.4258\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 38472 batches: 0.4271\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 38556 batches: 0.4212\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 38640 batches: 0.4249\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 38724 batches: 0.4302\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 38808 batches: 0.4200\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 38892 batches: 0.4253\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 38976 batches: 0.4223\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 39060 batches: 0.4133\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 39144 batches: 0.4324\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 39228 batches: 0.4256\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 39312 batches: 0.4227\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 39396 batches: 0.4251\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 39480 batches: 0.4183\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 39564 batches: 0.4190\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 39648 batches: 0.4212\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 39732 batches: 0.4228\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 39816 batches: 0.4262\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 39900 batches: 0.4275\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 39984 batches: 0.4203\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 40068 batches: 0.4263\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 40152 batches: 0.4298\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 40236 batches: 0.4175\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 40320 batches: 0.4196\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 40404 batches: 0.4201\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 40488 batches: 0.4287\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 40572 batches: 0.4137\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 40656 batches: 0.4228\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 40740 batches: 0.4229\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 40824 batches: 0.4219\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 40908 batches: 0.4238\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 40992 batches: 0.4132\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 41076 batches: 0.4151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 41160 batches: 0.4143\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 41244 batches: 0.4255\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 41328 batches: 0.4247\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 41412 batches: 0.4197\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 41496 batches: 0.4235\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 41580 batches: 0.4250\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 41664 batches: 0.4133\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 41748 batches: 0.4231\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 41832 batches: 0.4105\n",
      "Adjusting learning rate of group 0 to 4.0364e-07.\n",
      "Loss after 41916 batches: 0.4166\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 42000 batches: 0.4258\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 42084 batches: 0.4258\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 42168 batches: 0.4243\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 42252 batches: 0.4203\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 42336 batches: 0.4225\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 42420 batches: 0.4180\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 42504 batches: 0.4229\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 42588 batches: 0.4216\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 42672 batches: 0.4209\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 42756 batches: 0.4255\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 42840 batches: 0.4112\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 42924 batches: 0.4166\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 43008 batches: 0.4162\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 43092 batches: 0.4163\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 43176 batches: 0.4170\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 43260 batches: 0.4161\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 43344 batches: 0.4193\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 43428 batches: 0.4200\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 43512 batches: 0.4142\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 43596 batches: 0.4167\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 43680 batches: 0.4332\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 43764 batches: 0.4248\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 43848 batches: 0.4231\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 43932 batches: 0.4160\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 44016 batches: 0.4190\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 44100 batches: 0.4145\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 44184 batches: 0.4131\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 44268 batches: 0.4181\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 44352 batches: 0.4177\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 44436 batches: 0.4245\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 44520 batches: 0.4182\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 44604 batches: 0.4232\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 44688 batches: 0.4207\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 44772 batches: 0.4142\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 44856 batches: 0.4212\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 44940 batches: 0.4184\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 45024 batches: 0.4221\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 45108 batches: 0.4208\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 45192 batches: 0.4186\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 45276 batches: 0.4193\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 45360 batches: 0.4252\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 45444 batches: 0.4186\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 45528 batches: 0.4140\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 45612 batches: 0.4138\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 45696 batches: 0.4166\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 45780 batches: 0.4172\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 45864 batches: 0.4191\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 45948 batches: 0.4129\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 46032 batches: 0.4175\n",
      "Adjusting learning rate of group 0 to 3.6328e-07.\n",
      "Loss after 46116 batches: 0.4084\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 46200 batches: 0.4127\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 46284 batches: 0.4182\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 46368 batches: 0.4148\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 46452 batches: 0.4153\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 46536 batches: 0.4201\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 46620 batches: 0.4154\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 46704 batches: 0.4194\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 46788 batches: 0.4202\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 46872 batches: 0.4130\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 46956 batches: 0.4224\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 47040 batches: 0.4146\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 47124 batches: 0.4150\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 47208 batches: 0.4194\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 47292 batches: 0.4125\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 47376 batches: 0.4188\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 47460 batches: 0.4119\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 47544 batches: 0.4160\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 47628 batches: 0.4180\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 47712 batches: 0.4208\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 47796 batches: 0.4154\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 47880 batches: 0.4214\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 47964 batches: 0.4156\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 48048 batches: 0.4229\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 48132 batches: 0.4177\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 48216 batches: 0.4145\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 48300 batches: 0.4127\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 48384 batches: 0.4164\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 48468 batches: 0.4119\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 48552 batches: 0.4150\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 48636 batches: 0.4128\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 48720 batches: 0.4138\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 48804 batches: 0.4247\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 48888 batches: 0.4229\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 48972 batches: 0.4174\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 49056 batches: 0.4134\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 49140 batches: 0.4137\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 49224 batches: 0.4209\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 49308 batches: 0.4177\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 49392 batches: 0.4112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 49476 batches: 0.4117\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 49560 batches: 0.4143\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 49644 batches: 0.4169\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 49728 batches: 0.4137\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 49812 batches: 0.4175\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 49896 batches: 0.4166\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 49980 batches: 0.4038\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 50064 batches: 0.4150\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 50148 batches: 0.4097\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 50232 batches: 0.4034\n",
      "Adjusting learning rate of group 0 to 3.2695e-07.\n",
      "Loss after 50316 batches: 0.4088\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 50400 batches: 0.4180\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 50484 batches: 0.4129\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 50568 batches: 0.4134\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 50652 batches: 0.4134\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 50736 batches: 0.4079\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 50820 batches: 0.4071\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 50904 batches: 0.4233\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 50988 batches: 0.4137\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 51072 batches: 0.4152\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 51156 batches: 0.4162\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 51240 batches: 0.4166\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 51324 batches: 0.4110\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 51408 batches: 0.4083\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 51492 batches: 0.4066\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 51576 batches: 0.4187\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 51660 batches: 0.4139\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 51744 batches: 0.4118\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 51828 batches: 0.4160\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 51912 batches: 0.4178\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 51996 batches: 0.4114\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 52080 batches: 0.4144\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 52164 batches: 0.4162\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 52248 batches: 0.4067\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 52332 batches: 0.4159\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 52416 batches: 0.4072\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 52500 batches: 0.4104\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 52584 batches: 0.4081\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 52668 batches: 0.4156\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 52752 batches: 0.4113\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 52836 batches: 0.4137\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 52920 batches: 0.4111\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 53004 batches: 0.4101\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 53088 batches: 0.4096\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 53172 batches: 0.4126\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 53256 batches: 0.4229\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 53340 batches: 0.4130\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 53424 batches: 0.4047\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 53508 batches: 0.4071\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 53592 batches: 0.4155\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 53676 batches: 0.4156\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 53760 batches: 0.4101\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 53844 batches: 0.4026\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 53928 batches: 0.4074\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 54012 batches: 0.4098\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 54096 batches: 0.4146\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 54180 batches: 0.4109\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 54264 batches: 0.4183\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 54348 batches: 0.4082\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 54432 batches: 0.4105\n",
      "Adjusting learning rate of group 0 to 2.9425e-07.\n",
      "Loss after 54516 batches: 0.4150\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 54600 batches: 0.4061\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 54684 batches: 0.4026\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 54768 batches: 0.4106\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 54852 batches: 0.4153\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 54936 batches: 0.4154\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 55020 batches: 0.4040\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 55104 batches: 0.4075\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 55188 batches: 0.4094\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 55272 batches: 0.4073\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 55356 batches: 0.4089\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 55440 batches: 0.4103\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 55524 batches: 0.4152\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 55608 batches: 0.4068\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 55692 batches: 0.4077\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 55776 batches: 0.4077\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 55860 batches: 0.4078\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 55944 batches: 0.4029\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 56028 batches: 0.4128\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 56112 batches: 0.4050\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 56196 batches: 0.4049\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 56280 batches: 0.4070\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 56364 batches: 0.4165\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 56448 batches: 0.4070\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 56532 batches: 0.4198\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 56616 batches: 0.4112\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 56700 batches: 0.4099\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 56784 batches: 0.4086\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 56868 batches: 0.4117\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 56952 batches: 0.4102\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 57036 batches: 0.4125\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 57120 batches: 0.3991\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 57204 batches: 0.4099\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 57288 batches: 0.4085\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 57372 batches: 0.4008\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 57456 batches: 0.4132\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 57540 batches: 0.4060\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 57624 batches: 0.4048\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 57708 batches: 0.4094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 57792 batches: 0.4087\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 57876 batches: 0.4136\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 57960 batches: 0.4094\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 58044 batches: 0.4073\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 58128 batches: 0.4050\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 58212 batches: 0.4077\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 58296 batches: 0.4152\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 58380 batches: 0.4077\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 58464 batches: 0.4107\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 58548 batches: 0.4110\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 58632 batches: 0.4080\n",
      "Adjusting learning rate of group 0 to 2.6483e-07.\n",
      "Loss after 58716 batches: 0.4076\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 58800 batches: 0.4128\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 58884 batches: 0.4096\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 58968 batches: 0.4004\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 59052 batches: 0.4062\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 59136 batches: 0.4093\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 59220 batches: 0.4084\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 59304 batches: 0.4048\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 59388 batches: 0.4078\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 59472 batches: 0.4073\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 59556 batches: 0.4040\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 59640 batches: 0.4169\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 59724 batches: 0.4021\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 59808 batches: 0.4115\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 59892 batches: 0.4114\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 59976 batches: 0.4134\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 60060 batches: 0.4088\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 60144 batches: 0.4070\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 60228 batches: 0.4117\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 60312 batches: 0.4080\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 60396 batches: 0.4096\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 60480 batches: 0.4010\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 60564 batches: 0.4054\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 60648 batches: 0.4130\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 60732 batches: 0.4129\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 60816 batches: 0.4117\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 60900 batches: 0.4062\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 60984 batches: 0.4031\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 61068 batches: 0.4103\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 61152 batches: 0.4073\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 61236 batches: 0.4088\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 61320 batches: 0.4105\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 61404 batches: 0.4053\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 61488 batches: 0.4143\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 61572 batches: 0.4094\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 61656 batches: 0.4058\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 61740 batches: 0.4070\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 61824 batches: 0.4082\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 61908 batches: 0.4015\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 61992 batches: 0.4075\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 62076 batches: 0.4053\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 62160 batches: 0.4037\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 62244 batches: 0.4062\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 62328 batches: 0.4032\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 62412 batches: 0.4045\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 62496 batches: 0.4062\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 62580 batches: 0.4005\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 62664 batches: 0.4025\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 62748 batches: 0.4007\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 62832 batches: 0.3992\n",
      "Adjusting learning rate of group 0 to 2.3835e-07.\n",
      "Loss after 62916 batches: 0.4160\n",
      "Adjusting learning rate of group 0 to 2.1451e-07.\n",
      "Loss after 63000 batches: 0.4036\n",
      "Time to train on one home:  385.37815403938293\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 40368<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\wandb\\run-20211119_185231-35q4vcr5\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\wandb\\run-20211119_185231-35q4vcr5\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_F1_Score</td><td>-0.25438</td></tr><tr><td>Test_MAE</td><td>43.04541</td></tr><tr><td>Test_MSE</td><td>0.43576</td></tr><tr><td>Test_NDE</td><td>0.94033</td></tr><tr><td>Test_NEP</td><td>1.0928</td></tr><tr><td>Test_R2_Value</td><td>-2.37027</td></tr><tr><td>Training_F1</td><td>-0.30333</td></tr><tr><td>Training_MAE</td><td>56.76356</td></tr><tr><td>Training_MSE</td><td>0.4036</td></tr><tr><td>Training_NDE</td><td>1.51154</td></tr><tr><td>Training_NEP</td><td>1.19339</td></tr><tr><td>Training_R2</td><td>-1.2932</td></tr><tr><td>Validation_F1</td><td>-0.23552</td></tr><tr><td>Validation_MAE</td><td>53.45751</td></tr><tr><td>Validation_MSE</td><td>0.3359</td></tr><tr><td>Validation_NDE</td><td>1.34181</td></tr><tr><td>Validation_NEP</td><td>1.07173</td></tr><tr><td>Validation_R2</td><td>-1.8557</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_F1_Score</td><td>▁</td></tr><tr><td>Test_MAE</td><td>▁</td></tr><tr><td>Test_MSE</td><td>▁</td></tr><tr><td>Test_NDE</td><td>▁</td></tr><tr><td>Test_NEP</td><td>▁</td></tr><tr><td>Test_R2_Value</td><td>▁</td></tr><tr><td>Training_F1</td><td>▄▄▅▅▅▅▅▅▅▆▅▅▆▆▆▆▆▆▁█▆▄▆▅▆▆▆▆▇▆▆▆▆▆▆▅▇▆▆▆</td></tr><tr><td>Training_MAE</td><td>██▇▇▇▆▆▅▅▅▄▅▄▅▄▅▄▃▄▃▃▄▃▂▃▂▂▂▂▂▃▂▂▂▂▂▁▁▁▂</td></tr><tr><td>Training_MSE</td><td>██▇▇▇▆▆▅▆▅▄▅▄▅▄▅▄▃▄▃▃▃▃▂▃▂▂▂▃▂▂▂▂▂▂▂▁▂▁▁</td></tr><tr><td>Training_NDE</td><td>██▇▇▇▆▆▅▆▅▄▅▅▅▄▅▄▃▄▃▃▄▃▃▃▃▂▂▃▂▃▂▂▂▂▂▁▂▁▂</td></tr><tr><td>Training_NEP</td><td>██▇▇▇▆▆▅▅▅▄▅▄▅▄▅▄▃▄▃▃▄▃▂▃▂▂▂▂▂▃▂▂▂▂▂▁▁▁▂</td></tr><tr><td>Training_R2</td><td>▁▁▃▂▂▃▃▄▃▄▄▄▅▄▅▄▆▆▅▆▅▅▆▇▇▇▆▇▆▇▇▇▆█▇▇███▇</td></tr><tr><td>Validation_F1</td><td>▁▁▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>Validation_MAE</td><td>██▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation_MSE</td><td>██▇▇▇▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>Validation_NDE</td><td>██▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation_NEP</td><td>██▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Validation_R2</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██████</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">floral-universe-489</strong>: <a href=\"https://wandb.ai/nilm/Drye1_single_houses/runs/35q4vcr5\" target=\"_blank\">https://wandb.ai/nilm/Drye1_single_houses/runs/35q4vcr5</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-19 19:00:25,006]\u001b[0m Trial 2 finished with value: 0.43576309084892273 and parameters: {'hidden_size_1': 68, 'hidden_size_2': 409, 'fc1': 417, 'fc2': 15, 'weight_decay': 0.022668489976231432, 'learning_rate': 1.0418683927998107e-06, 'window_size': 85}. Best is trial 1 with value: 0.17984193563461304.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">fresh-fog-490</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nilm/Drye1_single_houses\" target=\"_blank\">https://wandb.ai/nilm/Drye1_single_houses</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/nilm/Drye1_single_houses/runs/1lsee4b1\" target=\"_blank\">https://wandb.ai/nilm/Drye1_single_houses/runs/1lsee4b1</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\wandb\\run-20211119_190025-1lsee4b1</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (conv1): Conv1d(1, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "  (lstm1): LSTM(16, 41, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (lstm2): LSTM(82, 289, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (linear1): Linear(in_features=578, out_features=376, bias=True)\n",
      "  (linear2): Linear(in_features=376, out_features=6, bias=True)\n",
      "  (linear3): Linear(in_features=6, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 00098 batches: 0.2616\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 00196 batches: 0.2452\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 00294 batches: 0.2410\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 00392 batches: 0.2392\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 00490 batches: 0.2283\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 00588 batches: 0.2222\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 00686 batches: 0.2214\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 00784 batches: 0.2198\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 00882 batches: 0.2123\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 00980 batches: 0.2135\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 01078 batches: 0.2067\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 01176 batches: 0.2055\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 01274 batches: 0.2023\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 01372 batches: 0.1978\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 01470 batches: 0.1928\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 01568 batches: 0.1927\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 01666 batches: 0.1907\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 01764 batches: 0.1874\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 01862 batches: 0.1883\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 01960 batches: 0.1881\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 02058 batches: 0.1840\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 02156 batches: 0.1824\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 02254 batches: 0.1862\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 02352 batches: 0.1790\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 02450 batches: 0.1775\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 02548 batches: 0.1794\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 02646 batches: 0.1758\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 02744 batches: 0.1788\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 02842 batches: 0.1772\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 02940 batches: 0.1758\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 03038 batches: 0.1783\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 03136 batches: 0.1763\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 03234 batches: 0.1772\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 03332 batches: 0.1758\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 03430 batches: 0.1747\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 03528 batches: 0.1752\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 03626 batches: 0.1715\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 03724 batches: 0.1712\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 03822 batches: 0.1722\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 03920 batches: 0.1701\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 04018 batches: 0.1708\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 04116 batches: 0.1724\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 04214 batches: 0.1715\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 04312 batches: 0.1712\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 04410 batches: 0.1711\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 04508 batches: 0.1687\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 04606 batches: 0.1699\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 04704 batches: 0.1701\n",
      "Adjusting learning rate of group 0 to 1.4274e-04.\n",
      "Loss after 04802 batches: 0.1690\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 04900 batches: 0.1714\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 04998 batches: 0.1683\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 05096 batches: 0.1698\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 05194 batches: 0.1689\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 05292 batches: 0.1692\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 05390 batches: 0.1695\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 05488 batches: 0.1684\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 05586 batches: 0.1686\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 05684 batches: 0.1682\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 05782 batches: 0.1663\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 05880 batches: 0.1674\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 05978 batches: 0.1669\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 06076 batches: 0.1651\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 06174 batches: 0.1665\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 06272 batches: 0.1665\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 06370 batches: 0.1664\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 06468 batches: 0.1663\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 06566 batches: 0.1641\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 06664 batches: 0.1649\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 06762 batches: 0.1642\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 06860 batches: 0.1624\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 06958 batches: 0.1626\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 07056 batches: 0.1655\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 07154 batches: 0.1633\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 07252 batches: 0.1622\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 07350 batches: 0.1631\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 07448 batches: 0.1624\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 07546 batches: 0.1624\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 07644 batches: 0.1626\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 07742 batches: 0.1618\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 07840 batches: 0.1623\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 07938 batches: 0.1609\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 08036 batches: 0.1601\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 08134 batches: 0.1611\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 08232 batches: 0.1608\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 08330 batches: 0.1612\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 08428 batches: 0.1611\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 08526 batches: 0.1597\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 08624 batches: 0.1596\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 08722 batches: 0.1608\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 08820 batches: 0.1603\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 08918 batches: 0.1608\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 09016 batches: 0.1609\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 09114 batches: 0.1606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 09212 batches: 0.1583\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 09310 batches: 0.1593\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 09408 batches: 0.1583\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 09506 batches: 0.1596\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 09604 batches: 0.1594\n",
      "Adjusting learning rate of group 0 to 1.2846e-04.\n",
      "Loss after 09702 batches: 0.1593\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 09800 batches: 0.1569\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 09898 batches: 0.1580\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 09996 batches: 0.1572\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 10094 batches: 0.1568\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 10192 batches: 0.1568\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 10290 batches: 0.1558\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 10388 batches: 0.1554\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 10486 batches: 0.1549\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 10584 batches: 0.1559\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 10682 batches: 0.1557\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 10780 batches: 0.1551\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 10878 batches: 0.1554\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 10976 batches: 0.1531\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 11074 batches: 0.1547\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 11172 batches: 0.1536\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 11270 batches: 0.1546\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 11368 batches: 0.1550\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 11466 batches: 0.1539\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 11564 batches: 0.1529\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 11662 batches: 0.1522\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 11760 batches: 0.1505\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 11858 batches: 0.1520\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 11956 batches: 0.1513\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 12054 batches: 0.1486\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 12152 batches: 0.1502\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 12250 batches: 0.1459\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 12348 batches: 0.1477\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 12446 batches: 0.1474\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 12544 batches: 0.1460\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 12642 batches: 0.1458\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 12740 batches: 0.1448\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 12838 batches: 0.1425\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 12936 batches: 0.1434\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 13034 batches: 0.1401\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 13132 batches: 0.1418\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 13230 batches: 0.1412\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 13328 batches: 0.1395\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 13426 batches: 0.1386\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 13524 batches: 0.1366\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 13622 batches: 0.1367\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 13720 batches: 0.1363\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 13818 batches: 0.1359\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 13916 batches: 0.1338\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 14014 batches: 0.1335\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 14112 batches: 0.1327\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 14210 batches: 0.1320\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 14308 batches: 0.1311\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 14406 batches: 0.1311\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 14504 batches: 0.1289\n",
      "Adjusting learning rate of group 0 to 1.1562e-04.\n",
      "Loss after 14602 batches: 0.1289\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 14700 batches: 0.1268\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 14798 batches: 0.1275\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 14896 batches: 0.1273\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 14994 batches: 0.1256\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 15092 batches: 0.1254\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 15190 batches: 0.1249\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 15288 batches: 0.1220\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 15386 batches: 0.1217\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 15484 batches: 0.1225\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 15582 batches: 0.1208\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 15680 batches: 0.1192\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 15778 batches: 0.1175\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 15876 batches: 0.1197\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 15974 batches: 0.1169\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 16072 batches: 0.1193\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 16170 batches: 0.1149\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 16268 batches: 0.1157\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 16366 batches: 0.1135\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 16464 batches: 0.1089\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 16562 batches: 0.1123\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 16660 batches: 0.1119\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 16758 batches: 0.1105\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 16856 batches: 0.1101\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 16954 batches: 0.1071\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 17052 batches: 0.1091\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 17150 batches: 0.1091\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 17248 batches: 0.1058\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 17346 batches: 0.1056\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 17444 batches: 0.1031\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 17542 batches: 0.1031\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 17640 batches: 0.1029\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 17738 batches: 0.1004\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 17836 batches: 0.1010\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 17934 batches: 0.1007\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 18032 batches: 0.0988\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 18130 batches: 0.0954\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 18228 batches: 0.0972\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 18326 batches: 0.0962\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 18424 batches: 0.0951\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 18522 batches: 0.0959\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 18620 batches: 0.0954\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 18718 batches: 0.0946\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 18816 batches: 0.0941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 18914 batches: 0.0928\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 19012 batches: 0.0908\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 19110 batches: 0.0905\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 19208 batches: 0.0877\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 19306 batches: 0.0901\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 19404 batches: 0.0883\n",
      "Adjusting learning rate of group 0 to 1.0405e-04.\n",
      "Loss after 19502 batches: 0.0884\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 19600 batches: 0.0874\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 19698 batches: 0.0880\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 19796 batches: 0.0873\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 19894 batches: 0.0857\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 19992 batches: 0.0838\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 20090 batches: 0.0837\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 20188 batches: 0.0836\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 20286 batches: 0.0809\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 20384 batches: 0.0843\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 20482 batches: 0.0826\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 20580 batches: 0.0821\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 20678 batches: 0.0823\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 20776 batches: 0.0825\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 20874 batches: 0.0811\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 20972 batches: 0.0778\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 21070 batches: 0.0794\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 21168 batches: 0.0802\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 21266 batches: 0.0797\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 21364 batches: 0.0769\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 21462 batches: 0.0788\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 21560 batches: 0.0777\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 21658 batches: 0.0771\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 21756 batches: 0.0760\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 21854 batches: 0.0789\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 21952 batches: 0.0765\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 22050 batches: 0.0746\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 22148 batches: 0.0778\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 22246 batches: 0.0767\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 22344 batches: 0.0742\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 22442 batches: 0.0756\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 22540 batches: 0.0746\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 22638 batches: 0.0742\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 22736 batches: 0.0753\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 22834 batches: 0.0741\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 22932 batches: 0.0749\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 23030 batches: 0.0740\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 23128 batches: 0.0729\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 23226 batches: 0.0723\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 23324 batches: 0.0729\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 23422 batches: 0.0727\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 23520 batches: 0.0711\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 23618 batches: 0.0725\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 23716 batches: 0.0717\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 23814 batches: 0.0716\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 23912 batches: 0.0714\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 24010 batches: 0.0719\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 24108 batches: 0.0701\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 24206 batches: 0.0700\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 24304 batches: 0.0693\n",
      "Adjusting learning rate of group 0 to 9.3649e-05.\n",
      "Loss after 24402 batches: 0.0684\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 24500 batches: 0.0706\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 24598 batches: 0.0700\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 24696 batches: 0.0709\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 24794 batches: 0.0714\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 24892 batches: 0.0684\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 24990 batches: 0.0683\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 25088 batches: 0.0690\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 25186 batches: 0.0686\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 25284 batches: 0.0672\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 25382 batches: 0.0686\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 25480 batches: 0.0663\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 25578 batches: 0.0671\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 25676 batches: 0.0665\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 25774 batches: 0.0654\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 25872 batches: 0.0653\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 25970 batches: 0.0670\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 26068 batches: 0.0674\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 26166 batches: 0.0686\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 26264 batches: 0.0676\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 26362 batches: 0.0670\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 26460 batches: 0.0665\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 26558 batches: 0.0651\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 26656 batches: 0.0663\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 26754 batches: 0.0665\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 26852 batches: 0.0666\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 26950 batches: 0.0667\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 27048 batches: 0.0670\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 27146 batches: 0.0668\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 27244 batches: 0.0649\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 27342 batches: 0.0666\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 27440 batches: 0.0650\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 27538 batches: 0.0663\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 27636 batches: 0.0661\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 27734 batches: 0.0643\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 27832 batches: 0.0642\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 27930 batches: 0.0641\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 28028 batches: 0.0653\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 28126 batches: 0.0652\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 28224 batches: 0.0645\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 28322 batches: 0.0652\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 28420 batches: 0.0632\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 28518 batches: 0.0646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 28616 batches: 0.0654\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 28714 batches: 0.0640\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 28812 batches: 0.0646\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 28910 batches: 0.0641\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 29008 batches: 0.0644\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 29106 batches: 0.0645\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 29204 batches: 0.0657\n",
      "Adjusting learning rate of group 0 to 8.4284e-05.\n",
      "Loss after 29302 batches: 0.0629\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 29400 batches: 0.0639\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 29498 batches: 0.0650\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 29596 batches: 0.0634\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 29694 batches: 0.0638\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 29792 batches: 0.0634\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 29890 batches: 0.0630\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 29988 batches: 0.0640\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 30086 batches: 0.0630\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 30184 batches: 0.0627\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 30282 batches: 0.0625\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 30380 batches: 0.0653\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 30478 batches: 0.0648\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 30576 batches: 0.0622\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 30674 batches: 0.0628\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 30772 batches: 0.0621\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 30870 batches: 0.0618\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 30968 batches: 0.0611\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 31066 batches: 0.0631\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 31164 batches: 0.0632\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 31262 batches: 0.0643\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 31360 batches: 0.0629\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 31458 batches: 0.0632\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 31556 batches: 0.0619\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 31654 batches: 0.0628\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 31752 batches: 0.0620\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 31850 batches: 0.0613\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 31948 batches: 0.0615\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 32046 batches: 0.0614\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 32144 batches: 0.0619\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 32242 batches: 0.0617\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 32340 batches: 0.0597\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 32438 batches: 0.0609\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 32536 batches: 0.0631\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 32634 batches: 0.0592\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 32732 batches: 0.0600\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 32830 batches: 0.0620\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 32928 batches: 0.0617\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 33026 batches: 0.0598\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 33124 batches: 0.0603\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 33222 batches: 0.0621\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 33320 batches: 0.0594\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 33418 batches: 0.0622\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 33516 batches: 0.0613\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 33614 batches: 0.0613\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 33712 batches: 0.0613\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 33810 batches: 0.0624\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 33908 batches: 0.0622\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 34006 batches: 0.0608\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 34104 batches: 0.0611\n",
      "Adjusting learning rate of group 0 to 7.5855e-05.\n",
      "Loss after 34202 batches: 0.0612\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 34300 batches: 0.0605\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 34398 batches: 0.0609\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 34496 batches: 0.0603\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 34594 batches: 0.0611\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 34692 batches: 0.0639\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 34790 batches: 0.0612\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 34888 batches: 0.0615\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 34986 batches: 0.0627\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 35084 batches: 0.0628\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 35182 batches: 0.0619\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 35280 batches: 0.0589\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 35378 batches: 0.0612\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 35476 batches: 0.0589\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 35574 batches: 0.0599\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 35672 batches: 0.0587\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 35770 batches: 0.0603\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 35868 batches: 0.0607\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 35966 batches: 0.0601\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 36064 batches: 0.0616\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 36162 batches: 0.0602\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 36260 batches: 0.0595\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 36358 batches: 0.0606\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 36456 batches: 0.0621\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 36554 batches: 0.0601\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 36652 batches: 0.0598\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 36750 batches: 0.0592\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 36848 batches: 0.0600\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 36946 batches: 0.0610\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 37044 batches: 0.0603\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 37142 batches: 0.0597\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 37240 batches: 0.0608\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 37338 batches: 0.0587\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 37436 batches: 0.0591\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 37534 batches: 0.0589\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 37632 batches: 0.0579\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 37730 batches: 0.0596\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 37828 batches: 0.0612\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 37926 batches: 0.0596\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 38024 batches: 0.0574\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 38122 batches: 0.0583\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 38220 batches: 0.0595\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 38318 batches: 0.0616\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 38416 batches: 0.0585\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 38514 batches: 0.0581\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 38612 batches: 0.0590\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 38710 batches: 0.0598\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 38808 batches: 0.0603\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 38906 batches: 0.0587\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 39004 batches: 0.0611\n",
      "Adjusting learning rate of group 0 to 6.8270e-05.\n",
      "Loss after 39102 batches: 0.0574\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 39200 batches: 0.0576\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 39298 batches: 0.0589\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 39396 batches: 0.0580\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 39494 batches: 0.0577\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 39592 batches: 0.0594\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 39690 batches: 0.0599\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 39788 batches: 0.0596\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 39886 batches: 0.0583\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 39984 batches: 0.0579\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 40082 batches: 0.0574\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 40180 batches: 0.0588\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 40278 batches: 0.0586\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 40376 batches: 0.0585\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 40474 batches: 0.0579\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 40572 batches: 0.0591\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 40670 batches: 0.0584\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 40768 batches: 0.0594\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 40866 batches: 0.0586\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 40964 batches: 0.0590\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 41062 batches: 0.0575\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 41160 batches: 0.0601\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 41258 batches: 0.0586\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 41356 batches: 0.0577\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 41454 batches: 0.0599\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 41552 batches: 0.0608\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 41650 batches: 0.0597\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 41748 batches: 0.0575\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 41846 batches: 0.0591\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 41944 batches: 0.0590\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 42042 batches: 0.0586\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 42140 batches: 0.0582\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 42238 batches: 0.0559\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 42336 batches: 0.0566\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 42434 batches: 0.0579\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 42532 batches: 0.0582\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 42630 batches: 0.0589\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 42728 batches: 0.0601\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 42826 batches: 0.0571\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 42924 batches: 0.0567\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 43022 batches: 0.0591\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 43120 batches: 0.0587\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 43218 batches: 0.0575\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 43316 batches: 0.0591\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 43414 batches: 0.0585\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 43512 batches: 0.0569\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 43610 batches: 0.0601\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 43708 batches: 0.0586\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 43806 batches: 0.0596\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 43904 batches: 0.0568\n",
      "Adjusting learning rate of group 0 to 6.1443e-05.\n",
      "Loss after 44002 batches: 0.0577\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 44100 batches: 0.0563\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 44198 batches: 0.0576\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 44296 batches: 0.0576\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 44394 batches: 0.0581\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 44492 batches: 0.0594\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 44590 batches: 0.0583\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 44688 batches: 0.0576\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 44786 batches: 0.0586\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 44884 batches: 0.0584\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 44982 batches: 0.0588\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 45080 batches: 0.0569\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 45178 batches: 0.0578\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 45276 batches: 0.0569\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 45374 batches: 0.0586\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 45472 batches: 0.0576\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 45570 batches: 0.0583\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 45668 batches: 0.0582\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 45766 batches: 0.0567\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 45864 batches: 0.0572\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 45962 batches: 0.0579\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 46060 batches: 0.0576\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 46158 batches: 0.0580\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 46256 batches: 0.0585\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 46354 batches: 0.0568\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 46452 batches: 0.0593\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 46550 batches: 0.0587\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 46648 batches: 0.0575\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 46746 batches: 0.0596\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 46844 batches: 0.0577\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 46942 batches: 0.0572\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 47040 batches: 0.0579\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 47138 batches: 0.0602\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 47236 batches: 0.0581\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 47334 batches: 0.0588\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 47432 batches: 0.0570\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 47530 batches: 0.0585\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 47628 batches: 0.0582\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 47726 batches: 0.0566\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 47824 batches: 0.0587\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 47922 batches: 0.0564\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 48020 batches: 0.0570\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 48118 batches: 0.0587\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 48216 batches: 0.0579\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 48314 batches: 0.0560\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 48412 batches: 0.0579\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 48510 batches: 0.0566\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 48608 batches: 0.0567\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 48706 batches: 0.0586\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 48804 batches: 0.0585\n",
      "Adjusting learning rate of group 0 to 5.5299e-05.\n",
      "Loss after 48902 batches: 0.0555\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 49000 batches: 0.0577\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 49098 batches: 0.0568\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 49196 batches: 0.0570\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 49294 batches: 0.0557\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 49392 batches: 0.0566\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 49490 batches: 0.0584\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 49588 batches: 0.0568\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 49686 batches: 0.0577\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 49784 batches: 0.0592\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 49882 batches: 0.0575\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 49980 batches: 0.0571\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 50078 batches: 0.0566\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 50176 batches: 0.0586\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 50274 batches: 0.0575\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 50372 batches: 0.0568\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 50470 batches: 0.0557\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 50568 batches: 0.0566\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 50666 batches: 0.0596\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 50764 batches: 0.0572\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 50862 batches: 0.0564\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 50960 batches: 0.0565\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 51058 batches: 0.0566\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 51156 batches: 0.0560\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 51254 batches: 0.0576\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 51352 batches: 0.0564\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 51450 batches: 0.0573\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 51548 batches: 0.0563\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 51646 batches: 0.0563\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 51744 batches: 0.0557\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 51842 batches: 0.0563\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 51940 batches: 0.0558\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 52038 batches: 0.0564\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 52136 batches: 0.0556\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 52234 batches: 0.0564\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 52332 batches: 0.0569\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 52430 batches: 0.0561\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 52528 batches: 0.0555\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 52626 batches: 0.0561\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 52724 batches: 0.0559\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 52822 batches: 0.0541\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 52920 batches: 0.0545\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 53018 batches: 0.0570\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 53116 batches: 0.0551\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 53214 batches: 0.0580\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 53312 batches: 0.0568\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 53410 batches: 0.0574\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 53508 batches: 0.0561\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 53606 batches: 0.0568\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 53704 batches: 0.0550\n",
      "Adjusting learning rate of group 0 to 4.9769e-05.\n",
      "Loss after 53802 batches: 0.0559\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 53900 batches: 0.0568\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 53998 batches: 0.0565\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 54096 batches: 0.0571\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 54194 batches: 0.0567\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 54292 batches: 0.0564\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 54390 batches: 0.0560\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 54488 batches: 0.0568\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 54586 batches: 0.0546\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 54684 batches: 0.0551\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 54782 batches: 0.0555\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 54880 batches: 0.0573\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 54978 batches: 0.0575\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 55076 batches: 0.0558\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 55174 batches: 0.0563\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 55272 batches: 0.0581\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 55370 batches: 0.0558\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 55468 batches: 0.0545\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 55566 batches: 0.0560\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 55664 batches: 0.0559\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 55762 batches: 0.0552\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 55860 batches: 0.0572\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 55958 batches: 0.0561\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 56056 batches: 0.0541\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 56154 batches: 0.0563\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 56252 batches: 0.0550\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 56350 batches: 0.0543\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 56448 batches: 0.0569\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 56546 batches: 0.0560\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 56644 batches: 0.0550\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 56742 batches: 0.0557\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 56840 batches: 0.0553\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 56938 batches: 0.0550\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 57036 batches: 0.0577\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 57134 batches: 0.0554\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 57232 batches: 0.0565\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 57330 batches: 0.0568\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 57428 batches: 0.0551\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 57526 batches: 0.0578\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 57624 batches: 0.0540\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 57722 batches: 0.0566\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 57820 batches: 0.0560\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 57918 batches: 0.0560\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 58016 batches: 0.0570\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 58114 batches: 0.0538\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 58212 batches: 0.0565\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 58310 batches: 0.0546\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 58408 batches: 0.0565\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 58506 batches: 0.0550\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 58604 batches: 0.0545\n",
      "Adjusting learning rate of group 0 to 4.4792e-05.\n",
      "Loss after 58702 batches: 0.0549\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 58800 batches: 0.0557\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 58898 batches: 0.0549\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 58996 batches: 0.0548\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 59094 batches: 0.0562\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 59192 batches: 0.0576\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 59290 batches: 0.0555\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 59388 batches: 0.0553\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 59486 batches: 0.0553\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 59584 batches: 0.0561\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 59682 batches: 0.0543\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 59780 batches: 0.0563\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 59878 batches: 0.0544\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 59976 batches: 0.0549\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 60074 batches: 0.0568\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 60172 batches: 0.0548\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 60270 batches: 0.0556\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 60368 batches: 0.0555\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 60466 batches: 0.0555\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 60564 batches: 0.0561\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 60662 batches: 0.0552\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 60760 batches: 0.0549\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 60858 batches: 0.0562\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 60956 batches: 0.0572\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 61054 batches: 0.0551\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 61152 batches: 0.0551\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 61250 batches: 0.0543\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 61348 batches: 0.0559\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 61446 batches: 0.0552\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 61544 batches: 0.0553\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 61642 batches: 0.0542\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 61740 batches: 0.0529\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 61838 batches: 0.0567\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 61936 batches: 0.0560\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 62034 batches: 0.0571\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 62132 batches: 0.0574\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 62230 batches: 0.0548\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 62328 batches: 0.0573\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 62426 batches: 0.0546\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 62524 batches: 0.0556\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 62622 batches: 0.0556\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 62720 batches: 0.0567\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 62818 batches: 0.0547\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 62916 batches: 0.0566\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 63014 batches: 0.0559\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 63112 batches: 0.0554\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 63210 batches: 0.0564\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 63308 batches: 0.0559\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 63406 batches: 0.0546\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 63504 batches: 0.0542\n",
      "Adjusting learning rate of group 0 to 4.0313e-05.\n",
      "Loss after 63602 batches: 0.0560\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 63700 batches: 0.0556\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 63798 batches: 0.0564\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 63896 batches: 0.0567\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 63994 batches: 0.0554\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 64092 batches: 0.0541\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 64190 batches: 0.0558\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 64288 batches: 0.0567\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 64386 batches: 0.0554\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 64484 batches: 0.0556\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 64582 batches: 0.0558\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 64680 batches: 0.0537\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 64778 batches: 0.0554\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 64876 batches: 0.0552\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 64974 batches: 0.0537\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 65072 batches: 0.0555\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 65170 batches: 0.0554\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 65268 batches: 0.0560\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 65366 batches: 0.0537\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 65464 batches: 0.0552\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 65562 batches: 0.0543\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 65660 batches: 0.0548\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 65758 batches: 0.0545\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 65856 batches: 0.0549\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 65954 batches: 0.0532\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 66052 batches: 0.0559\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 66150 batches: 0.0531\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 66248 batches: 0.0570\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 66346 batches: 0.0544\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 66444 batches: 0.0544\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 66542 batches: 0.0545\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 66640 batches: 0.0556\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 66738 batches: 0.0555\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 66836 batches: 0.0557\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 66934 batches: 0.0569\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 67032 batches: 0.0530\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 67130 batches: 0.0551\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 67228 batches: 0.0539\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 67326 batches: 0.0560\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 67424 batches: 0.0547\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 67522 batches: 0.0551\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 67620 batches: 0.0556\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 67718 batches: 0.0550\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 67816 batches: 0.0538\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 67914 batches: 0.0541\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 68012 batches: 0.0554\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 68110 batches: 0.0536\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 68208 batches: 0.0551\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 68306 batches: 0.0548\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 68404 batches: 0.0550\n",
      "Adjusting learning rate of group 0 to 3.6281e-05.\n",
      "Loss after 68502 batches: 0.0566\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 68600 batches: 0.0580\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 68698 batches: 0.0537\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 68796 batches: 0.0551\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 68894 batches: 0.0532\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 68992 batches: 0.0555\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 69090 batches: 0.0569\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 69188 batches: 0.0553\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 69286 batches: 0.0557\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 69384 batches: 0.0555\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 69482 batches: 0.0566\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 69580 batches: 0.0540\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 69678 batches: 0.0532\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 69776 batches: 0.0553\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 69874 batches: 0.0562\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 69972 batches: 0.0551\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 70070 batches: 0.0545\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 70168 batches: 0.0532\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 70266 batches: 0.0544\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 70364 batches: 0.0544\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 70462 batches: 0.0547\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 70560 batches: 0.0560\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 70658 batches: 0.0571\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 70756 batches: 0.0566\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 70854 batches: 0.0547\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 70952 batches: 0.0533\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 71050 batches: 0.0558\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 71148 batches: 0.0544\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 71246 batches: 0.0540\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 71344 batches: 0.0560\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 71442 batches: 0.0567\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 71540 batches: 0.0540\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 71638 batches: 0.0565\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 71736 batches: 0.0563\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 71834 batches: 0.0558\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 71932 batches: 0.0572\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 72030 batches: 0.0547\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 72128 batches: 0.0553\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 72226 batches: 0.0526\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 72324 batches: 0.0547\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 72422 batches: 0.0567\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 72520 batches: 0.0542\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 72618 batches: 0.0541\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 72716 batches: 0.0547\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 72814 batches: 0.0541\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 72912 batches: 0.0537\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 73010 batches: 0.0552\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 73108 batches: 0.0541\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 73206 batches: 0.0543\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 73304 batches: 0.0559\n",
      "Adjusting learning rate of group 0 to 3.2653e-05.\n",
      "Loss after 73402 batches: 0.0566\n",
      "Adjusting learning rate of group 0 to 2.9388e-05.\n",
      "Loss after 73500 batches: 0.0553\n",
      "Time to train on one home:  215.24895358085632\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 41016<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\wandb\\run-20211119_190025-1lsee4b1\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\wandb\\run-20211119_190025-1lsee4b1\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_F1_Score</td><td>0.62907</td></tr><tr><td>Test_MAE</td><td>16.13383</td></tr><tr><td>Test_MSE</td><td>0.11221</td></tr><tr><td>Test_NDE</td><td>0.27465</td></tr><tr><td>Test_NEP</td><td>0.70519</td></tr><tr><td>Test_R2_Value</td><td>-2.70758</td></tr><tr><td>Training_F1</td><td>0.72296</td></tr><tr><td>Training_MAE</td><td>18.81332</td></tr><tr><td>Training_MSE</td><td>0.05527</td></tr><tr><td>Training_NDE</td><td>0.3147</td></tr><tr><td>Training_NEP</td><td>0.48282</td></tr><tr><td>Training_R2</td><td>-0.00787</td></tr><tr><td>Validation_F1</td><td>0.59704</td></tr><tr><td>Validation_MAE</td><td>26.94384</td></tr><tr><td>Validation_MSE</td><td>0.11804</td></tr><tr><td>Validation_NDE</td><td>0.43865</td></tr><tr><td>Validation_NEP</td><td>0.61403</td></tr><tr><td>Validation_R2</td><td>-0.73685</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_F1_Score</td><td>▁</td></tr><tr><td>Test_MAE</td><td>▁</td></tr><tr><td>Test_MSE</td><td>▁</td></tr><tr><td>Test_NDE</td><td>▁</td></tr><tr><td>Test_NEP</td><td>▁</td></tr><tr><td>Test_R2_Value</td><td>▁</td></tr><tr><td>Training_F1</td><td>▁▁▁▁▁▁▂▃▃▅▆▆▇▇▇▇▇▇█▇████████████████████</td></tr><tr><td>Training_MAE</td><td>█▇▇▇▇▇▇▆▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Training_MSE</td><td>█▆▆▆▆▅▅▅▄▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Training_NDE</td><td>█▆▆▆▆▆▅▄▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Training_NEP</td><td>█▇▇▇▇▇▇▆▅▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Training_R2</td><td>▁▃▄▄▄▄▄▅▅▆▇▇▇▇▇███▇████▇████████████████</td></tr><tr><td>Validation_F1</td><td>▄▁▁▂▂▂▄▅▆▇████▇▆▆▆▆▅▇▆▇▇▇▇▇▆▆▇█▇▇▆▇▆▇▆▇▇</td></tr><tr><td>Validation_MAE</td><td>▇███▇▇▇▆▅▄▃▂▂▁▂▂▂▂▂▂▁▂▂▁▁▁▂▂▂▁▁▁▁▂▂▂▁▂▁▁</td></tr><tr><td>Validation_MSE</td><td>▇██▇▇▇▆▅▄▃▂▁▁▁▂▂▃▃▃▃▂▂▃▂▂▂▂▂▃▂▂▂▂▃▂▃▂▃▂▂</td></tr><tr><td>Validation_NDE</td><td>▇██▇▇▇▆▅▄▃▂▁▁▁▂▂▂▂▃▃▂▂▂▂▂▁▂▂▂▂▂▂▁▂▂▂▂▂▂▂</td></tr><tr><td>Validation_NEP</td><td>▇███▇▇▇▆▅▄▃▂▂▁▂▂▂▂▂▂▁▂▂▁▁▁▂▂▂▁▁▁▁▂▂▂▁▂▁▁</td></tr><tr><td>Validation_R2</td><td>▃▁▁▂▂▂▄▅▆▇███▇▆▅▄▄▄▄▅▄▄▅▅▅▄▄▄▄▅▄▅▄▄▄▄▄▄▄</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">fresh-fog-490</strong>: <a href=\"https://wandb.ai/nilm/Drye1_single_houses/runs/1lsee4b1\" target=\"_blank\">https://wandb.ai/nilm/Drye1_single_houses/runs/1lsee4b1</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-19 19:05:28,654]\u001b[0m Trial 3 finished with value: 0.11220970749855042 and parameters: {'hidden_size_1': 41, 'hidden_size_2': 289, 'fc1': 376, 'fc2': 6, 'weight_decay': 0.07221882989457616, 'learning_rate': 0.00014273527847785615, 'window_size': 56}. Best is trial 3 with value: 0.11220970749855042.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">graceful-cherry-491</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nilm/Drye1_single_houses\" target=\"_blank\">https://wandb.ai/nilm/Drye1_single_houses</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/nilm/Drye1_single_houses/runs/gxo58kb5\" target=\"_blank\">https://wandb.ai/nilm/Drye1_single_houses/runs/gxo58kb5</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\wandb\\run-20211119_190528-gxo58kb5</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (conv1): Conv1d(1, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "  (lstm1): LSTM(16, 41, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (lstm2): LSTM(82, 316, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (linear1): Linear(in_features=632, out_features=299, bias=True)\n",
      "  (linear2): Linear(in_features=299, out_features=28, bias=True)\n",
      "  (linear3): Linear(in_features=28, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 00099 batches: 0.4146\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 00198 batches: 0.4150\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 00297 batches: 0.4090\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 00396 batches: 0.3983\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 00495 batches: 0.3896\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 00594 batches: 0.3817\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 00693 batches: 0.3797\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 00792 batches: 0.3811\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 00891 batches: 0.3680\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 00990 batches: 0.3668\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 01089 batches: 0.3609\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 01188 batches: 0.3551\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 01287 batches: 0.3532\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 01386 batches: 0.3471\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 01485 batches: 0.3419\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 01584 batches: 0.3351\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 01683 batches: 0.3297\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 01782 batches: 0.3268\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 01881 batches: 0.3245\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 01980 batches: 0.3230\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 02079 batches: 0.3177\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 02178 batches: 0.3168\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 02277 batches: 0.3181\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 02376 batches: 0.3022\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 02475 batches: 0.3084\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 02574 batches: 0.3014\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 02673 batches: 0.3004\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 02772 batches: 0.3028\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 02871 batches: 0.2957\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 02970 batches: 0.2959\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 03069 batches: 0.2911\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 03168 batches: 0.2923\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 03267 batches: 0.2844\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 03366 batches: 0.2878\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 03465 batches: 0.2902\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 03564 batches: 0.2878\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 03663 batches: 0.2806\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 03762 batches: 0.2734\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 03861 batches: 0.2717\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 03960 batches: 0.2710\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 04059 batches: 0.2764\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 04158 batches: 0.2722\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 04257 batches: 0.2692\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 04356 batches: 0.2671\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 04455 batches: 0.2660\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 04554 batches: 0.2652\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 04653 batches: 0.2683\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 04752 batches: 0.2675\n",
      "Adjusting learning rate of group 0 to 4.2002e-05.\n",
      "Loss after 04851 batches: 0.2622\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 04950 batches: 0.2626\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 05049 batches: 0.2613\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 05148 batches: 0.2626\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 05247 batches: 0.2587\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 05346 batches: 0.2607\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 05445 batches: 0.2622\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 05544 batches: 0.2513\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 05643 batches: 0.2539\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 05742 batches: 0.2595\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 05841 batches: 0.2492\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 05940 batches: 0.2608\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 06039 batches: 0.2537\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 06138 batches: 0.2498\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 06237 batches: 0.2571\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 06336 batches: 0.2529\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 06435 batches: 0.2544\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 06534 batches: 0.2478\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 06633 batches: 0.2619\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 06732 batches: 0.2599\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 06831 batches: 0.2545\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 06930 batches: 0.2463\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 07029 batches: 0.2550\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 07128 batches: 0.2465\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 07227 batches: 0.2513\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 07326 batches: 0.2518\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 07425 batches: 0.2462\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 07524 batches: 0.2522\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 07623 batches: 0.2518\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 07722 batches: 0.2470\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 07821 batches: 0.2473\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 07920 batches: 0.2448\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 08019 batches: 0.2448\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 08118 batches: 0.2467\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 08217 batches: 0.2486\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 08316 batches: 0.2414\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 08415 batches: 0.2445\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 08514 batches: 0.2453\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 08613 batches: 0.2406\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 08712 batches: 0.2436\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 08811 batches: 0.2454\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 08910 batches: 0.2386\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 09009 batches: 0.2386\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 09108 batches: 0.2411\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 09207 batches: 0.2436\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 09306 batches: 0.2476\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 09405 batches: 0.2378\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 09504 batches: 0.2392\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 09603 batches: 0.2410\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 09702 batches: 0.2390\n",
      "Adjusting learning rate of group 0 to 3.7802e-05.\n",
      "Loss after 09801 batches: 0.2416\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 09900 batches: 0.2397\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 09999 batches: 0.2436\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 10098 batches: 0.2388\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 10197 batches: 0.2346\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 10296 batches: 0.2426\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 10395 batches: 0.2341\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 10494 batches: 0.2383\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 10593 batches: 0.2435\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 10692 batches: 0.2412\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 10791 batches: 0.2416\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 10890 batches: 0.2385\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 10989 batches: 0.2405\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 11088 batches: 0.2402\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 11187 batches: 0.2363\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 11286 batches: 0.2281\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 11385 batches: 0.2366\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 11484 batches: 0.2325\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 11583 batches: 0.2360\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 11682 batches: 0.2343\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 11781 batches: 0.2316\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 11880 batches: 0.2328\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 11979 batches: 0.2370\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 12078 batches: 0.2388\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 12177 batches: 0.2316\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 12276 batches: 0.2303\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 12375 batches: 0.2403\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 12474 batches: 0.2387\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 12573 batches: 0.2316\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 12672 batches: 0.2313\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 12771 batches: 0.2276\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 12870 batches: 0.2305\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 12969 batches: 0.2305\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 13068 batches: 0.2249\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 13167 batches: 0.2288\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 13266 batches: 0.2265\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 13365 batches: 0.2295\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 13464 batches: 0.2292\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 13563 batches: 0.2321\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 13662 batches: 0.2262\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 13761 batches: 0.2303\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 13860 batches: 0.2338\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 13959 batches: 0.2316\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 14058 batches: 0.2278\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 14157 batches: 0.2273\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 14256 batches: 0.2232\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 14355 batches: 0.2229\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 14454 batches: 0.2269\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 14553 batches: 0.2282\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 14652 batches: 0.2240\n",
      "Adjusting learning rate of group 0 to 3.4022e-05.\n",
      "Loss after 14751 batches: 0.2215\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 14850 batches: 0.2244\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 14949 batches: 0.2219\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 15048 batches: 0.2291\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 15147 batches: 0.2286\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 15246 batches: 0.2231\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 15345 batches: 0.2226\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 15444 batches: 0.2204\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 15543 batches: 0.2262\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 15642 batches: 0.2210\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 15741 batches: 0.2241\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 15840 batches: 0.2199\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 15939 batches: 0.2212\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 16038 batches: 0.2221\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 16137 batches: 0.2192\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 16236 batches: 0.2257\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 16335 batches: 0.2231\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 16434 batches: 0.2217\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 16533 batches: 0.2204\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 16632 batches: 0.2160\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 16731 batches: 0.2222\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 16830 batches: 0.2172\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 16929 batches: 0.2156\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 17028 batches: 0.2217\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 17127 batches: 0.2142\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 17226 batches: 0.2125\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 17325 batches: 0.2194\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 17424 batches: 0.2172\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 17523 batches: 0.2143\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 17622 batches: 0.2126\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 17721 batches: 0.2148\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 17820 batches: 0.2159\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 17919 batches: 0.2154\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 18018 batches: 0.2118\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 18117 batches: 0.2145\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 18216 batches: 0.2215\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 18315 batches: 0.2116\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 18414 batches: 0.2144\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 18513 batches: 0.2235\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 18612 batches: 0.2104\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 18711 batches: 0.2139\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 18810 batches: 0.2131\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 18909 batches: 0.2166\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 19008 batches: 0.2131\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 19107 batches: 0.2127\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 19206 batches: 0.2140\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 19305 batches: 0.2115\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 19404 batches: 0.2105\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 19503 batches: 0.2102\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 19602 batches: 0.2136\n",
      "Adjusting learning rate of group 0 to 3.0620e-05.\n",
      "Loss after 19701 batches: 0.2045\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 19800 batches: 0.2059\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 19899 batches: 0.2131\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 19998 batches: 0.2116\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 20097 batches: 0.2148\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 20196 batches: 0.2104\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 20295 batches: 0.2090\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 20394 batches: 0.2108\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 20493 batches: 0.2105\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 20592 batches: 0.2068\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 20691 batches: 0.2122\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 20790 batches: 0.2082\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 20889 batches: 0.2054\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 20988 batches: 0.2032\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 21087 batches: 0.2065\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 21186 batches: 0.2057\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 21285 batches: 0.2037\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 21384 batches: 0.2039\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 21483 batches: 0.2086\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 21582 batches: 0.2069\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 21681 batches: 0.1997\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 21780 batches: 0.2003\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 21879 batches: 0.2054\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 21978 batches: 0.2024\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 22077 batches: 0.2093\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 22176 batches: 0.2049\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 22275 batches: 0.2045\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 22374 batches: 0.2020\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 22473 batches: 0.2036\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 22572 batches: 0.2064\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 22671 batches: 0.2044\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 22770 batches: 0.2045\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 22869 batches: 0.2020\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 22968 batches: 0.2013\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 23067 batches: 0.2007\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 23166 batches: 0.2026\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 23265 batches: 0.2047\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 23364 batches: 0.1992\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 23463 batches: 0.2045\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 23562 batches: 0.1995\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 23661 batches: 0.1961\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 23760 batches: 0.1995\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 23859 batches: 0.2054\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 23958 batches: 0.1964\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 24057 batches: 0.1980\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 24156 batches: 0.2003\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 24255 batches: 0.2000\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 24354 batches: 0.2002\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 24453 batches: 0.1965\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 24552 batches: 0.1984\n",
      "Adjusting learning rate of group 0 to 2.7558e-05.\n",
      "Loss after 24651 batches: 0.1956\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 24750 batches: 0.2009\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 24849 batches: 0.2002\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 24948 batches: 0.1930\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 25047 batches: 0.1959\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 25146 batches: 0.1959\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 25245 batches: 0.1983\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 25344 batches: 0.1976\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 25443 batches: 0.1959\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 25542 batches: 0.1982\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 25641 batches: 0.1930\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 25740 batches: 0.2039\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 25839 batches: 0.1953\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 25938 batches: 0.1947\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 26037 batches: 0.1947\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 26136 batches: 0.1974\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 26235 batches: 0.1924\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 26334 batches: 0.1911\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 26433 batches: 0.1915\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 26532 batches: 0.1924\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 26631 batches: 0.1956\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 26730 batches: 0.1934\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 26829 batches: 0.1899\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 26928 batches: 0.1934\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 27027 batches: 0.1919\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 27126 batches: 0.1870\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 27225 batches: 0.1964\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 27324 batches: 0.1881\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 27423 batches: 0.1917\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 27522 batches: 0.1918\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 27621 batches: 0.1908\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 27720 batches: 0.1925\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 27819 batches: 0.1935\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 27918 batches: 0.1919\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 28017 batches: 0.1879\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 28116 batches: 0.1873\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 28215 batches: 0.1911\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 28314 batches: 0.1894\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 28413 batches: 0.1879\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 28512 batches: 0.1857\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 28611 batches: 0.1908\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 28710 batches: 0.1843\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 28809 batches: 0.1880\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 28908 batches: 0.1872\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 29007 batches: 0.1869\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 29106 batches: 0.1850\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 29205 batches: 0.1884\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 29304 batches: 0.1847\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 29403 batches: 0.1872\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 29502 batches: 0.1849\n",
      "Adjusting learning rate of group 0 to 2.4802e-05.\n",
      "Loss after 29601 batches: 0.1857\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 29700 batches: 0.1823\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 29799 batches: 0.1858\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 29898 batches: 0.1875\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 29997 batches: 0.1833\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 30096 batches: 0.1854\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 30195 batches: 0.1889\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 30294 batches: 0.1872\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 30393 batches: 0.1846\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 30492 batches: 0.1881\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 30591 batches: 0.1818\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 30690 batches: 0.1869\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 30789 batches: 0.1841\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 30888 batches: 0.1798\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 30987 batches: 0.1853\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 31086 batches: 0.1841\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 31185 batches: 0.1832\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 31284 batches: 0.1820\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 31383 batches: 0.1806\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 31482 batches: 0.1850\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 31581 batches: 0.1810\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 31680 batches: 0.1801\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 31779 batches: 0.1881\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 31878 batches: 0.1784\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 31977 batches: 0.1807\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 32076 batches: 0.1813\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 32175 batches: 0.1817\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 32274 batches: 0.1793\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 32373 batches: 0.1786\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 32472 batches: 0.1844\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 32571 batches: 0.1763\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 32670 batches: 0.1820\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 32769 batches: 0.1812\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 32868 batches: 0.1801\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 32967 batches: 0.1782\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 33066 batches: 0.1804\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 33165 batches: 0.1815\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 33264 batches: 0.1792\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 33363 batches: 0.1825\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 33462 batches: 0.1781\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 33561 batches: 0.1770\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 33660 batches: 0.1769\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 33759 batches: 0.1794\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 33858 batches: 0.1782\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 33957 batches: 0.1777\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 34056 batches: 0.1771\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 34155 batches: 0.1754\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 34254 batches: 0.1790\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 34353 batches: 0.1774\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 34452 batches: 0.1745\n",
      "Adjusting learning rate of group 0 to 2.2322e-05.\n",
      "Loss after 34551 batches: 0.1752\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 34650 batches: 0.1768\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 34749 batches: 0.1741\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 34848 batches: 0.1750\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 34947 batches: 0.1738\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 35046 batches: 0.1749\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 35145 batches: 0.1729\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 35244 batches: 0.1692\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 35343 batches: 0.1722\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 35442 batches: 0.1768\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 35541 batches: 0.1711\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 35640 batches: 0.1724\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 35739 batches: 0.1753\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 35838 batches: 0.1759\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 35937 batches: 0.1720\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 36036 batches: 0.1744\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 36135 batches: 0.1712\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 36234 batches: 0.1724\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 36333 batches: 0.1703\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 36432 batches: 0.1690\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 36531 batches: 0.1753\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 36630 batches: 0.1724\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 36729 batches: 0.1715\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 36828 batches: 0.1675\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 36927 batches: 0.1693\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 37026 batches: 0.1697\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 37125 batches: 0.1750\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 37224 batches: 0.1701\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 37323 batches: 0.1698\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 37422 batches: 0.1735\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 37521 batches: 0.1720\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 37620 batches: 0.1694\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 37719 batches: 0.1758\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 37818 batches: 0.1705\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 37917 batches: 0.1692\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 38016 batches: 0.1715\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 38115 batches: 0.1707\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 38214 batches: 0.1706\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 38313 batches: 0.1679\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 38412 batches: 0.1711\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 38511 batches: 0.1693\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 38610 batches: 0.1689\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 38709 batches: 0.1699\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 38808 batches: 0.1689\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 38907 batches: 0.1714\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 39006 batches: 0.1672\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 39105 batches: 0.1660\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 39204 batches: 0.1682\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 39303 batches: 0.1684\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 39402 batches: 0.1719\n",
      "Adjusting learning rate of group 0 to 2.0089e-05.\n",
      "Loss after 39501 batches: 0.1659\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 39600 batches: 0.1660\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 39699 batches: 0.1669\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 39798 batches: 0.1670\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 39897 batches: 0.1645\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 39996 batches: 0.1677\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 40095 batches: 0.1690\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 40194 batches: 0.1609\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 40293 batches: 0.1698\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 40392 batches: 0.1625\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 40491 batches: 0.1658\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 40590 batches: 0.1637\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 40689 batches: 0.1669\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 40788 batches: 0.1627\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 40887 batches: 0.1634\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 40986 batches: 0.1661\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 41085 batches: 0.1681\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 41184 batches: 0.1680\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 41283 batches: 0.1647\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 41382 batches: 0.1611\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 41481 batches: 0.1639\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 41580 batches: 0.1611\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 41679 batches: 0.1603\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 41778 batches: 0.1677\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 41877 batches: 0.1609\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 41976 batches: 0.1637\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 42075 batches: 0.1636\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 42174 batches: 0.1618\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 42273 batches: 0.1636\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 42372 batches: 0.1620\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 42471 batches: 0.1602\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 42570 batches: 0.1607\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 42669 batches: 0.1612\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 42768 batches: 0.1606\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 42867 batches: 0.1633\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 42966 batches: 0.1580\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 43065 batches: 0.1628\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 43164 batches: 0.1624\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 43263 batches: 0.1622\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 43362 batches: 0.1589\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 43461 batches: 0.1603\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 43560 batches: 0.1625\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 43659 batches: 0.1590\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 43758 batches: 0.1611\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 43857 batches: 0.1596\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 43956 batches: 0.1576\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 44055 batches: 0.1582\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 44154 batches: 0.1625\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 44253 batches: 0.1585\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 44352 batches: 0.1571\n",
      "Adjusting learning rate of group 0 to 1.8081e-05.\n",
      "Loss after 44451 batches: 0.1542\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 44550 batches: 0.1598\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 44649 batches: 0.1625\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 44748 batches: 0.1558\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 44847 batches: 0.1548\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 44946 batches: 0.1579\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 45045 batches: 0.1534\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 45144 batches: 0.1561\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 45243 batches: 0.1538\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 45342 batches: 0.1563\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 45441 batches: 0.1551\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 45540 batches: 0.1574\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 45639 batches: 0.1564\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 45738 batches: 0.1565\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 45837 batches: 0.1544\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 45936 batches: 0.1542\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 46035 batches: 0.1579\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 46134 batches: 0.1629\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 46233 batches: 0.1551\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 46332 batches: 0.1554\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 46431 batches: 0.1561\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 46530 batches: 0.1567\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 46629 batches: 0.1527\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 46728 batches: 0.1600\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 46827 batches: 0.1553\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 46926 batches: 0.1556\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 47025 batches: 0.1537\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 47124 batches: 0.1509\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 47223 batches: 0.1540\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 47322 batches: 0.1546\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 47421 batches: 0.1554\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 47520 batches: 0.1545\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 47619 batches: 0.1564\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 47718 batches: 0.1536\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 47817 batches: 0.1539\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 47916 batches: 0.1565\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 48015 batches: 0.1526\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 48114 batches: 0.1487\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 48213 batches: 0.1532\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 48312 batches: 0.1500\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 48411 batches: 0.1530\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 48510 batches: 0.1516\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 48609 batches: 0.1522\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 48708 batches: 0.1499\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 48807 batches: 0.1498\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 48906 batches: 0.1501\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 49005 batches: 0.1536\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 49104 batches: 0.1560\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 49203 batches: 0.1559\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 49302 batches: 0.1513\n",
      "Adjusting learning rate of group 0 to 1.6272e-05.\n",
      "Loss after 49401 batches: 0.1543\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 49500 batches: 0.1497\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 49599 batches: 0.1508\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 49698 batches: 0.1491\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 49797 batches: 0.1524\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 49896 batches: 0.1500\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 49995 batches: 0.1522\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 50094 batches: 0.1534\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 50193 batches: 0.1490\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 50292 batches: 0.1497\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 50391 batches: 0.1530\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 50490 batches: 0.1523\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 50589 batches: 0.1507\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 50688 batches: 0.1494\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 50787 batches: 0.1520\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 50886 batches: 0.1472\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 50985 batches: 0.1447\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 51084 batches: 0.1481\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 51183 batches: 0.1446\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 51282 batches: 0.1482\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 51381 batches: 0.1505\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 51480 batches: 0.1487\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 51579 batches: 0.1500\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 51678 batches: 0.1461\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 51777 batches: 0.1471\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 51876 batches: 0.1462\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 51975 batches: 0.1434\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 52074 batches: 0.1412\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 52173 batches: 0.1517\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 52272 batches: 0.1390\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 52371 batches: 0.1440\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 52470 batches: 0.1460\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 52569 batches: 0.1469\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 52668 batches: 0.1453\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 52767 batches: 0.1469\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 52866 batches: 0.1432\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 52965 batches: 0.1502\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 53064 batches: 0.1458\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 53163 batches: 0.1463\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 53262 batches: 0.1420\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 53361 batches: 0.1471\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 53460 batches: 0.1407\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 53559 batches: 0.1441\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 53658 batches: 0.1448\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 53757 batches: 0.1446\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 53856 batches: 0.1410\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 53955 batches: 0.1470\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 54054 batches: 0.1399\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 54153 batches: 0.1451\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 54252 batches: 0.1400\n",
      "Adjusting learning rate of group 0 to 1.4645e-05.\n",
      "Loss after 54351 batches: 0.1437\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 54450 batches: 0.1448\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 54549 batches: 0.1403\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 54648 batches: 0.1419\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 54747 batches: 0.1445\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 54846 batches: 0.1405\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 54945 batches: 0.1458\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 55044 batches: 0.1415\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 55143 batches: 0.1433\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 55242 batches: 0.1422\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 55341 batches: 0.1424\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 55440 batches: 0.1415\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 55539 batches: 0.1440\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 55638 batches: 0.1429\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 55737 batches: 0.1454\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 55836 batches: 0.1410\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 55935 batches: 0.1415\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 56034 batches: 0.1384\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 56133 batches: 0.1373\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 56232 batches: 0.1423\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 56331 batches: 0.1439\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 56430 batches: 0.1398\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 56529 batches: 0.1423\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 56628 batches: 0.1373\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 56727 batches: 0.1406\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 56826 batches: 0.1362\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 56925 batches: 0.1412\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 57024 batches: 0.1439\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 57123 batches: 0.1379\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 57222 batches: 0.1414\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 57321 batches: 0.1344\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 57420 batches: 0.1398\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 57519 batches: 0.1402\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 57618 batches: 0.1422\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 57717 batches: 0.1412\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 57816 batches: 0.1401\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 57915 batches: 0.1387\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 58014 batches: 0.1408\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 58113 batches: 0.1387\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 58212 batches: 0.1382\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 58311 batches: 0.1400\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 58410 batches: 0.1366\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 58509 batches: 0.1381\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 58608 batches: 0.1388\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 58707 batches: 0.1360\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 58806 batches: 0.1378\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 58905 batches: 0.1351\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 59004 batches: 0.1376\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 59103 batches: 0.1373\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 59202 batches: 0.1358\n",
      "Adjusting learning rate of group 0 to 1.3181e-05.\n",
      "Loss after 59301 batches: 0.1351\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 59400 batches: 0.1369\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 59499 batches: 0.1333\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 59598 batches: 0.1373\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 59697 batches: 0.1377\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 59796 batches: 0.1333\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 59895 batches: 0.1364\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 59994 batches: 0.1358\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 60093 batches: 0.1329\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 60192 batches: 0.1386\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 60291 batches: 0.1384\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 60390 batches: 0.1373\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 60489 batches: 0.1349\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 60588 batches: 0.1357\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 60687 batches: 0.1396\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 60786 batches: 0.1382\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 60885 batches: 0.1368\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 60984 batches: 0.1309\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 61083 batches: 0.1385\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 61182 batches: 0.1372\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 61281 batches: 0.1326\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 61380 batches: 0.1369\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 61479 batches: 0.1343\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 61578 batches: 0.1361\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 61677 batches: 0.1353\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 61776 batches: 0.1373\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 61875 batches: 0.1334\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 61974 batches: 0.1357\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 62073 batches: 0.1371\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 62172 batches: 0.1348\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 62271 batches: 0.1308\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 62370 batches: 0.1381\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 62469 batches: 0.1328\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 62568 batches: 0.1360\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 62667 batches: 0.1351\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 62766 batches: 0.1360\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 62865 batches: 0.1346\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 62964 batches: 0.1334\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 63063 batches: 0.1318\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 63162 batches: 0.1380\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 63261 batches: 0.1319\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 63360 batches: 0.1294\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 63459 batches: 0.1337\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 63558 batches: 0.1301\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 63657 batches: 0.1317\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 63756 batches: 0.1312\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 63855 batches: 0.1363\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 63954 batches: 0.1307\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 64053 batches: 0.1288\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 64152 batches: 0.1322\n",
      "Adjusting learning rate of group 0 to 1.1863e-05.\n",
      "Loss after 64251 batches: 0.1315\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 64350 batches: 0.1305\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 64449 batches: 0.1258\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 64548 batches: 0.1336\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 64647 batches: 0.1272\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 64746 batches: 0.1311\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 64845 batches: 0.1329\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 64944 batches: 0.1296\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 65043 batches: 0.1335\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 65142 batches: 0.1302\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 65241 batches: 0.1315\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 65340 batches: 0.1296\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 65439 batches: 0.1293\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 65538 batches: 0.1293\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 65637 batches: 0.1331\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 65736 batches: 0.1298\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 65835 batches: 0.1320\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 65934 batches: 0.1311\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 66033 batches: 0.1275\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 66132 batches: 0.1277\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 66231 batches: 0.1313\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 66330 batches: 0.1313\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 66429 batches: 0.1269\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 66528 batches: 0.1276\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 66627 batches: 0.1267\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 66726 batches: 0.1271\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 66825 batches: 0.1314\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 66924 batches: 0.1309\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 67023 batches: 0.1280\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 67122 batches: 0.1244\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 67221 batches: 0.1251\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 67320 batches: 0.1257\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 67419 batches: 0.1322\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 67518 batches: 0.1286\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 67617 batches: 0.1292\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 67716 batches: 0.1231\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 67815 batches: 0.1318\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 67914 batches: 0.1266\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 68013 batches: 0.1275\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 68112 batches: 0.1254\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 68211 batches: 0.1260\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 68310 batches: 0.1236\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 68409 batches: 0.1243\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 68508 batches: 0.1276\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after 68607 batches: 0.1246\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 68706 batches: 0.1324\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 68805 batches: 0.1226\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 68904 batches: 0.1266\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 69003 batches: 0.1274\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 69102 batches: 0.1277\n",
      "Adjusting learning rate of group 0 to 1.0676e-05.\n",
      "Loss after 69201 batches: 0.1267\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 69300 batches: 0.1281\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 69399 batches: 0.1286\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 69498 batches: 0.1271\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 69597 batches: 0.1254\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 69696 batches: 0.1299\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 69795 batches: 0.1289\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 69894 batches: 0.1265\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 69993 batches: 0.1243\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 70092 batches: 0.1247\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 70191 batches: 0.1264\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 70290 batches: 0.1239\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 70389 batches: 0.1240\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 70488 batches: 0.1268\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 70587 batches: 0.1268\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 70686 batches: 0.1222\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 70785 batches: 0.1243\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 70884 batches: 0.1230\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 70983 batches: 0.1279\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 71082 batches: 0.1289\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 71181 batches: 0.1264\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 71280 batches: 0.1249\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 71379 batches: 0.1261\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 71478 batches: 0.1231\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 71577 batches: 0.1241\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 71676 batches: 0.1228\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 71775 batches: 0.1263\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 71874 batches: 0.1237\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 71973 batches: 0.1246\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 72072 batches: 0.1173\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 72171 batches: 0.1237\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 72270 batches: 0.1251\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 72369 batches: 0.1209\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 72468 batches: 0.1220\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 72567 batches: 0.1219\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 72666 batches: 0.1254\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 72765 batches: 0.1256\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 72864 batches: 0.1254\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 72963 batches: 0.1216\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 73062 batches: 0.1249\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 73161 batches: 0.1213\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 73260 batches: 0.1188\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 73359 batches: 0.1215\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 73458 batches: 0.1237\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 73557 batches: 0.1200\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 73656 batches: 0.1200\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 73755 batches: 0.1231\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 73854 batches: 0.1193\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 73953 batches: 0.1222\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 74052 batches: 0.1233\n",
      "Adjusting learning rate of group 0 to 9.6087e-06.\n",
      "Loss after 74151 batches: 0.1195\n",
      "Adjusting learning rate of group 0 to 8.6479e-06.\n",
      "Loss after 74250 batches: 0.1217\n",
      "Time to train on one home:  213.904212474823\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 41284<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\wandb\\run-20211119_190528-gxo58kb5\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\wandb\\run-20211119_190528-gxo58kb5\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_F1_Score</td><td>0.53477</td></tr><tr><td>Test_MAE</td><td>15.52647</td></tr><tr><td>Test_MSE</td><td>0.11691</td></tr><tr><td>Test_NDE</td><td>0.32839</td></tr><tr><td>Test_NEP</td><td>0.87224</td></tr><tr><td>Test_R2_Value</td><td>-3.72347</td></tr><tr><td>Training_F1</td><td>0.62615</td></tr><tr><td>Training_MAE</td><td>24.64107</td></tr><tr><td>Training_MSE</td><td>0.12171</td></tr><tr><td>Training_NDE</td><td>0.52407</td></tr><tr><td>Training_NEP</td><td>0.64595</td></tr><tr><td>Training_R2</td><td>-0.91938</td></tr><tr><td>Validation_F1</td><td>0.53828</td></tr><tr><td>Validation_MAE</td><td>26.5388</td></tr><tr><td>Validation_MSE</td><td>0.12896</td></tr><tr><td>Validation_NDE</td><td>0.50051</td></tr><tr><td>Validation_NEP</td><td>0.72132</td></tr><tr><td>Validation_R2</td><td>-2.02577</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_F1_Score</td><td>▁</td></tr><tr><td>Test_MAE</td><td>▁</td></tr><tr><td>Test_MSE</td><td>▁</td></tr><tr><td>Test_NDE</td><td>▁</td></tr><tr><td>Test_NEP</td><td>▁</td></tr><tr><td>Test_R2_Value</td><td>▁</td></tr><tr><td>Training_F1</td><td>▁▄▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>Training_MAE</td><td>█▇▇▆▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▂▁▁</td></tr><tr><td>Training_MSE</td><td>█▆▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Training_NDE</td><td>█▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>Training_NEP</td><td>█▇▇▆▆▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▂▁▁</td></tr><tr><td>Training_R2</td><td>▁▃▃▂▂▁▃▃▃▄▄▄▄▄▅▅▅▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████</td></tr><tr><td>Validation_F1</td><td>▁▄▆▇███████████████████▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Validation_MAE</td><td>█▇▅▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>Validation_MSE</td><td>█▅▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁</td></tr><tr><td>Validation_NDE</td><td>█▅▄▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▁▁</td></tr><tr><td>Validation_NEP</td><td>█▇▅▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>Validation_R2</td><td>▁▄▆▇██████████████████████████▇▇▇▇▇▇▇█▇▇</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">graceful-cherry-491</strong>: <a href=\"https://wandb.ai/nilm/Drye1_single_houses/runs/gxo58kb5\" target=\"_blank\">https://wandb.ai/nilm/Drye1_single_houses/runs/gxo58kb5</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-19 19:10:31,351]\u001b[0m Trial 4 finished with value: 0.11691244691610336 and parameters: {'hidden_size_1': 41, 'hidden_size_2': 316, 'fc1': 299, 'fc2': 28, 'weight_decay': 0.06474963344976757, 'learning_rate': 4.200211764688184e-05, 'window_size': 50}. Best is trial 3 with value: 0.11220970749855042.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">peachy-wildflower-492</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nilm/Drye1_single_houses\" target=\"_blank\">https://wandb.ai/nilm/Drye1_single_houses</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/nilm/Drye1_single_houses/runs/mkd43wtc\" target=\"_blank\">https://wandb.ai/nilm/Drye1_single_houses/runs/mkd43wtc</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\wandb\\run-20211119_191031-mkd43wtc</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (conv1): Conv1d(1, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "  (lstm1): LSTM(16, 113, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (lstm2): LSTM(226, 420, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (linear1): Linear(in_features=840, out_features=310, bias=True)\n",
      "  (linear2): Linear(in_features=310, out_features=32, bias=True)\n",
      "  (linear3): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 00089 batches: 0.3094\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 00178 batches: 0.3067\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 00267 batches: 0.3086\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 00356 batches: 0.3007\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 00445 batches: 0.3036\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 00534 batches: 0.3020\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 00623 batches: 0.2971\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 00712 batches: 0.2947\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 00801 batches: 0.2971\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 00890 batches: 0.2961\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 00979 batches: 0.2973\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 01068 batches: 0.2933\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 01157 batches: 0.2937\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 01246 batches: 0.2848\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 01335 batches: 0.2878\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 01424 batches: 0.2888\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 01513 batches: 0.2842\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 01602 batches: 0.2836\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 01691 batches: 0.2815\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 01780 batches: 0.2870\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 01869 batches: 0.2847\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 01958 batches: 0.2846\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 02047 batches: 0.2751\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 02136 batches: 0.2838\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 02225 batches: 0.2758\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 02314 batches: 0.2825\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 02403 batches: 0.2804\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 02492 batches: 0.2690\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 02581 batches: 0.2748\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 02670 batches: 0.2768\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 02759 batches: 0.2758\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 02848 batches: 0.2723\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 02937 batches: 0.2700\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 03026 batches: 0.2723\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 03115 batches: 0.2672\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 03204 batches: 0.2665\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 03293 batches: 0.2620\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 03382 batches: 0.2642\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 03471 batches: 0.2573\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 03560 batches: 0.2607\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 03649 batches: 0.2663\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 03738 batches: 0.2596\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 03827 batches: 0.2613\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 03916 batches: 0.2557\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 04005 batches: 0.2638\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 04094 batches: 0.2541\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 04183 batches: 0.2566\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 04272 batches: 0.2561\n",
      "Adjusting learning rate of group 0 to 1.1664e-05.\n",
      "Loss after 04361 batches: 0.2550\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 04450 batches: 0.2533\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 04539 batches: 0.2494\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 04628 batches: 0.2558\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 04717 batches: 0.2562\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 04806 batches: 0.2527\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 04895 batches: 0.2469\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 04984 batches: 0.2534\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 05073 batches: 0.2568\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 05162 batches: 0.2490\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 05251 batches: 0.2436\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 05340 batches: 0.2497\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 05429 batches: 0.2453\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 05518 batches: 0.2524\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 05607 batches: 0.2532\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 05696 batches: 0.2481\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 05785 batches: 0.2499\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 05874 batches: 0.2501\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 05963 batches: 0.2506\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 06052 batches: 0.2439\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 06141 batches: 0.2502\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 06230 batches: 0.2461\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 06319 batches: 0.2406\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 06408 batches: 0.2496\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 06497 batches: 0.2425\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 06586 batches: 0.2456\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 06675 batches: 0.2400\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 06764 batches: 0.2437\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 06853 batches: 0.2406\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 06942 batches: 0.2414\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 07031 batches: 0.2447\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 07120 batches: 0.2425\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 07209 batches: 0.2406\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 07298 batches: 0.2406\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 07387 batches: 0.2444\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 07476 batches: 0.2439\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 07565 batches: 0.2453\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 07654 batches: 0.2399\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 07743 batches: 0.2371\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 07832 batches: 0.2421\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 07921 batches: 0.2388\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 08010 batches: 0.2389\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 08099 batches: 0.2398\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 08188 batches: 0.2428\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 08277 batches: 0.2332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 08366 batches: 0.2429\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 08455 batches: 0.2385\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 08544 batches: 0.2410\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 08633 batches: 0.2416\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 08722 batches: 0.2340\n",
      "Adjusting learning rate of group 0 to 1.0497e-05.\n",
      "Loss after 08811 batches: 0.2413\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 08900 batches: 0.2346\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 08989 batches: 0.2335\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 09078 batches: 0.2388\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 09167 batches: 0.2368\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 09256 batches: 0.2301\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 09345 batches: 0.2358\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 09434 batches: 0.2424\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 09523 batches: 0.2364\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 09612 batches: 0.2294\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 09701 batches: 0.2318\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 09790 batches: 0.2355\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 09879 batches: 0.2345\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 09968 batches: 0.2375\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 10057 batches: 0.2336\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 10146 batches: 0.2283\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 10235 batches: 0.2329\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 10324 batches: 0.2312\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 10413 batches: 0.2358\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 10502 batches: 0.2296\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 10591 batches: 0.2352\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 10680 batches: 0.2318\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 10769 batches: 0.2344\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 10858 batches: 0.2337\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 10947 batches: 0.2293\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 11036 batches: 0.2311\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 11125 batches: 0.2318\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 11214 batches: 0.2273\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 11303 batches: 0.2310\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 11392 batches: 0.2288\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 11481 batches: 0.2315\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 11570 batches: 0.2291\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 11659 batches: 0.2302\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 11748 batches: 0.2371\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 11837 batches: 0.2283\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 11926 batches: 0.2310\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 12015 batches: 0.2359\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 12104 batches: 0.2321\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 12193 batches: 0.2381\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 12282 batches: 0.2318\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 12371 batches: 0.2309\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 12460 batches: 0.2290\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 12549 batches: 0.2307\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 12638 batches: 0.2265\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 12727 batches: 0.2300\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 12816 batches: 0.2338\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 12905 batches: 0.2288\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 12994 batches: 0.2314\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 13083 batches: 0.2288\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 13172 batches: 0.2270\n",
      "Adjusting learning rate of group 0 to 9.4474e-06.\n",
      "Loss after 13261 batches: 0.2307\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 13350 batches: 0.2293\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 13439 batches: 0.2298\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 13528 batches: 0.2278\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 13617 batches: 0.2308\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 13706 batches: 0.2317\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 13795 batches: 0.2260\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 13884 batches: 0.2287\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 13973 batches: 0.2225\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 14062 batches: 0.2292\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 14151 batches: 0.2322\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 14240 batches: 0.2226\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 14329 batches: 0.2252\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 14418 batches: 0.2284\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 14507 batches: 0.2245\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 14596 batches: 0.2262\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 14685 batches: 0.2228\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 14774 batches: 0.2240\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 14863 batches: 0.2322\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 14952 batches: 0.2213\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 15041 batches: 0.2229\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 15130 batches: 0.2281\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 15219 batches: 0.2264\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 15308 batches: 0.2237\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 15397 batches: 0.2287\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 15486 batches: 0.2248\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 15575 batches: 0.2282\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 15664 batches: 0.2232\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 15753 batches: 0.2250\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 15842 batches: 0.2219\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 15931 batches: 0.2242\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 16020 batches: 0.2204\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 16109 batches: 0.2239\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 16198 batches: 0.2235\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 16287 batches: 0.2223\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 16376 batches: 0.2215\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 16465 batches: 0.2260\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 16554 batches: 0.2266\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 16643 batches: 0.2247\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 16732 batches: 0.2187\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 16821 batches: 0.2254\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 16910 batches: 0.2205\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 16999 batches: 0.2245\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 17088 batches: 0.2181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 17177 batches: 0.2225\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 17266 batches: 0.2267\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 17355 batches: 0.2213\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 17444 batches: 0.2214\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 17533 batches: 0.2211\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 17622 batches: 0.2223\n",
      "Adjusting learning rate of group 0 to 8.5027e-06.\n",
      "Loss after 17711 batches: 0.2213\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 17800 batches: 0.2208\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 17889 batches: 0.2183\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 17978 batches: 0.2212\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 18067 batches: 0.2244\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 18156 batches: 0.2156\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 18245 batches: 0.2169\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 18334 batches: 0.2203\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 18423 batches: 0.2258\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 18512 batches: 0.2166\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 18601 batches: 0.2242\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 18690 batches: 0.2159\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 18779 batches: 0.2196\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 18868 batches: 0.2188\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 18957 batches: 0.2252\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 19046 batches: 0.2208\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 19135 batches: 0.2195\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 19224 batches: 0.2156\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 19313 batches: 0.2207\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 19402 batches: 0.2175\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 19491 batches: 0.2159\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 19580 batches: 0.2223\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 19669 batches: 0.2145\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 19758 batches: 0.2178\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 19847 batches: 0.2211\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 19936 batches: 0.2125\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 20025 batches: 0.2199\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 20114 batches: 0.2167\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 20203 batches: 0.2201\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 20292 batches: 0.2197\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 20381 batches: 0.2142\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 20470 batches: 0.2166\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 20559 batches: 0.2163\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 20648 batches: 0.2156\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 20737 batches: 0.2200\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 20826 batches: 0.2166\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 20915 batches: 0.2185\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 21004 batches: 0.2158\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 21093 batches: 0.2181\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 21182 batches: 0.2118\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 21271 batches: 0.2204\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 21360 batches: 0.2165\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 21449 batches: 0.2149\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 21538 batches: 0.2180\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 21627 batches: 0.2131\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 21716 batches: 0.2179\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 21805 batches: 0.2130\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 21894 batches: 0.2145\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 21983 batches: 0.2170\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 22072 batches: 0.2145\n",
      "Adjusting learning rate of group 0 to 7.6524e-06.\n",
      "Loss after 22161 batches: 0.2120\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 22250 batches: 0.2129\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 22339 batches: 0.2202\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 22428 batches: 0.2184\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 22517 batches: 0.2125\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 22606 batches: 0.2162\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 22695 batches: 0.2173\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 22784 batches: 0.2161\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 22873 batches: 0.2130\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 22962 batches: 0.2142\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 23051 batches: 0.2142\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 23140 batches: 0.2237\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 23229 batches: 0.2105\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 23318 batches: 0.2135\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 23407 batches: 0.2093\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 23496 batches: 0.2166\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 23585 batches: 0.2134\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 23674 batches: 0.2097\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 23763 batches: 0.2178\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 23852 batches: 0.2120\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 23941 batches: 0.2110\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 24030 batches: 0.2175\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 24119 batches: 0.2134\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 24208 batches: 0.2103\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 24297 batches: 0.2129\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 24386 batches: 0.2161\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 24475 batches: 0.2069\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 24564 batches: 0.2094\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 24653 batches: 0.2081\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 24742 batches: 0.2152\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 24831 batches: 0.2159\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 24920 batches: 0.2139\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 25009 batches: 0.2181\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 25098 batches: 0.2103\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 25187 batches: 0.2068\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 25276 batches: 0.2125\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 25365 batches: 0.2126\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 25454 batches: 0.2143\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 25543 batches: 0.2152\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 25632 batches: 0.2080\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 25721 batches: 0.2056\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 25810 batches: 0.2101\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 25899 batches: 0.2130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 25988 batches: 0.2086\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 26077 batches: 0.2072\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 26166 batches: 0.2073\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 26255 batches: 0.2072\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 26344 batches: 0.2090\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 26433 batches: 0.2073\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 26522 batches: 0.2075\n",
      "Adjusting learning rate of group 0 to 6.8872e-06.\n",
      "Loss after 26611 batches: 0.2072\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 26700 batches: 0.2029\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 26789 batches: 0.2056\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 26878 batches: 0.2111\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 26967 batches: 0.2058\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 27056 batches: 0.2102\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 27145 batches: 0.2076\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 27234 batches: 0.2025\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 27323 batches: 0.2056\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 27412 batches: 0.2050\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 27501 batches: 0.2113\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 27590 batches: 0.2067\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 27679 batches: 0.2066\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 27768 batches: 0.2106\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 27857 batches: 0.2025\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 27946 batches: 0.2082\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 28035 batches: 0.2052\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 28124 batches: 0.2070\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 28213 batches: 0.2050\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 28302 batches: 0.2038\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 28391 batches: 0.2052\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 28480 batches: 0.2058\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 28569 batches: 0.2019\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 28658 batches: 0.2041\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 28747 batches: 0.2035\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 28836 batches: 0.2050\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 28925 batches: 0.2057\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 29014 batches: 0.2033\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 29103 batches: 0.2039\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 29192 batches: 0.2049\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 29281 batches: 0.2070\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 29370 batches: 0.2045\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 29459 batches: 0.2071\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 29548 batches: 0.2056\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 29637 batches: 0.2044\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 29726 batches: 0.2017\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 29815 batches: 0.2067\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 29904 batches: 0.2041\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 29993 batches: 0.2040\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 30082 batches: 0.1986\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 30171 batches: 0.2073\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 30260 batches: 0.2031\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 30349 batches: 0.2029\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 30438 batches: 0.2059\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 30527 batches: 0.2047\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 30616 batches: 0.2008\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 30705 batches: 0.2019\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 30794 batches: 0.2057\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 30883 batches: 0.1991\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 30972 batches: 0.1952\n",
      "Adjusting learning rate of group 0 to 6.1985e-06.\n",
      "Loss after 31061 batches: 0.2017\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 31150 batches: 0.1968\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 31239 batches: 0.1963\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 31328 batches: 0.2021\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 31417 batches: 0.1980\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 31506 batches: 0.1994\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 31595 batches: 0.1987\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 31684 batches: 0.2018\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 31773 batches: 0.1979\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 31862 batches: 0.1997\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 31951 batches: 0.2024\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 32040 batches: 0.1941\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 32129 batches: 0.1993\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 32218 batches: 0.1952\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 32307 batches: 0.1967\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 32396 batches: 0.1966\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 32485 batches: 0.1957\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 32574 batches: 0.1984\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 32663 batches: 0.2016\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 32752 batches: 0.1983\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 32841 batches: 0.1966\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 32930 batches: 0.1993\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 33019 batches: 0.1980\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 33108 batches: 0.1959\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 33197 batches: 0.1993\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 33286 batches: 0.1973\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 33375 batches: 0.1959\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 33464 batches: 0.1971\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 33553 batches: 0.1967\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 33642 batches: 0.1953\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 33731 batches: 0.1952\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 33820 batches: 0.1927\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 33909 batches: 0.1961\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 33998 batches: 0.1993\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 34087 batches: 0.1928\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 34176 batches: 0.1964\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 34265 batches: 0.1956\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 34354 batches: 0.1937\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 34443 batches: 0.1988\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 34532 batches: 0.1959\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 34621 batches: 0.1976\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 34710 batches: 0.1933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 34799 batches: 0.1899\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 34888 batches: 0.1918\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 34977 batches: 0.1991\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 35066 batches: 0.1953\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 35155 batches: 0.1927\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 35244 batches: 0.1913\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 35333 batches: 0.1940\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 35422 batches: 0.1987\n",
      "Adjusting learning rate of group 0 to 5.5786e-06.\n",
      "Loss after 35511 batches: 0.1979\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 35600 batches: 0.1962\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 35689 batches: 0.1931\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 35778 batches: 0.1947\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 35867 batches: 0.1923\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 35956 batches: 0.1951\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 36045 batches: 0.1918\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 36134 batches: 0.1924\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 36223 batches: 0.1937\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 36312 batches: 0.1967\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 36401 batches: 0.1934\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 36490 batches: 0.1941\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 36579 batches: 0.1897\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 36668 batches: 0.1923\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 36757 batches: 0.1915\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 36846 batches: 0.1975\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 36935 batches: 0.1941\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 37024 batches: 0.1918\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 37113 batches: 0.1947\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 37202 batches: 0.1904\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 37291 batches: 0.1905\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 37380 batches: 0.1957\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 37469 batches: 0.1897\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 37558 batches: 0.1919\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 37647 batches: 0.1878\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 37736 batches: 0.1887\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 37825 batches: 0.1909\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 37914 batches: 0.1970\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 38003 batches: 0.1940\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 38092 batches: 0.1901\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 38181 batches: 0.1903\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 38270 batches: 0.1921\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 38359 batches: 0.1914\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 38448 batches: 0.1898\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 38537 batches: 0.1891\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 38626 batches: 0.1824\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 38715 batches: 0.1883\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 38804 batches: 0.1889\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 38893 batches: 0.1867\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 38982 batches: 0.1885\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 39071 batches: 0.1879\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 39160 batches: 0.1858\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 39249 batches: 0.1837\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 39338 batches: 0.1921\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 39427 batches: 0.1912\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 39516 batches: 0.1870\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 39605 batches: 0.1928\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 39694 batches: 0.1856\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 39783 batches: 0.1874\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 39872 batches: 0.1862\n",
      "Adjusting learning rate of group 0 to 5.0208e-06.\n",
      "Loss after 39961 batches: 0.1861\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 40050 batches: 0.1842\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 40139 batches: 0.1880\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 40228 batches: 0.1913\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 40317 batches: 0.1841\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 40406 batches: 0.1923\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 40495 batches: 0.1879\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 40584 batches: 0.1880\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 40673 batches: 0.1848\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 40762 batches: 0.1845\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 40851 batches: 0.1854\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 40940 batches: 0.1869\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 41029 batches: 0.1879\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 41118 batches: 0.1843\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 41207 batches: 0.1880\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 41296 batches: 0.1882\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 41385 batches: 0.1880\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 41474 batches: 0.1850\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 41563 batches: 0.1878\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 41652 batches: 0.1881\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 41741 batches: 0.1872\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 41830 batches: 0.1875\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 41919 batches: 0.1858\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 42008 batches: 0.1868\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 42097 batches: 0.1819\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 42186 batches: 0.1853\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 42275 batches: 0.1788\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 42364 batches: 0.1859\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 42453 batches: 0.1837\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 42542 batches: 0.1825\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 42631 batches: 0.1855\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 42720 batches: 0.1824\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 42809 batches: 0.1878\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 42898 batches: 0.1819\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 42987 batches: 0.1862\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 43076 batches: 0.1837\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 43165 batches: 0.1881\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 43254 batches: 0.1814\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 43343 batches: 0.1810\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 43432 batches: 0.1793\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 43521 batches: 0.1807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 43610 batches: 0.1865\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 43699 batches: 0.1790\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 43788 batches: 0.1782\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 43877 batches: 0.1853\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 43966 batches: 0.1817\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 44055 batches: 0.1819\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 44144 batches: 0.1869\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 44233 batches: 0.1825\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 44322 batches: 0.1820\n",
      "Adjusting learning rate of group 0 to 4.5187e-06.\n",
      "Loss after 44411 batches: 0.1793\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 44500 batches: 0.1817\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 44589 batches: 0.1820\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 44678 batches: 0.1804\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 44767 batches: 0.1854\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 44856 batches: 0.1848\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 44945 batches: 0.1823\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 45034 batches: 0.1805\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 45123 batches: 0.1788\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 45212 batches: 0.1836\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 45301 batches: 0.1836\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 45390 batches: 0.1806\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 45479 batches: 0.1793\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 45568 batches: 0.1795\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 45657 batches: 0.1822\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 45746 batches: 0.1841\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 45835 batches: 0.1800\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 45924 batches: 0.1749\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 46013 batches: 0.1801\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 46102 batches: 0.1799\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 46191 batches: 0.1836\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 46280 batches: 0.1772\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 46369 batches: 0.1826\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 46458 batches: 0.1777\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 46547 batches: 0.1777\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 46636 batches: 0.1796\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 46725 batches: 0.1803\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 46814 batches: 0.1811\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 46903 batches: 0.1816\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 46992 batches: 0.1805\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 47081 batches: 0.1815\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 47170 batches: 0.1781\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 47259 batches: 0.1817\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 47348 batches: 0.1805\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 47437 batches: 0.1841\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 47526 batches: 0.1761\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 47615 batches: 0.1796\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 47704 batches: 0.1796\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 47793 batches: 0.1791\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 47882 batches: 0.1765\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 47971 batches: 0.1776\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 48060 batches: 0.1767\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 48149 batches: 0.1762\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 48238 batches: 0.1787\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 48327 batches: 0.1780\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 48416 batches: 0.1748\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 48505 batches: 0.1790\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 48594 batches: 0.1768\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 48683 batches: 0.1737\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 48772 batches: 0.1744\n",
      "Adjusting learning rate of group 0 to 4.0668e-06.\n",
      "Loss after 48861 batches: 0.1788\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 48950 batches: 0.1756\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 49039 batches: 0.1778\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 49128 batches: 0.1809\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 49217 batches: 0.1789\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 49306 batches: 0.1745\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 49395 batches: 0.1756\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 49484 batches: 0.1751\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 49573 batches: 0.1720\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 49662 batches: 0.1775\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 49751 batches: 0.1797\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 49840 batches: 0.1796\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 49929 batches: 0.1781\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 50018 batches: 0.1751\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 50107 batches: 0.1780\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 50196 batches: 0.1778\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 50285 batches: 0.1766\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 50374 batches: 0.1757\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 50463 batches: 0.1714\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 50552 batches: 0.1766\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 50641 batches: 0.1745\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 50730 batches: 0.1718\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 50819 batches: 0.1765\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 50908 batches: 0.1734\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 50997 batches: 0.1783\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 51086 batches: 0.1768\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 51175 batches: 0.1743\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 51264 batches: 0.1757\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 51353 batches: 0.1757\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 51442 batches: 0.1753\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 51531 batches: 0.1708\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 51620 batches: 0.1737\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 51709 batches: 0.1712\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 51798 batches: 0.1748\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 51887 batches: 0.1724\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 51976 batches: 0.1732\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 52065 batches: 0.1747\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 52154 batches: 0.1767\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 52243 batches: 0.1766\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 52332 batches: 0.1748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 52421 batches: 0.1713\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 52510 batches: 0.1730\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 52599 batches: 0.1713\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 52688 batches: 0.1727\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 52777 batches: 0.1777\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 52866 batches: 0.1741\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 52955 batches: 0.1773\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 53044 batches: 0.1745\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 53133 batches: 0.1710\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 53222 batches: 0.1735\n",
      "Adjusting learning rate of group 0 to 3.6601e-06.\n",
      "Loss after 53311 batches: 0.1730\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 53400 batches: 0.1729\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 53489 batches: 0.1725\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 53578 batches: 0.1740\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 53667 batches: 0.1747\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 53756 batches: 0.1743\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 53845 batches: 0.1758\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 53934 batches: 0.1731\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 54023 batches: 0.1757\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 54112 batches: 0.1703\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 54201 batches: 0.1789\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 54290 batches: 0.1740\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 54379 batches: 0.1695\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 54468 batches: 0.1721\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 54557 batches: 0.1746\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 54646 batches: 0.1727\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 54735 batches: 0.1725\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 54824 batches: 0.1720\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 54913 batches: 0.1704\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 55002 batches: 0.1773\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 55091 batches: 0.1714\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 55180 batches: 0.1765\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 55269 batches: 0.1742\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 55358 batches: 0.1740\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 55447 batches: 0.1722\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 55536 batches: 0.1720\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 55625 batches: 0.1714\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 55714 batches: 0.1707\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 55803 batches: 0.1729\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 55892 batches: 0.1709\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 55981 batches: 0.1701\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 56070 batches: 0.1680\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 56159 batches: 0.1733\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 56248 batches: 0.1702\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 56337 batches: 0.1728\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 56426 batches: 0.1702\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 56515 batches: 0.1709\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 56604 batches: 0.1712\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 56693 batches: 0.1713\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 56782 batches: 0.1713\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 56871 batches: 0.1737\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 56960 batches: 0.1703\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 57049 batches: 0.1722\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 57138 batches: 0.1708\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 57227 batches: 0.1658\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 57316 batches: 0.1713\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 57405 batches: 0.1711\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 57494 batches: 0.1708\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 57583 batches: 0.1716\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 57672 batches: 0.1708\n",
      "Adjusting learning rate of group 0 to 3.2941e-06.\n",
      "Loss after 57761 batches: 0.1717\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 57850 batches: 0.1712\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 57939 batches: 0.1709\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 58028 batches: 0.1653\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 58117 batches: 0.1697\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 58206 batches: 0.1725\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 58295 batches: 0.1710\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 58384 batches: 0.1713\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 58473 batches: 0.1656\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 58562 batches: 0.1678\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 58651 batches: 0.1664\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 58740 batches: 0.1685\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 58829 batches: 0.1673\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 58918 batches: 0.1680\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 59007 batches: 0.1697\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 59096 batches: 0.1694\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 59185 batches: 0.1695\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 59274 batches: 0.1669\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 59363 batches: 0.1658\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 59452 batches: 0.1655\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 59541 batches: 0.1696\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 59630 batches: 0.1664\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 59719 batches: 0.1678\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 59808 batches: 0.1697\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 59897 batches: 0.1675\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 59986 batches: 0.1687\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 60075 batches: 0.1697\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 60164 batches: 0.1728\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 60253 batches: 0.1707\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 60342 batches: 0.1691\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 60431 batches: 0.1715\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 60520 batches: 0.1656\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 60609 batches: 0.1701\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 60698 batches: 0.1700\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 60787 batches: 0.1643\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 60876 batches: 0.1704\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 60965 batches: 0.1674\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 61054 batches: 0.1653\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 61143 batches: 0.1669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 61232 batches: 0.1674\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 61321 batches: 0.1679\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 61410 batches: 0.1660\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 61499 batches: 0.1715\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 61588 batches: 0.1680\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 61677 batches: 0.1698\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 61766 batches: 0.1693\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 61855 batches: 0.1679\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 61944 batches: 0.1658\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 62033 batches: 0.1674\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 62122 batches: 0.1663\n",
      "Adjusting learning rate of group 0 to 2.9647e-06.\n",
      "Loss after 62211 batches: 0.1655\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 62300 batches: 0.1648\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 62389 batches: 0.1664\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 62478 batches: 0.1645\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 62567 batches: 0.1683\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 62656 batches: 0.1631\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 62745 batches: 0.1647\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 62834 batches: 0.1671\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 62923 batches: 0.1664\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 63012 batches: 0.1652\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 63101 batches: 0.1677\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 63190 batches: 0.1626\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 63279 batches: 0.1635\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 63368 batches: 0.1633\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 63457 batches: 0.1662\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 63546 batches: 0.1675\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 63635 batches: 0.1634\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 63724 batches: 0.1675\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 63813 batches: 0.1653\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 63902 batches: 0.1677\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 63991 batches: 0.1678\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 64080 batches: 0.1701\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 64169 batches: 0.1667\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 64258 batches: 0.1704\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 64347 batches: 0.1639\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 64436 batches: 0.1665\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 64525 batches: 0.1633\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 64614 batches: 0.1663\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 64703 batches: 0.1664\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 64792 batches: 0.1638\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 64881 batches: 0.1637\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 64970 batches: 0.1624\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 65059 batches: 0.1653\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 65148 batches: 0.1637\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 65237 batches: 0.1687\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 65326 batches: 0.1680\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 65415 batches: 0.1658\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 65504 batches: 0.1662\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 65593 batches: 0.1656\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 65682 batches: 0.1623\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 65771 batches: 0.1665\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 65860 batches: 0.1660\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 65949 batches: 0.1623\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 66038 batches: 0.1619\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 66127 batches: 0.1641\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 66216 batches: 0.1660\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 66305 batches: 0.1633\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 66394 batches: 0.1646\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 66483 batches: 0.1658\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 66572 batches: 0.1624\n",
      "Adjusting learning rate of group 0 to 2.6682e-06.\n",
      "Loss after 66661 batches: 0.1654\n",
      "Adjusting learning rate of group 0 to 2.4014e-06.\n",
      "Loss after 66750 batches: 0.1672\n",
      "Time to train on one home:  372.51039004325867\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 41148<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\wandb\\run-20211119_191031-mkd43wtc\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\wandb\\run-20211119_191031-mkd43wtc\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_F1_Score</td><td>0.52605</td></tr><tr><td>Test_MAE</td><td>26.5153</td></tr><tr><td>Test_MSE</td><td>0.15442</td></tr><tr><td>Test_NDE</td><td>0.35398</td></tr><tr><td>Test_NEP</td><td>0.86832</td></tr><tr><td>Test_R2_Value</td><td>-0.56643</td></tr><tr><td>Training_F1</td><td>0.50652</td></tr><tr><td>Training_MAE</td><td>39.39901</td></tr><tr><td>Training_MSE</td><td>0.1672</td></tr><tr><td>Training_NDE</td><td>0.79545</td></tr><tr><td>Training_NEP</td><td>0.8945</td></tr><tr><td>Training_R2</td><td>-0.51279</td></tr><tr><td>Validation_F1</td><td>0.52175</td></tr><tr><td>Validation_MAE</td><td>40.09564</td></tr><tr><td>Validation_MSE</td><td>0.13789</td></tr><tr><td>Validation_NDE</td><td>0.55814</td></tr><tr><td>Validation_NEP</td><td>0.78242</td></tr><tr><td>Validation_R2</td><td>-0.95393</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Test_F1_Score</td><td>▁</td></tr><tr><td>Test_MAE</td><td>▁</td></tr><tr><td>Test_MSE</td><td>▁</td></tr><tr><td>Test_NDE</td><td>▁</td></tr><tr><td>Test_NEP</td><td>▁</td></tr><tr><td>Test_R2_Value</td><td>▁</td></tr><tr><td>Training_F1</td><td>▁▂▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██████████</td></tr><tr><td>Training_MAE</td><td>██▇▇▇█▇██▇▇▇▇▇▆▆▆▆▆▅▅▅▅▃▄▄▄▃▃▃▃▂▂▂▂▂▁▁▂▁</td></tr><tr><td>Training_MSE</td><td>█▇▆▆▅▅▅▅▄▄▄▄▄▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>Training_NDE</td><td>██▇▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▃▃▃▂▂▂▂▂▁▂▁▁▁▁▁▁</td></tr><tr><td>Training_NEP</td><td>██▇▇▇█▇██▇▇▇▇▇▆▆▆▆▆▅▅▅▅▃▄▄▄▃▃▃▃▂▂▂▂▂▁▁▂▁</td></tr><tr><td>Training_R2</td><td>▁▂▂▂▂▁▂▁▂▁▁▃▂▁▃▃▃▄▄▅▅▅▅▆▆▆▅▆▆▆▇▇▇▇▇███▇█</td></tr><tr><td>Validation_F1</td><td>▁▂▄▅▆▆▇▇▇▇▇█████████████████████████████</td></tr><tr><td>Validation_MAE</td><td>█▇▆▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation_MSE</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation_NDE</td><td>█▇▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation_NEP</td><td>█▇▆▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation_R2</td><td>▁▂▃▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">peachy-wildflower-492</strong>: <a href=\"https://wandb.ai/nilm/Drye1_single_houses/runs/mkd43wtc\" target=\"_blank\">https://wandb.ai/nilm/Drye1_single_houses/runs/mkd43wtc</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-19 19:18:12,568]\u001b[0m Trial 5 finished with value: 0.1544160693883896 and parameters: {'hidden_size_1': 113, 'hidden_size_2': 420, 'fc1': 310, 'fc2': 32, 'weight_decay': 0.07815272502760769, 'learning_rate': 1.1663504713283506e-05, 'window_size': 70}. Best is trial 3 with value: 0.11220970749855042.\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.12.2<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">proud-energy-493</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/nilm/Drye1_single_houses\" target=\"_blank\">https://wandb.ai/nilm/Drye1_single_houses</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/nilm/Drye1_single_houses/runs/2lj0b2wj\" target=\"_blank\">https://wandb.ai/nilm/Drye1_single_houses/runs/2lj0b2wj</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\wandb\\run-20211119_191812-2lj0b2wj</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (conv1): Conv1d(1, 16, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "  (lstm1): LSTM(16, 122, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (lstm2): LSTM(244, 457, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (linear1): Linear(in_features=914, out_features=468, bias=True)\n",
      "  (linear2): Linear(in_features=468, out_features=3, bias=True)\n",
      "  (linear3): Linear(in_features=3, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Adjusting learning rate of group 0 to 1.1603e-04.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 39208<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\wandb\\run-20211119_191812-2lj0b2wj\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\wandb\\run-20211119_191812-2lj0b2wj\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">proud-energy-493</strong>: <a href=\"https://wandb.ai/nilm/Drye1_single_houses/runs/2lj0b2wj\" target=\"_blank\">https://wandb.ai/nilm/Drye1_single_houses/runs/2lj0b2wj</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2021-11-19 19:20:20,935]\u001b[0m Trial 6 failed because of the following error: RuntimeError('CUDA out of memory. Tried to allocate 572.00 MiB (GPU 0; 4.00 GiB total capacity; 715.60 MiB already allocated; 428.94 MiB free; 1010.00 MiB reserved in total by PyTorch)')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\aar245.CORNELL\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"<ipython-input-8-da283f16d517>\", line 12, in objective\n",
      "    model, result = model_pipeline(\n",
      "  File \"<ipython-input-5-f7f6751d77a7>\", line 28, in model_pipeline\n",
      "    model, example_ct, batch_ct, all_epochs = train(\n",
      "  File \"C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\train.py\", line 44, in train\n",
      "    train_predictions, train_true_vals, loss = train_batch(features, labels, model, optimizer, criterion)\n",
      "  File \"C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\train.py\", line 175, in train_batch\n",
      "    outputs = model(features)\n",
      "  File \"C:\\Users\\aar245.CORNELL\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\src\\lstm.py\", line 44, in forward\n",
      "    out, _ = self.lstm2(out)\n",
      "  File \"C:\\Users\\aar245.CORNELL\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"C:\\Users\\aar245.CORNELL\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\", line 581, in forward\n",
      "    result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 572.00 MiB (GPU 0; 4.00 GiB total capacity; 715.60 MiB already allocated; 428.94 MiB free; 1010.00 MiB reserved in total by PyTorch)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 572.00 MiB (GPU 0; 4.00 GiB total capacity; 715.60 MiB already allocated; 428.94 MiB free; 1010.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4f0eb4278a78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'minimize'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"best trial:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    398\u001b[0m             )\n\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m         _optimize(\n\u001b[0m\u001b[0;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             _optimize_sequential(\n\u001b[0m\u001b[0;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-da283f16d517>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     10\u001b[0m     }\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     model, result = model_pipeline(\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mconfig_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;34m'may_june_july'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-f7f6751d77a7>\u001b[0m in \u001b[0;36mmodel_pipeline\u001b[1;34m(hyperparameters, train_months, test_month, appliance, window_length, train_buildings, test_buildings, params)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mtime_log\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_train_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_months\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappliance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_buildings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         model, example_ct, batch_ct, all_epochs = train(\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\privacy_preserving_nn\\src\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, loader, validation_loader, criterion, optimizer, config, example_ct, batch_ct, all_epochs, scheduler)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mall_epochs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mtrain_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_true_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[0mepoch_total_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mepoch_predictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_predictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\privacy_preserving_nn\\src\\train.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[1;34m(features, labels, model, optimizer, criterion)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\privacy_preserving_nn\\src\\lstm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;31m# print(\"shape3: \", out.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    579\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[0;32m    582\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0;32m    583\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 572.00 MiB (GPU 0; 4.00 GiB total capacity; 715.60 MiB already allocated; 428.94 MiB free; 1010.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=20)\n",
    "    \n",
    "    print(\"best trial:\")\n",
    "    trial_ = study.best_trial\n",
    "    \n",
    "    print(trial_.values)\n",
    "    print(trial_.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d44b257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(hyperparameters, train_months, test_month, appliance, window_length, train_buildings,\n",
    "                   test_buildings, params):\n",
    "    with wandb.init(project=\"Drye1_single_houses\", config=hyperparameters):\n",
    "        wandb.run.name = \"Test1706normalize_over_dataset_hs1:32_hs2:200_fc1:200_fc2:100_1200epochs100batch_StepLR.0004_step50_gamma0.9_3dropout_weightdecay.00005_kern:7_outchan:16_4sigmoid_0maxpool_Trainbldgs:\" + str(\n",
    "            train_buildings)\n",
    "\n",
    "        config = wandb.config\n",
    "\n",
    "        # lengths = [85320, 132480, 132480, 132480, 132480, 132480, 132480]\n",
    "\n",
    "        model, criterion, optimizer = make_model(config, params)\n",
    "\n",
    "        print(model)\n",
    "\n",
    "        wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "\n",
    "        example_ct = 0\n",
    "        batch_ct = 0\n",
    "        all_epochs = 0\n",
    "        # all step_size=30 tests had gamma=0.5\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.9, verbose=True)\n",
    "\n",
    "        validation_loader, test_loader = make_test_val_data(config, test_month, appliance, window_length,\n",
    "                                                            test_buildings)\n",
    "\n",
    "        time_log = time.time()\n",
    "        train_loader = make_train_data(config, train_months, appliance, window_length, train_buildings)\n",
    "        model, example_ct, batch_ct, all_epochs = train(\n",
    "            model,\n",
    "            train_loader,\n",
    "            validation_loader,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            config,\n",
    "            example_ct,\n",
    "            batch_ct,\n",
    "            all_epochs,\n",
    "            scheduler)\n",
    "\n",
    "        print(\"Time to train on one home: \", time.time() - time_log)\n",
    "\n",
    "        results = test(model, test_loader, criterion)\n",
    "\n",
    "    return model, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28b465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "homes = load_all_houses_with_device(config_file.path, 'drye1')\n",
    "\n",
    "\n",
    "drye1_homes = homes['dataid'].loc[homes['dataid'] != 1706].unique()\n",
    "\n",
    "\n",
    "final_results = {}\n",
    "random.seed(5)\n",
    "for j in drye1_homes:\n",
    "    for i in range(10):\n",
    "        model, per_house_result = model_pipeline(\n",
    "        config_,\n",
    "        'may_june_july',\n",
    "        'may_june_july',\n",
    "        'drye1',\n",
    "        100,\n",
    "        [j],\n",
    "        [1706])\n",
    "        result = {j: per_house_result}\n",
    "        final_results.update(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0cac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trial 2 finished with value: 0.048315126448869705 and parameters:\n",
    "        {'hidden_size_1': 30,\n",
    "         'hidden_size_2': 123,\n",
    "         'fc1': 299, 'fc2': 18,\n",
    "         'weight_decay': 0.005038971768580936,\n",
    "         'learning_rate': 0.000624235019529808,\n",
    "         'window_size': 280}.\n",
    "        Best is trial 2 with value: 0.048315126448869705"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
