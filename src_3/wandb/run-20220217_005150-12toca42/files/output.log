LSTM(
  (conv1): Conv1d(1, 30, kernel_size=(10,), stride=(1,))
  (conv2): Conv1d(30, 30, kernel_size=(8,), stride=(1,))
  (conv3): Conv1d(30, 40, kernel_size=(6,), stride=(1,))
  (conv4): Conv1d(40, 50, kernel_size=(5,), stride=(1,))
  (conv5): Conv1d(50, 50, kernel_size=(5,), stride=(1,))
  (linear1): Linear(in_features=23500, out_features=1024, bias=True)
  (linear2): Linear(in_features=1024, out_features=1, bias=True)
  (relu): ReLU()
  (leaky): LeakyReLU(negative_slope=0.01)
  (dropout): Dropout(p=0.2, inplace=False)
)
Window Length:  499
trigger times: 0
Loss after 131100 batches: 0.8472
trigger times: 0
Loss after 262200 batches: 0.7551
trigger times: 1
Loss after 393300 batches: 0.7045
trigger times: 2
Loss after 524400 batches: 0.6680
trigger times: 3
Loss after 655500 batches: 0.6334
trigger times: 4
Loss after 786600 batches: 0.6051
trigger times: 5
Loss after 917700 batches: 0.5871
trigger times: 6
Loss after 1048800 batches: 0.5696
trigger times: 7
Loss after 1179900 batches: 0.5530
trigger times: 8
Loss after 1311000 batches: 0.5429
trigger times: 9
Loss after 1442100 batches: 0.5349
trigger times: 10
Loss after 1573200 batches: 0.5257
trigger times: 11
Loss after 1704300 batches: 0.5115
trigger times: 12
Loss after 1835400 batches: 0.5073
trigger times: 13
Loss after 1966500 batches: 0.4983
trigger times: 14
Loss after 2097600 batches: 0.4911
trigger times: 15
Loss after 2228700 batches: 0.4821
trigger times: 16
Loss after 2359800 batches: 0.4758
trigger times: 17
Loss after 2490900 batches: 0.4711
trigger times: 18
Loss after 2622000 batches: 0.4668
trigger times: 19
Loss after 2753100 batches: 0.4657
trigger times: 20
Loss after 2884200 batches: 0.4588
trigger times: 21
Loss after 3015300 batches: 0.4544
trigger times: 22
Loss after 3146400 batches: 0.4480
trigger times: 23
Loss after 3277500 batches: 0.4427
trigger times: 24
Loss after 3408600 batches: 0.4460
trigger times: 25
Loss after 3539700 batches: 0.4414
trigger times: 26
Loss after 3670800 batches: 0.4392
trigger times: 27
Loss after 3801900 batches: 0.4389
trigger times: 28
Loss after 3933000 batches: 0.4365
trigger times: 29
Loss after 4064100 batches: 0.4344
trigger times: 30
Loss after 4195200 batches: 0.4300
trigger times: 31
Loss after 4326300 batches: 0.4273
trigger times: 32
Loss after 4457400 batches: 0.4288
trigger times: 33
Loss after 4588500 batches: 0.4253
trigger times: 34
Loss after 4719600 batches: 0.4240
trigger times: 35
Loss after 4850700 batches: 0.4226
trigger times: 36
Loss after 4981800 batches: 0.4176
trigger times: 37
Loss after 5112900 batches: 0.4184
trigger times: 38
Loss after 5244000 batches: 0.4130
trigger times: 39
Loss after 5375100 batches: 0.4116
trigger times: 40
Loss after 5506200 batches: 0.4088
trigger times: 41
Loss after 5637300 batches: 0.4051
trigger times: 42
Loss after 5768400 batches: 0.4056
trigger times: 43
Loss after 5899500 batches: 0.4059
trigger times: 44
Loss after 6030600 batches: 0.4006
trigger times: 45
Loss after 6161700 batches: 0.4007
trigger times: 46
Loss after 6292800 batches: 0.4003
trigger times: 47
Loss after 6423900 batches: 0.3976
trigger times: 48
Loss after 6555000 batches: 0.4008
Time to train on one home:  10957.044776678085