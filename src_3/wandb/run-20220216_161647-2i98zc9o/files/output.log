LSTM(
  (conv1): Conv1d(1, 30, kernel_size=(10,), stride=(1,))
  (conv2): Conv1d(30, 30, kernel_size=(8,), stride=(1,))
  (conv3): Conv1d(30, 40, kernel_size=(6,), stride=(1,))
  (conv4): Conv1d(40, 50, kernel_size=(5,), stride=(1,))
  (conv5): Conv1d(50, 50, kernel_size=(5,), stride=(1,))
  (linear1): Linear(in_features=23500, out_features=1024, bias=True)
  (linear2): Linear(in_features=1024, out_features=1, bias=True)
  (relu): ReLU()
  (leaky): LeakyReLU(negative_slope=0.01)
  (dropout): Dropout(p=0.2, inplace=False)
)
Window Length:  499
37.81458
trigger times: 0
Loss after 131100 batches: 0.2429
1.9601758
trigger times: 0
Loss after 262200 batches: 0.0926
1.4921534
trigger times: 1
Loss after 393300 batches: 0.0910
1.8357974
trigger times: 0
Loss after 524400 batches: 0.0886
1.9362473
trigger times: 1
Loss after 655500 batches: 0.0856
1.7561063
trigger times: 2
Loss after 786600 batches: 0.0846
2.1592612
trigger times: 3
Loss after 917700 batches: 0.0831
1320529.5
trigger times: 4
Loss after 1048800 batches: 274377746.1427
6221.975
trigger times: 5
Loss after 1179900 batches: 381326.8287
4694.6094
trigger times: 6
Loss after 1311000 batches: 146865.6633
Time to train on one home:  2348.9347608089447