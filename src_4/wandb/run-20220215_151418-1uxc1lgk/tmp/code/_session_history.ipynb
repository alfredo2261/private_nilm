{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25aabab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from data_loaders import make_train_data, make_test_val_data, make_model\n",
    "from train import train, test, precision, recall, f1_score\n",
    "import torch\n",
    "import time\n",
    "import gc\n",
    "import config_file\n",
    "from clean_data import load_all_houses_with_device\n",
    "import random\n",
    "import optuna\n",
    "from data_loaders import PecanStreetDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from lstm_seq2point import LSTM\n",
    "from clean_data import normalize_y\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef2a4e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f2f6cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_ = config_file.load_hyperparameters(\"refrigerator1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4422ba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "homes = load_all_houses_with_device(config_file.path, config_['appliance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a535619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(hyperparameters, train_months, test_month, appliance, window_length, train_buildings,\n",
    "                   test_buildings, patience):\n",
    "    with wandb.init(project=\"global_models_feb10\", config=hyperparameters):\n",
    "        wandb.run.name = str(config_['appliance'])+\"_Test:\"+str(test_buildings)+\"_Train:\" + str(train_buildings)\n",
    "\n",
    "        config = wandb.config\n",
    "\n",
    "        # lengths = [85320, 132480, 132480, 132480, 132480, 132480, 132480]\n",
    "\n",
    "        model, criterion, optimizer = make_model(config)\n",
    "\n",
    "        print(model)\n",
    "        print(\"Window Length: \", window_length)\n",
    "\n",
    "        wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "\n",
    "        example_ct = 0\n",
    "        batch_ct = 0\n",
    "        all_epochs = 0\n",
    "\n",
    "        #Scheduler for training on single building\n",
    "#         scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.85, verbose=True)\n",
    "        \n",
    "        #base_lr: 0.001*lr, max_lr: 4*lr, step_size_up:50, step_size_down:2000\n",
    "        scheduler = torch.optim.lr_scheduler.CyclicLR(\n",
    "            optimizer,\n",
    "            base_lr = 2*config_['learning_rate'], #0.01\n",
    "            max_lr = 10*config_['learning_rate'], #1\n",
    "            step_size_up = 100, #200\n",
    "            step_size_down = 500, #1000\n",
    "            gamma = 0.9, #1\n",
    "            cycle_momentum=False,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        validation_loader, test_loader, test_val_seq_min, test_val_seq_max = make_test_val_data(\n",
    "            config,\n",
    "            test_month,\n",
    "            appliance,\n",
    "            window_length,\n",
    "            test_buildings\n",
    "        )\n",
    "\n",
    "        time_log = time.time()\n",
    "        train_loader, train_seq_min, train_seq_max = make_train_data(\n",
    "            config,\n",
    "            train_months,\n",
    "            appliance,\n",
    "            window_length,\n",
    "            train_buildings\n",
    "        )\n",
    "        \n",
    "        model, example_ct, batch_ct, all_epochs, best_model = train( \n",
    "            model,\n",
    "            train_loader,\n",
    "            validation_loader,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            config,\n",
    "            example_ct,\n",
    "            batch_ct,\n",
    "            all_epochs,\n",
    "            scheduler,\n",
    "            test_val_seq_min,\n",
    "            test_val_seq_max,\n",
    "            train_seq_min,\n",
    "            train_seq_max,\n",
    "            patience\n",
    "        )\n",
    "\n",
    "        print(\"Time to train on one home: \", time.time() - time_log)\n",
    "\n",
    "        results = test(best_model, test_loader, criterion, test_val_seq_min, test_val_seq_max)\n",
    "\n",
    "    return model, results, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "750e6b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_ids = homes.dataid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e23b16bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38"
     ]
    }
   ],
   "source": [
    "len(home_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd4c2282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([  142,   183,   335,   387,   526,  1240,  1417,  2126,  2358,\n",
      "        3383,  3488,  3976,  3996,  5058,  5192,  6069,  6178,  6240,\n",
      "        6526,  6564,  6594,  6672,  6703,  7069,  7365,  7935,  8627,\n",
      "        8825,  9002,  9004,  9053,  9290, 10182, 10811, 10983, 11421,\n",
      "       11785, 11878], dtype=int64)"
     ]
    }
   ],
   "source": [
    "home_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70cb036a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_select = [2,3,4,5,6,7,8,9,10,15,20,25,30,35,38]\n",
    "#random_select = [len(home_ids)]\n",
    "#random_select = [53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8293f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r\"C:\\Users\\aar245.CORNELL\\Desktop\\privacy_preserving_nn\\models_squ_foot_filter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa0fd994",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_homes_from_fl = [\n",
    "    [5058, 2358, 8825, 10811, 526],\n",
    "    [142, 10811, 2358, 6240, 2126, 1417, 7365, 5058, 10182, 9004],\n",
    "    [9053, 2561, 2126, 7021, 526, 9973, 6178, 3700, 8825, 142, 7069, 335, 690, 6526, 183],\n",
    "    [183, 6240, 5058, 6672, 8825, 3700, 7365, 9053, 3976, 9973, 6526, 3996, 526, 3488, 387, 11878, 7021, 10811, 9290, 6178],\n",
    "    [6672, 9290, 6178, 10983, 3700, 6526, 3488, 6240, 9973, 3976, 9004, 2126, 3383, 142, 2358, 690, 7021, 387, 10182, 10811, 5058, 8825, 2561, 526, 3996],\n",
    "    [526, 10811, 9973, 7021, 5058, 335, 3488, 9053, 10983, 3976, 11878, 142, 2561, 8825, 6672, 387, 183, 6178, 1417, 9290, 10182, 690, 2358, 7365, 3383, 6240, 7069, 9004, 3996, 3700],\n",
    "    [5058, 2358, 3488, 10182, 6672, 11878, 7021, 6526, 335, 10164, 142, 9973, 10983, 6240, 2126, 1417, 7069, 6178, 8825, 3383, 9004, 387, 3976, 3700, 9290, 3996, 690, 7365, 9053, 183, 2561, 526, 10811]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d1e14fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_homes_from_fl = [526, 5058, 526, 3488, 10983, 7021, 2358]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "855d9da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/nilm/global_models_feb10/runs/1uxc1lgk\" target=\"_blank\">smitten-hug-77</a></strong> to <a href=\"https://wandb.ai/nilm/global_models_feb10\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_results = {}\n",
    "random.seed(3)\n",
    "train_homes = []\n",
    "best_models = []\n",
    "max_patience = 200\n",
    "min_patience = 50\n",
    "\n",
    "for i in home_ids:\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    training_homes=[i]\n",
    "    #training_homes = random.sample(list(home_ids), k=1)\n",
    "    #training_homes = train_homes_from_fl[-1]\n",
    "    testing_homes = [random.choice(training_homes)]\n",
    "    #testing_homes = [test_homes_from_fl[-1]]\n",
    "    #patience = int((max_patience-min_patience)/(1-random_select[-1])*len(training_homes)+max_patience+(max_patience-min_patience)/(1-random_select[-1]))\n",
    "    patience = 2000\n",
    "    print(\"patience: \", patience)\n",
    "    print(\"training_home: \", training_homes)\n",
    "    print(\"test_home: \", testing_homes)\n",
    "    model, per_house_result, best_model = model_pipeline(\n",
    "    config_,\n",
    "    'sept_oct_nov',\n",
    "    'dec',\n",
    "    config_['appliance'],\n",
    "    config_['window_size'],\n",
    "    training_homes,\n",
    "    testing_homes,\n",
    "    patience)\n",
    "    result = {str(config_[\"appliance\"])+\"_Train_home_\"+str(training_homes)+\"_Test_home_\"+str(testing_homes)+\"_total_homes_\"+str(1): per_house_result}\n",
    "    final_results.update(result)\n",
    "    print(final_results)\n",
    "    #model.cpu()\n",
    "    #torch.save(model.state_dict(), PATH+\"\\\\refrigerator_model_total_houses_\"+str(random_select[i])+\"_trial_3.pth\")\n",
    "    best_model.cpu()\n",
    "    model.cpu()\n",
    "    best_models.append(best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
